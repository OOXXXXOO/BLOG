<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Tom Winshare Page</title>
  
  <subtitle> Research about perception / robotics / natural language</subtitle>
  <link href="http://winshare.tech/atom.xml" rel="self"/>
  
  <link href="http://winshare.tech/"/>
  <updated>2023-04-20T18:26:00.288Z</updated>
  <id>http://winshare.tech/</id>
  
  <author>
    <name>Tom Winshare</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>MakeFile.Python &amp; C++ Programe Toturial</title>
    <link href="http://winshare.tech/2023/04/21/CPP_Python%20Code%20Inference/"/>
    <id>http://winshare.tech/2023/04/21/CPP_Python%20Code%20Inference/</id>
    <published>2023-04-20T18:23:17.911Z</published>
    <updated>2023-04-20T18:26:00.288Z</updated>
    
    <content type="html"><![CDATA[<h1 id="MakeFile-Python-amp-C-混编教程-上"><a href="#MakeFile-Python-amp-C-混编教程-上" class="headerlink" title="MakeFile.Python &amp; C++ 混编教程 上"></a>MakeFile.Python &amp; C++ 混编教程 上</h1><p>对于习惯IDE的Programmer来说 底层实际上是非常陌生的领域 然而下探到C++编译机制，对于一个合格的工程师又是非常有必要掌握的技术因此  本篇文章将讲解利用MakeFile 来实现Python C++混编的目的</p><p>首先不同平台的编译，存在着显著的差别：</p><blockquote><p>Linux&#x2F;UnixLike平台的动态链接库一般为.so为结尾（shared object）</p><p>Windows平台的动态链接库一般为.dll为结尾（Dynamic Link Library ）</p></blockquote><h2 id="Linux-Part："><a href="#Linux-Part：" class="headerlink" title="Linux Part："></a>Linux Part：</h2><h3 id="编译器"><a href="#编译器" class="headerlink" title="编译器"></a>编译器</h3><p>在Linux中  主流编译器为Clang以及GNU（GCC，G++）<br>GCC中支持的语言常用的有<br>C、C++、Java、Object-C<br>结构类似于一个标准Unix编译器</p><p>而Clang是支持C++，CObject-C，Object-C++语言的编译器前端<br>其底层采用了LLVM底层虚拟机，在编译Object-C时对比GCC快三倍</p><p>总体上：</p><ul><li>GCC特性：</li></ul><p>除支持C&#x2F;C++&#x2F; Objective-C&#x2F;Objective-C++语言外，还是支持Java&#x2F;Ada&#x2F;Fortran&#x2F;Go等；当前的Clang的C++支持落后于GCC；支持更多平台；更流行，广泛使用，支持完备。</p><ul><li>Clang特性：</li></ul><p>编译速度快；内存占用小；兼容GCC；设计清晰简单、容易理解，易于扩展增强；基于库的模块化设计，易于IDE集成；出错提示更友好</p><hr><p>我们先以GCC为例讲解以下一个典型的C++编译指令是如何工作的</p><h4 id="一个典型的Unix-like平台的-C-程序编译要经过哪些步骤？"><a href="#一个典型的Unix-like平台的-C-程序编译要经过哪些步骤？" class="headerlink" title="一个典型的Unix like平台的 C++程序编译要经过哪些步骤？"></a>一个典型的Unix like平台的 C++程序编译要经过哪些步骤？</h4><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://img-blog.csdnimg.cn/img_convert/4ece889e044de7f9c8de37222789cb40.jpeg"                                     ></p><p>(更详细的解释参照<a class="link"   href="https://blog.csdn.net/csdn_violin/article/details/79430384" >C++编译过程 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>，不再赘述)</p><p>而一个 gcc –h显示的帮助信息<strong>最常用</strong>的部分如下：</p><div class="highlight-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">-B &lt;directory&gt;           Add &lt;directory&gt; to the compiler<span class="string">&#x27;s search paths</span></span><br><span class="line"><span class="string">#添加编译器的搜索路径（例如头文件等）</span></span><br><span class="line"><span class="string">-v                       Display the programs invoked by the compiler</span></span><br><span class="line"><span class="string">#显示被编译器调用的程序</span></span><br><span class="line"><span class="string">-###                     Like -v but options quoted and commands not executed</span></span><br><span class="line"><span class="string">-E                       Preprocess only; do not compile, assemble or link</span></span><br><span class="line"><span class="string">#只预处理不编译汇编或者链接</span></span><br><span class="line"><span class="string">-S                       Compile only; do not assemble or link</span></span><br><span class="line"><span class="string">#只编译不汇编和链接</span></span><br><span class="line"><span class="string">-c                       Compile and assemble, but do not link</span></span><br><span class="line"><span class="string">#编译和汇编，不连接</span></span><br><span class="line"><span class="string">-o &lt;file&gt;                Place the output into &lt;file&gt;</span></span><br><span class="line"><span class="string">#输出到文件</span></span><br><span class="line"><span class="string">-pie                     Create a position independent executable</span></span><br><span class="line"><span class="string">#创建与位置无关的可执行文件</span></span><br><span class="line"><span class="string">-shared                  Create a shared library</span></span><br><span class="line"><span class="string">#创建一个共享库</span></span><br></pre></td></tr></table></figure></div><p>我们来尝试编译一个helloworld</p><blockquote><p>main.cpp</p></blockquote><div class="highlight-container" data-rel="C++"><figure class="iseeu highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    cout&lt;&lt;<span class="string">&quot;c++ is best language&quot;</span>&lt;&lt;endl;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><p>对于这样一个非常基础的没有额外依赖的cpp文件来说，编译过程当然也相当简单。</p><div class="highlight-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">g++ -c main.cpp</span><br><span class="line"><span class="comment">#只编译和汇编main.cpp不链接生成main.o的目标代码文件</span></span><br></pre></td></tr></table></figure></div><p>如果我们还想执行这个代码就要生成可执行文件</p><div class="highlight-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">g++ -o main.out main.o</span><br><span class="line"><span class="comment">#输出到.out可执行文件</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#也可以合并执行</span></span><br><span class="line">g++ -o hello.out hello.cpp</span><br><span class="line"><span class="comment">#直接编译并输出到可执行文件</span></span><br></pre></td></tr></table></figure></div><p>则.&#x2F;xx.out 就可以运行编译完成的可执行文件了<br>但是这个并不是典型的应用场景  我们用下面的三个代码来模拟日常更常用的C++工作模式</p><blockquote><p>head.h</p></blockquote><div class="highlight-container" data-rel="C"><figure class="iseeu highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">ifndef</span> HEAD_H</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> HEAD_H</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;head.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line">using namespace <span class="built_in">std</span>;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Human</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">private:</span><br><span class="line">    <span class="comment">/* data */</span></span><br><span class="line">public:</span><br><span class="line"><span class="type">void</span> <span class="title function_">Say</span><span class="params">()</span>;</span><br><span class="line"><span class="type">void</span> <span class="title function_">SaywithPython</span><span class="params">()</span>;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br></pre></td></tr></table></figure></div><blockquote><p>function.cpp</p></blockquote><div class="highlight-container" data-rel="C"><figure class="iseeu highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;head.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">Human::Say</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="built_in">cout</span>&lt;&lt;<span class="string">&quot;Im Human ,You are shit&quot;</span>&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">void</span> <span class="title function_">Human::SaywithPython</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="built_in">cout</span>&lt;&lt;<span class="string">&quot;Python is best language&quot;</span>&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure></div><blockquote><p>main.cpp</p></blockquote><div class="highlight-container" data-rel="C"><figure class="iseeu highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;head.h&quot;</span></span></span><br><span class="line">using namespace <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt;<span class="string">&quot;C++ is best language&quot;</span>&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">    Human Jarvis;</span><br><span class="line">    Jarvis.Say();</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><p>这一小段程序包含了非常多的技巧</p><p>首先定义了head以及function本地头文件和实现，在cpp文件中实现了<br>两个公开的方法</p><p>在main中又调用了实例化对象中的该方法</p><p>由于涉及了多个文件因此我们必须有一种方法来指定编译器的行为——MakeFile</p><div class="highlight-container" data-rel="Makefile"><figure class="iseeu highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">build : main.o function.o</span><br><span class="line">g++ -o build main.o function.o</span><br><span class="line">main.o : main.cpp head.h</span><br><span class="line">g++ -g -c main.cpp</span><br><span class="line">function.o : head.h function.cpp</span><br><span class="line">g++ -g -c function.cpp</span><br><span class="line">clean :</span><br><span class="line">rm main.o function.o build</span><br><span class="line"><span class="comment">#pylib : function.cpp</span></span><br><span class="line"><span class="comment">#g++ -o pylib.so -shared -fPIC function.cpp</span></span><br></pre></td></tr></table></figure></div><p>其中整个的格式为：</p><div class="highlight-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">target ... : prerequisites ...</span><br><span class="line">　　<span class="built_in">command</span>    <span class="comment">#tab</span></span><br></pre></td></tr></table></figure></div><ul><li><p>target为目标文件</p></li><li><p>prerequisites为生成目标文件所需的文件</p></li><li><p>command为编译该目标文件所需的指令</p></li></ul><p>所以目前我们可以按照之前的C++编译流程图 整理出的依赖顺序为：<br>1.编译function.cpp依赖于head.h 生成function.o 即：</p><div class="highlight-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">function.o : head.h function.cpp</span><br><span class="line">g++ -g -c function.cpp</span><br></pre></td></tr></table></figure></div><p>2.编译main.cpp依赖于head.h 生成 main.o 即：</p><div class="highlight-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">main.o : main.cpp head.h</span><br><span class="line">g++ -g -c main.cpp</span><br></pre></td></tr></table></figure></div><p>3.编译可执行文件依赖于main.o function.o 生成指定的可执行文件（build）即：</p><div class="highlight-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">build : main.o function.o</span><br><span class="line">g++ -o build main.o function.o</span><br></pre></td></tr></table></figure></div><p>具体在执行过程中则遵循依赖，书写则从可执行文件开始（如果确实要生成可执行文件的话）</p><p>至此命令行中输入</p><div class="highlight-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">make</span><br></pre></td></tr></table></figure></div><p>就可以进行编译啦</p><div class="highlight-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#结果如同</span></span><br><span class="line">g++ -g -c main.cpp</span><br><span class="line">g++ -g -c function.cpp</span><br><span class="line">g++ -o build main.o function.o</span><br></pre></td></tr></table></figure></div><p>生成了build可执行文件<br>结果：</p><div class="highlight-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">c++ is best language</span><br><span class="line"></span><br><span class="line">Im Human ,You are shit</span><br></pre></td></tr></table></figure></div><p>通过这一步我们解决了C++编译的问题，那我们怎么解决Python和C++的混编呢？</p><p>重新编写</p><blockquote><p>function.cpp</p></blockquote><div class="highlight-container" data-rel="C"><figure class="iseeu highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;head.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">Human::Say</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="built_in">cout</span>&lt;&lt;<span class="string">&quot;Im Human ,You are shit&quot;</span>&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">void</span> <span class="title function_">Human::SaywithPython</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="built_in">cout</span>&lt;&lt;<span class="string">&quot;Python is best language&quot;</span>&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">extern</span> <span class="string">&quot;C&quot;</span>&#123;</span><br><span class="line">    Human pythonman;</span><br><span class="line">    <span class="type">void</span> <span class="title function_">SaywithPython</span><span class="params">()</span>&#123;</span><br><span class="line">        pythonman.SaywithPython();</span><br><span class="line">        <span class="built_in">cout</span>&lt;&lt;<span class="string">&quot;C++ IS SHIT!!&quot;</span>&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><h5 id="通常来说，在模块的头文件中对本模块提供给其他模块引用的函数和全局变量以关键字extern声明。"><a href="#通常来说，在模块的头文件中对本模块提供给其他模块引用的函数和全局变量以关键字extern声明。" class="headerlink" title="通常来说，在模块的头文件中对本模块提供给其他模块引用的函数和全局变量以关键字extern声明。"></a>通常来说，在模块的头文件中对本模块提供给其他模块引用的函数和全局变量以关键字extern声明。</h5><p>Tips:</p><ul><li><p>extern是C&#x2F;C++语言中表明函数和全局变量的作用范围的关键字，该关键字告诉编译器，其申明的函数和变量可以在本模块或其他模块中使用。</p></li><li><p>被extern “C”修饰的变量和函数是按照C语言方式进行编译和链接的</p></li><li><p>extern int a; 仅仅是一个变量的声明，其并不是在定义变量a，并未为a分配空间。变量a在所有模块中作为一种全局变量只能被定义一次，否则会出错。</p></li><li><p>extern对应的关键字是static，static表明变量或者函数只能在本模块中使用，因此，被static修饰的变量或者函数不可能被extern C修饰。</p></li></ul><p>这一步的目的是通过MakeFile生成动态链接库，在Unix like系统中一般为.so文件：</p><div class="highlight-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">build : main.o function.o</span><br><span class="line">g++ -o build main.o function.o</span><br><span class="line">main.o : main.cpp head.h</span><br><span class="line">g++ -g -c main.cpp</span><br><span class="line">function.o : head.h function.cpp</span><br><span class="line">g++ -g -c function.cpp</span><br><span class="line">clean :</span><br><span class="line"><span class="built_in">rm</span> main.o function.o build</span><br><span class="line"></span><br><span class="line">pylib : function.cpp</span><br><span class="line">g++ -o pylib.so -shared -fPIC function.cpp</span><br><span class="line"><span class="comment">#通过 -shared 生成 .so文件</span></span><br></pre></td></tr></table></figure></div><p>通过</p><div class="highlight-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">make pylib</span><br></pre></td></tr></table></figure></div><p>就可以生成pylib.so文件<br>此时我们开始建立python脚本</p><blockquote><p>main.py</p></blockquote><div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> ctypes</span><br><span class="line">ll=ctypes.cdll.LoadLibrary</span><br><span class="line"><span class="comment">#载入动态链接库</span></span><br><span class="line">lib=ll(<span class="string">&#x27;/home/winshare/Leetcode/MakeFileTutorial/pylib.so&#x27;</span>)</span><br><span class="line"><span class="comment">#ll(&#x27;动态链接库文件的地址&#x27;)</span></span><br><span class="line">lib.SaywithPython()</span><br></pre></td></tr></table></figure></div><p>输出：</p><div class="highlight-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Python is best language</span><br><span class="line">C++ IS SHIT!!</span><br></pre></td></tr></table></figure></div><p>至此  我们完成了Python调用C++的实践</p>]]></content>
    
    
    <summary type="html">对于习惯IDE的Programmer来说 底层实际上是非常陌生的领域 然而下探到C++编译机制，对于一个合格的工程师又是非常有必要掌握的技术因此  本篇文章将讲解利用MakeFile 来实现Python C++混编的目的</summary>
    
    
    
    <category term="C++" scheme="http://winshare.tech/categories/C/"/>
    
    
    <category term="Programe" scheme="http://winshare.tech/source/tags/Programe/"/>
    
    <category term="C++" scheme="http://winshare.tech/source/tags/C/"/>
    
    <category term="Python" scheme="http://winshare.tech/source/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>LandSlide Prediction Algorithm</title>
    <link href="http://winshare.tech/2023/04/21/Landslide%20Prediction%20System/"/>
    <id>http://winshare.tech/2023/04/21/Landslide%20Prediction%20System/</id>
    <published>2023-04-20T17:49:27.401Z</published>
    <updated>2023-04-20T18:02:25.158Z</updated>
    
    <content type="html"><![CDATA[<h1 id="LandSlide-Prediction-Algorithm"><a href="#LandSlide-Prediction-Algorithm" class="headerlink" title="LandSlide Prediction Algorithm"></a>LandSlide Prediction Algorithm</h1><p>Massive earthquakes in mountainous regions often lead to numerous landslides endangering human lives. Whether and where landslides can occur is a mystery. We wonder whether it is possible to single out mountainous sites prone to landslides around major fault lines, and subsequently warn off habitation and development there.<br>To do that, we propose the deep learning of terrain structure around the 2008 Wenchuan earthquake. We convert this terrain challenge to literally an MNIST challenge familiar to most data miners. Results show that landslide area can be predicted up to <strong>~93% accuracy</strong> when the location and depth of the quake epicenter is known, or to <strong>~78% accuracy</strong> with unknown epicenter location and depth. These accuracy numbers are imperfect but already useful for disaster prevention and relief work. We are releasing this dataset to the community for further experiments. In the future, deep learning of landslides from all major earthquakes around the world may lead to much more accurate predictions.</p><hr><h3 id="Predict-performance"><a href="#Predict-performance" class="headerlink" title="Predict performance"></a>Predict performance</h3><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://github.com/OOXXXXOO/Efficient-landslide/raw/master/resources/table.png"                                     ></p><p><strong>Without auxiliary feature vector input, the model trains to 78% binary classification accuracy. When we incorporate auxiliary feature input, the classification accuracy rises sharply to 93%.</strong></p><h3 id="Network-Structure-amp-Data-Process"><a href="#Network-Structure-amp-Data-Process" class="headerlink" title="Network Structure &amp; Data Process"></a>Network Structure &amp; Data Process</h3><p>We synchronized both the landslide dataset and the elevation dataset to the same ground resolution of 30 meters. Then we randomly subset both datasets to 33-by-33-pixel images. This translates to a square-kilometer region on the ground. In total we have 160,000 square kilometers in this study. 60% of the data is used for training, and 40% for validation.<br>We chose <strong>EfficientNet-B0</strong> due to its small size and excellent results.<br><img                       lazyload                     src="/images/loading.svg"                     data-src="https://github.com/OOXXXXOO/Efficient-landslide/raw/master/resources/network.png"                                     ><br>The auxiliary input data is a <strong>4x1 vector feature</strong> :</p><ul><li><strong>the distance to epicenter</strong></li><li><strong>longitudinal and latitudinal angles towards epicenter</strong>(two cord values)</li><li><strong>the local quake intensity</strong></li></ul><p>In Mercalli scale. We conducted two training-testing runs in total. The first training run does not incorporate the auxiliary input data feed, while the second run incorporates it. Their results will be compared and discussed in later sections.</p><h4 id="The-Integrated-SRTM-Data-at-epicenter-Wenchuan-2018："><a href="#The-Integrated-SRTM-Data-at-epicenter-Wenchuan-2018：" class="headerlink" title="The Integrated SRTM Data at epicenter, Wenchuan 2018："></a>The Integrated SRTM Data at epicenter, Wenchuan 2018：</h4><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://github.com/OOXXXXOO/Efficient-landslide/raw/master/resources/input.png"                                     ></p><ul><li>SRTM data &amp; Fault lines</li></ul><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://github.com/OOXXXXOO/Efficient-landslide/raw/master/resources/label.png"                                     ></p><ul><li>label data in the whole Wenchuan area.</li></ul><h4 id="Predicition-amp-Result"><a href="#Predicition-amp-Result" class="headerlink" title="Predicition &amp; Result"></a>Predicition &amp; Result</h4><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://github.com/OOXXXXOO/Efficient-landslide/raw/master/resources/prediction.png"                                     ></p><p>The prediction visualization in the gis softwear.</p><h4 id="Original-prediction-data"><a href="#Original-prediction-data" class="headerlink" title="Original prediction data"></a>Original prediction data</h4><p>We use two different way to generate prediction data.</p><ul><li>Random sample</li><li>Sliding window sample</li></ul><p>The first way like <strong>monte carlo simulation</strong> that random generate a cordinate of point in the whole area and add prediction to sample position on the background zero-matrix.(see iamge below)</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://github.com/OOXXXXOO/Efficient-landslide/raw/master/resources/Figure_2.png"                                     ></p><p>The second way like convolution operation.The sample process like sliding window in original STRM data map, you can set different stride to make result perfect.<br>(see image below)</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://github.com/OOXXXXOO/Efficient-landslide/raw/master/resources/Figure_3.png"                                     ></p><p>As comparison, the first way has more information about possibility of landslide,the secound way just faster and generate binary classification result to help people make a strategic decision directly.</p><hr><h3 id="Train-amp-Run"><a href="#Train-amp-Run" class="headerlink" title="Train &amp; Run"></a>Train &amp; Run</h3><p>Clone Project:</p><div class="highlight-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git@github.com:OOXXXXOO/Efficient-landslide.git</span><br></pre></td></tr></table></figure></div><h5 id="Environment-requirement："><a href="#Environment-requirement：" class="headerlink" title="Environment requirement："></a>Environment requirement：</h5><ul><li><a class="link"   href="https://www.anaconda.com/" >Anaconda <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a><br><a class="link"   href="https://mirrors.tuna.tsinghua.edu.cn/help/anaconda/" >(China Option) <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></li><li><a class="link"   href="https://pytorch.org/" >Pytorch 1.1&#x2F;1.2 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a><br><a class="link"   href="https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/" >(China Channel Option) <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></li></ul><p><strong>In order to simplify configuration process. you could install requirement from yml file.</strong></p><div class="highlight-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda <span class="built_in">env</span> create -f environment.yml</span><br></pre></td></tr></table></figure></div><p>Then</p><div class="highlight-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">source</span> activate torchbeta</span><br><span class="line">python predict_vector_intensity.py <span class="comment">#train_vector_intensity.py</span></span><br></pre></td></tr></table></figure></div><h3 id="Data"><a href="#Data" class="headerlink" title="Data:"></a>Data:</h3><p>Original Data is </p><ul><li>SRTM map : <a class="link"   href="http://dwtkns.com/srtm30m/" >download link <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></li><li>Intensity map : <a class="link"   href="https://earthquake.usgs.gov/earthquakes/eventpage/usp000g650/shakemap/intensity" >download link <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></li><li>The Wenchuan Epicenter longitude and latitude (31.0°N,103.4°E)</li></ul><p>Preprocessed Data :</p><p><a class="link"   href="https://youngqfbr-my.sharepoint.com/:f:/g/personal/winshare_x1_tn/EjeEEp3l3qxDoJbHHVQjxDEBJpO4JwHzKjaYwoVAWHfw6Q?e=5Uez52" >OneDrive Link ( China.Hongkong Data Center ) <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p><p><strong>Tips:</strong><br>The $10^{6}$ small files I&#x2F;O has been a bottleneck in training process，append all sample data to a npy file is a greate training strategy for save you time.</p><p>It is true that our study is based on the dataset from just one major earthquake and thus can be quite limited in power. Overfitting is a serious concern. However, if geologists from quake-prone countries could share landslide cataloging data after major quakes, then it is possible to train deep learning models for the whole planet. More data leads to more reliable predictions. As a baby step, we are sharing the Wenchuan landslide dataset with the research community.<br><strong>We invite everyone to try it and come up with insights.</strong></p><h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference:"></a>Reference:</h3><ul><li>[1] C. Xu et al., Three (nearly) complete inventories of landslides triggered by the May 12, 2008 Wenchuan Mw 7.9 earthquake of China and their spatial distribution statistical analysis. Landslides (2014) 11: 441</li><li>[2] C. Xu et al., “Revisions of the M 8.0 Wenchuan earthquake seismic intensity map based on co-seismic landslide abundance”, Natural Hazards 69(3) · December 2013</li><li>[3] Jet Propulsion Laboratory, NASA. “U.S. Releases Enhanced Shuttle Land Elevation Data”, , <a class="link"   href="https://www2.jpl.nasa.gov/srtm/index.html" >https://www2.jpl.nasa.gov/srtm/index.html <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> as accessed in July 2019</li><li>[4] M. Tan, Q. V. Le, EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks, ICML2019</li><li>[5] Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. “Gradient-based learning applied to document recognition.” Proceedings of the IEEE, 86(11):2278-2324, November 1998</li><li>[6] A. Holcombe, “Farewell authors, hello contributors”, Nature 571, 147 (2019)</li></ul>]]></content>
    
    
    <summary type="html">Massive earthquakes in mountainous regions often lead to numerous landslides endangering human lives. Whether and where landslides can occur is a mystery. We wonder whether it is possible to single out mountainous sites prone to landslides around major fault lines, and subsequently warn off habitation and development there.</summary>
    
    
    
    <category term="GIS" scheme="http://winshare.tech/categories/GIS/"/>
    
    
    <category term="GIS" scheme="http://winshare.tech/source/tags/GIS/"/>
    
    <category term="ComputerVision" scheme="http://winshare.tech/source/tags/ComputerVision/"/>
    
    <category term="Dataset" scheme="http://winshare.tech/source/tags/Dataset/"/>
    
  </entry>
  
  <entry>
    <title>The Satellite Imagery DataSet Toolkit</title>
    <link href="http://winshare.tech/2023/04/21/The%20Satellite%20Imagery%20DataSet%20Toolkit/"/>
    <id>http://winshare.tech/2023/04/21/The%20Satellite%20Imagery%20DataSet%20Toolkit/</id>
    <published>2023-04-20T17:41:16.537Z</published>
    <updated>2023-04-20T23:54:01.463Z</updated>
    
    <content type="html"><![CDATA[<p>The Satellite Imagery DataSet Toolkit</p><hr><h2 id="The-Satellite-Imagery-DataSet-Toolkit"><a href="#The-Satellite-Imagery-DataSet-Toolkit" class="headerlink" title="The Satellite Imagery DataSet Toolkit"></a><strong>The Satellite Imagery DataSet Toolkit</strong></h2><h3 id="Useage"><a href="#Useage" class="headerlink" title="Useage:"></a>Useage:</h3><ul><li><a href="document/GuidetoStart.md">Guide to Start</a></li><li><a href="document/doc.md">Document</a></li></ul><p><strong>The Satellite Imagery DataSet</strong> is an important part to train, validate the deep learning model of different missions in modern GIS science. </p><p>This toolkit work for download different data sources and use specific layer (class) in <a class="link"   href="https://openmaptiles.com/downloads/planet/" >OSM Vector Data <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> (or other vector file)  to generate dataset for train or validation model.</p><h3 id="Install"><a href="#Install" class="headerlink" title="Install"></a>Install</h3><h4 id="Requirement"><a href="#Requirement" class="headerlink" title="Requirement:"></a>Requirement:</h4><h5 id="Install-GDAL-by-Anaconda-x2F-MiniConda-not-pip"><a href="#Install-GDAL-by-Anaconda-x2F-MiniConda-not-pip" class="headerlink" title="Install GDAL by Anaconda&#x2F;MiniConda not pip"></a><strong>Install GDAL by Anaconda&#x2F;MiniConda not pip</strong></h5><div class="highlight-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda install gdal</span><br></pre></td></tr></table></figure></div><h5 id="install-package"><a href="#install-package" class="headerlink" title="install package"></a>install package</h5><div class="highlight-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install d-arth</span><br></pre></td></tr></table></figure></div><h5 id="Additional-Huawei-OBS-Server-Package-Optional"><a href="#Additional-Huawei-OBS-Server-Package-Optional" class="headerlink" title="Additional: Huawei OBS Server Package (Optional)"></a>Additional: Huawei OBS Server Package (Optional)</h5><p>After version 0.0.3, the process will install OBS package automatically. The Azure &amp; Amazon Service will support in beta version, <strong>if it is necessary</strong>. So we don’t need to install related package manually.</p><h3 id="Support-Vector-Datasource-type"><a href="#Support-Vector-Datasource-type" class="headerlink" title="Support Vector Datasource type:"></a>Support Vector Datasource type:</h3><ul><li>MBTiles</li><li>Shapefile</li><li>Pbf</li><li>Geojson</li></ul><p>First of all , the layer name &amp; class should be know as prior knowledge that mean the same class maybe has different keyword in OSM data and definition. like ‘water’ as a classname, but same classname in OSM data will be ‘waterway’,’water’,’lake’…</p><h3 id="Support-Raster-Dataset-key"><a href="#Support-Raster-Dataset-key" class="headerlink" title="Support Raster Dataset key:"></a>Support Raster Dataset key:</h3><ul><li>Google</li><li>Google China,</li><li>Google Maps,</li><li>Google Satellite,</li><li>Google Terrain,</li><li>Google Terrain Hybrid,</li><li>Google Satellite Hybrid</li><li>Stamen Terrain</li><li>Stamen Toner</li><li>Stamen Toner Light</li><li>Stamen Watercolor</li><li>Wikimedia Map</li><li>Wikimedia Hike Bike Map</li><li>Esri Boundaries Places</li><li>Esri Gray (dark)</li><li>Esri Gray (light)</li><li>Esri National Geographic</li><li>Esri Ocean,</li><li>Esri Satellite,</li><li>Esri Standard,</li><li>Esri Terrain,</li><li>Esri Transportation,</li><li>Esri Topo World,</li><li>OpenStreetMap Standard,</li><li>OpenStreetMap H.O.T.,</li><li>OpenStreetMap Monochrome,</li><li>OpenTopoMap,</li><li>Strava All,</li><li>Strava Run,</li><li>Open Weather Map Temperature,</li><li>Open Weather Map Clouds,</li><li>Open Weather Map Wind Speed,</li><li>CartoDb Dark Matter,</li><li>CartoDb Positron,</li><li>Bing VirtualEarth</li></ul><h3 id="Tutorial"><a href="#Tutorial" class="headerlink" title="Tutorial:"></a>Tutorial:</h3><h4 id="Step-1"><a href="#Step-1" class="headerlink" title="Step 1:"></a>Step 1:</h4><p>Download the tile file is the first step. But the almost data resources supporter didn’t write the projection information to tile file. So the compute tile projection infomation &amp; write to file is most import part in process of download flow.</p><p><strong>Optional :</strong></p><div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> darth.downloader <span class="keyword">import</span> downloader</span><br><span class="line">Google=downloader(<span class="string">&quot;Google Satellite&quot;</span>,thread_count=<span class="number">8</span>)</span><br></pre></td></tr></table></figure></div><p>Ues the 8 thread(if you have more thread could set more) to process download that will speed up whole flow of step1.</p><hr><div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> darth.downloader <span class="keyword">import</span> downloader</span><br><span class="line">Google=downloader(<span class="string">&quot;Google Satellite&quot;</span>)</span><br></pre></td></tr></table></figure></div><pre><code># ---------------------------------------------------------------------------- ##                            MAP Production Toolkit                            ## ---------------------------------------------------------------------------- ## ---------------------- MAP Serverv Init Successful by ---------------------- ## ---------------------- Google Satellite ------------------------------------ #</code></pre><hr><h3 id="Demo"><a href="#Demo" class="headerlink" title="Demo:"></a>Demo:</h3><p>We could choose a position like the Saltlake city, Utah states.</p><p>Salt Lake City is located in United States country, in North America continent (or region). DMS latitude longitude coordinates for Salt Lake City are: </p><blockquote><p><em>40°45’38.81”N, 111°53’27.78”W.</em></p></blockquote><ul><li>Latitude position:<br>Equator ⇐ 4532km (2816mi) ⇐ Salt Lake City ⇒ 5475km (3402mi) ⇒ North pole.</li><li>Longitude position: Salt Lake City ⇐ 8644km (5371mi) ⇐ Prime meridian. GMT: -6h.</li><li>Local time in Salt Lake City: Friday 1:35 am, May 22, 2020. [*time info]</li></ul><p>We need plan a area that describe by WGS84 lonlat,like:</p><ul><li><p>Cord1&#x3D;(-111.89105,40.76078) # Left Top Lonlat</p></li><li><p>Cord2&#x3D;(-111.8,40.7)# Right Bottom Lonlat</p></li></ul><p>In addition, we need set the <code>zoom level</code> that mean resolution of each map tile. Relative info:</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://i.stack.imgur.com/sVyYF.jpg"                                     ></p><p>The data will generate as tiles (256*256 pixel image), you also could use <code>DOWNLOADER_INSTANCE</code>.merge() to merge all the tiles to whole tiff file.</p><p>addcord() as a function ,input is WGS cord of left-top point &amp; right-bottom point x1,y1,x2,y2,additional zoom level that mean different level density of data grid.</p><pre><code>left, top : left-top coordinate, for example (100.361,38.866)right, bottom : right-bottom coordinatez : zoomfilePath : File path for storing results, TIFF format</code></pre><div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Google.add_cord(<span class="number">116.3</span>, <span class="number">39.9</span>, <span class="number">116.6</span>, <span class="number">39.7</span>, <span class="number">13</span>)<span class="comment"># WGS Lonlat Form</span></span><br><span class="line">Google.download()</span><br><span class="line"><span class="comment">#Google.merge()#Merge to one tif file </span></span><br></pre></td></tr></table></figure></div><pre><code># -----WGS BoundingBox: (116.27325422704708, 39.90850398784923, 116.62506415757257, 39.67233079805734)# -----Mercator BoudingBox: (12943479.451629978, 4852655.222148937, 12982642.753946641, 4818439.909406773)# -----Total tiles number：8 X 7  0%|          | 0/56 [00:00&lt;?, ?it/s]# -----Url Queue size: 56 88%|████████▊ | 49/56 [00:00&lt;00:00, 30.20it/s]100%|██████████| 56/56 [00:00&lt;00:00, 93877.31it/s]100%|██████████| 56/56 [00:00&lt;00:00, 57.96it/s]# ===== Decode Downloading...# ------------------------------- Download Done ------------------------------ ## ===== Save description done Google China-Sun Jun 28 10:51:01 2020-(116.3, 39.9, 116.6, 39.7)-13.json</code></pre><h5 id="Cord-System"><a href="#Cord-System" class="headerlink" title="Cord System"></a>Cord System</h5><p>TMS Global Mercator Profile</p><div class="highlight-container" data-rel="Txt"><figure class="iseeu highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">Functions necessary for generation of tiles in Spherical Mercator projection,</span><br><span class="line">EPSG:900913 (EPSG:gOOglE, Google Maps Global Mercator), EPSG:3785, OSGEO:41001.</span><br><span class="line"></span><br><span class="line">Such tiles are compatible with Google Maps, Microsoft Virtual Earth, Yahoo Maps,</span><br><span class="line">UK Ordnance Survey OpenSpace API, ...</span><br><span class="line">and you can overlay them on top of base maps of those web mapping applications.</span><br><span class="line"></span><br><span class="line">Pixel and tile coordinates are in TMS notation (origin [0,0] in bottom-left).</span><br><span class="line"></span><br><span class="line">What coordinate conversions do we need for TMS Global Mercator tiles::</span><br><span class="line"></span><br><span class="line">     LatLon      &lt;-&gt;       Meters      &lt;-&gt;     Pixels    &lt;-&gt;       Tile     </span><br><span class="line"></span><br><span class="line"> WGS84 coordinates   Spherical Mercator  Pixels in pyramid  Tiles in pyramid</span><br><span class="line">     lat/lon            XY in metres     XY pixels Z zoom      XYZ from TMS </span><br><span class="line">    EPSG:4326           EPSG:900913                                         </span><br><span class="line">     .----.              ---------               --                TMS      </span><br><span class="line">    /      \     &lt;-&gt;     |       |     &lt;-&gt;     /----/    &lt;-&gt;      Google    </span><br><span class="line">    \      /             |       |           /--------/          QuadTree   </span><br><span class="line">     -----               ---------         /------------/                   </span><br><span class="line">   KML, public         WebMapService         Web Clients      TileMapService</span><br></pre></td></tr></table></figure></div><hr><p>The new version of data toolkit will have dict to save info during process.<br>format:</p><div class="highlight-container" data-rel="Json"><figure class="iseeu highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">tileinfo=<span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;time&quot;</span><span class="punctuation">:</span>str(time.asctime(time.localtime(time.time())))<span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;left&quot;</span><span class="punctuation">:</span>self.left<span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;top&quot;</span><span class="punctuation">:</span>self.top<span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;right&quot;</span><span class="punctuation">:</span>self.right<span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;bottom&quot;</span><span class="punctuation">:</span>self.bottom<span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;zoom&quot;</span><span class="punctuation">:</span>self.zoom<span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;server&quot;</span><span class="punctuation">:</span>self.server<span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;data&quot;</span><span class="punctuation">:</span>self.result</span><br><span class="line">    <span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure></div><p>The each downloaded item will has a self description key like:</p><div class="highlight-container" data-rel="Json"><figure class="iseeu highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    &#x27;server&#x27;<span class="punctuation">:</span> &#x27;Google Satellite&#x27;<span class="punctuation">,</span> </span><br><span class="line">    &#x27;info&#x27;<span class="punctuation">:</span> <span class="punctuation">[</span><span class="number">6743</span><span class="punctuation">,</span> <span class="number">3104</span><span class="punctuation">,</span> <span class="number">13</span><span class="punctuation">]</span><span class="punctuation">,</span> </span><br><span class="line">    &#x27;url&#x27;<span class="punctuation">:</span> &#x27;https<span class="punctuation">:</span><span class="comment">//mt1.google.com/vt/lyrs=s&amp;x=6743&amp;y=3104&amp;z=13&#x27;, </span></span><br><span class="line">    &#x27;path&#x27;<span class="punctuation">:</span> &#x27;./images/Google Satellite<span class="number">-6743</span><span class="number">-3104</span><span class="number">-13.</span>tif&#x27;</span><br><span class="line"><span class="punctuation">&#125;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure></div><hr><div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tiles=[i[<span class="string">&quot;path&quot;</span>] <span class="keyword">for</span> i <span class="keyword">in</span> Google.result]</span><br></pre></td></tr></table></figure></div><hr><p>The Vector &amp; Raster Class could do some I&#x2F;O, transform object to raster or vector object.</p><p>For instance, we use a shapefile that downloads from <a class="link"   href="https://gis.utah.gov/" >https://gis.utah.gov/ <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> as the label to generate ground-truth.</p><p>If the timestamp of two data sources (vector &amp; raster) is almost the same, you could get a high-quality dataset. </p><p>Additionally, <a class="link"   href="https://www.openstreetmap.org/" >https://www.openstreetmap.org/ <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> has global vector product as below: </p><hr><div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> darth.vector <span class="keyword">import</span> Vector</span><br><span class="line">Building=Vector(<span class="string">&#x27;/home/winshare/Downloads/2017-07-03_asia_china.mbtiles&#x27;</span>)<span class="comment"># 3.7GB SQLiteBased-MBTiles . The China Main Class Vector Object.</span></span><br></pre></td></tr></table></figure></div><pre><code># ---------------------------------------------------------------------------- ##                                Vector Toolkit                                ## ---------------------------------------------------------------------------- ## ---------------------------------------------------------------------------- ##                            TIFF process Toolkit                              ## ---------------------------------------------------------------------------- ## -----Class TIF init without filename# -----Valid vector format : mbtiles# ----------------------------- Meta Information ----------------------------- ## -----ZOOM_LEVEL : 14                                                         ## -----attribution : &lt;a href=&quot;http://www.openmaptiles.org/&quot; target=&quot;_blank&quot;&gt;&amp;co## -----center : 116.4025,39.92,14                                              ## -----description : Extract from https://openmaptiles.org                     ## -----maxzoom : 14                                                            ## -----minzoom : 0                                                             ## -----name : OpenMapTiles                                                     ## -----pixel_scale : 256                                                       ## -----mtime : 1499626373833                                                   ## -----format : pbf                                                            ## -----id : openmaptiles                                                       ## -----version : 3.6.1                                                         ## -----maskLevel : 5                                                           ## -----bounds : 115.686,39.414,117.119,40.426                                  ## -----planettime : 1499040000000                                              ## -----basename : china_beijing.mbtiles                                        ## ----------------------------- Meta Information ----------------------------- ## -----Description :  /workspace/osm-2017-07-03-v3.6.1-china_beijing.mbtiles# -----LayerCount: 15# -----Layer : 0  LayerName :  water # -----Layer : 1  LayerName :  waterway # -----Layer : 2  LayerName :  landcover # -----Layer : 3  LayerName :  landuse # -----Layer : 4  LayerName :  mountain_peak # -----Layer : 5  LayerName :  park # -----Layer : 6  LayerName :  boundary # -----Layer : 7  LayerName :  aeroway # -----Layer : 8  LayerName :  transportation # -----Layer : 9  LayerName :  building # -----Layer : 10  LayerName :  water_name </code></pre><hr><p>The most of SQLite based mbtiles vector database will have multi-layer, but wkt based shapefile &amp; geojson almost have single layer.<br>Normally , Name of layer is class name that must set as default layer by <code>getDefaultLayerbyName</code> function. So we need choose a default layer by <code>LayerName</code> that will generate binary label for deep learning training.</p><ul><li>Of course , the function of multi-layer will update in next version.</li></ul><hr><div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Building.getDefaultLayerbyName(<span class="string">&quot;building&quot;</span>)</span><br></pre></td></tr></table></figure></div><pre><code>----- Set Default Layer  building  :  &lt;osgeo.ogr.Layer; proxy of &lt;Swig Object of type &#39;OGRLayerShadow *&#39; at 0x7fd4b2566660&gt; &gt;&lt;osgeo.ogr.Layer; proxy of &lt;Swig Object of type &#39;OGRLayerShadow *&#39; at 0x7fd4b2566660&gt; &gt;</code></pre><hr><h3 id="Step-2"><a href="#Step-2" class="headerlink" title="Step 2:"></a>Step 2:</h3><p>If the data used for model training, we should have a label that could be generated by the rasterize vector file. Normally, the data will label by artificial work. But human resources have limit in huge object labels with high-resolution imagery. The OSM Vector data has a worldwide version that saves in sqlite based mbtiles file system that could be decode by GDAL library.</p><p>The Class Vector and Raster is an important part of data I&#x2F;O. Rasterisation is the task of taking an image described in a vector graphics format (shapes) and converting it into a raster image (a series of pixels, dots, or lines, which, when displayed together, create the image which was represented via shapes).[1][2] The rasterized image may then be displayed on a computer display, video display or printer, or stored in a bitmap file format. Rasterisation may refer to the technique of drawing 3D models, or the conversion of 2D rendering primitives such as polygons, line segments into a rasterized format.</p><p>The map data has better relative accuracy than temporary human label work that means the vector map has the potential to be ground-truth. So, transform the existing vector to raster data that is an indispensable method for generating training data in deep-learning-based computer vision mission.<br>Rasterize:</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://upload.wikimedia.org/wikipedia/commons/thumb/b/b0/Top-left_triangle_rasterization_rule.gif/220px-Top-left_triangle_rasterization_rule.gif"                                     ></p><hr><h4 id="Notes"><a href="#Notes" class="headerlink" title="Notes:"></a>Notes:</h4><p>If the vector layers have a huge geography space and enormous amount of data item that will cause the indexing process will extremely inefficient in rasterize process. </p><p>We set a rect size like a bounding box of Beijing city from the geographic area of CHINA. Then, we set the same area as filters in the whole space.</p><p>That could show the speed of the same mission on with filter and without a filter.</p><table><thead><tr><th align="center">Experiment</th><th align="center"></th><th align="center"></th></tr></thead><tbody><tr><td align="center"></td><td align="center">item&#x2F;Sec</td><td align="center">100000sample</td></tr><tr><td align="center">withoutFilter</td><td align="center">34</td><td align="center">94  hour</td></tr><tr><td align="center">withFilter</td><td align="center">3</td><td align="center">8.3 hour</td></tr></tbody></table><p>Although I already boost the rasterize flow, but that still runs on a single process, I still want to find a way that runs GDAL rasterize on python multiprocessing.</p><div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Building.crop_default_layer_by_rect(Google.mercator_cord)<span class="comment">#FILTER to speed up</span></span><br><span class="line">label=Building.generate(tiles)</span><br></pre></td></tr></table></figure></div><pre><code>  0%|          | 0/56 [00:00&lt;?, ?it/s]-----Set filter Rect: (12944152.11792486, 4852834.051769256, 12983287.876406869, 4818590.263097501)-----Start Generate.....100%|██████████| 56/56 [00:18&lt;00:00,  2.99it/s]</code></pre><p>If we write the ‘image’ &amp; ‘label’ to csv &#x2F; json that could be a great dataset for deep learning training workflow.</p><p>And we have finished that on the <a href="document/GuidetoStart.md">Process</a> workflow.<br>We could show the label&amp;image like that. </p><div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tifffile <span class="keyword">as</span> tif </span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">image=tif.imread(tiles[<span class="number">1</span>])</span><br><span class="line">label=tif.imread(label[<span class="number">1</span>])</span><br><span class="line">plt.imshow(image),plt.show()</span><br><span class="line">plt.imshow(label),plt.show()</span><br></pre></td></tr></table></figure></div><p><figure class="image-caption"><img                       lazyload                     src="/images/loading.svg"                     data-src="https://github.com/OOXXXXOO/DARTH/raw/master/document/output_9_0.png"                      alt="png"                ><figcaption>png</figcaption></figure></p><p><figure class="image-caption"><img                       lazyload                     src="/images/loading.svg"                     data-src="https://github.com/OOXXXXOO/DARTH/raw/master/document/output_9_1.png"                      alt="png"                ><figcaption>png</figcaption></figure></p><h3 id="update-log："><a href="#update-log：" class="headerlink" title="update log："></a>update log：</h3><ul><li><p>Version 0.1.0 change the CLI UI &amp; cancle the opencv requirement to simplify the install operation.</p></li><li><p>Version 0.0.9 Fix HTTP header bug for request url of Google mt1-mt6 resources.</p></li><li><p>Version 0.0.7 GDAL version limit is not friendly for user ,so i cancel the GDAL version require</p></li><li><p>Version 0.0.6 fix license problem &amp; call problem the root call function has been turn back to low case</p></li><li><p>Version 0.0.3 Test Sucessful &amp; Package Could be download  &amp; install huawei obs server automatically</p></li></ul><hr><h4 id="Neural-Network-for-GIS-let’s-fuck"><a href="#Neural-Network-for-GIS-let’s-fuck" class="headerlink" title="Neural Network for GIS , let’s fuck!"></a>Neural Network for GIS , let’s fuck!</h4><p><strong>Copyright 2020 Tom Winshare</strong></p><p>Licensed under the Apache License, Version 2.0 (the “License”);<br>you may not use this file except in compliance with the License.<br>You may obtain a copy of the License at</p><pre><code>http://www.apache.org/licenses/LICENSE-2.0</code></pre><p>Unless required by applicable law or agreed to in writing, software<br>distributed under the License is distributed on an “AS IS” BASIS,<br>WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<br>See the License for the specific language governing permissions and<br>limitations under the License.</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://github.com/OOXXXXOO/DARTH/raw/master/document/darth-04.png"                                     ></p>]]></content>
    
    
    <summary type="html">The Satellite Imagery DataSet is an important part to train, validate the deep learning model of different missions in modern GIS science.</summary>
    
    
    
    <category term="GIS" scheme="http://winshare.tech/categories/GIS/"/>
    
    
    <category term="GIS" scheme="http://winshare.tech/source/tags/GIS/"/>
    
    <category term="ComputerVision" scheme="http://winshare.tech/source/tags/ComputerVision/"/>
    
    <category term="Dataset" scheme="http://winshare.tech/source/tags/Dataset/"/>
    
  </entry>
  
  <entry>
    <title>Natural language models and strategic command systems</title>
    <link href="http://winshare.tech/2023/04/19/Natural%20language%20models%20and%20strategic%20command%20systems/"/>
    <id>http://winshare.tech/2023/04/19/Natural%20language%20models%20and%20strategic%20command%20systems/</id>
    <published>2023-04-19T13:07:26.134Z</published>
    <updated>2023-04-20T21:42:32.122Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>All philosophy is a critique of language - Wittgenstein</p></blockquote><h1 id="Strategy-Instructions"><a href="#Strategy-Instructions" class="headerlink" title="Strategy Instructions"></a>Strategy Instructions</h1><p>The components of strategy instructions are: conditions (signals) and actions. The core idea of strategy is “condition &#x3D;&gt; action”. Set any condition, and once it is met, trigger the trading action.</p><p>Common conditions include: price, assets, and time. Common actions include: buying and selling. With just these few elements, very rich trading strategies can be constructed. Whether good trigger conditions can be found, whether good actions can be taken under established conditions, and whether this process can continue to cycle and continue to profit - this is the embodiment of trading will in a quantified system. When people talk about quantification, they usually think of strategy first. It is the soul of the quantification system.</p><p><figure class="image-caption"><img                       lazyload                     src="/images/loading.svg"                     data-src="/images/Untitled.png"                      alt="Untitled"                ><figcaption>Untitled</figcaption></figure></p><p>A basic prototype of a quant trading system should include:</p><ul><li>Strategy system</li><li>Trading system</li><li>Intelligence system</li><li>Real-time data</li><li>Historical data</li></ul><p>The intelligence system includes trading data, factor data crawling, interface acquisition, and various alternative data factors, together forming the system’s data pool. From the perspective of Python, the data acquisition interface simply includes the following types.</p><hr><hr><h1 id="Relationship-between-Data-and-Instructions"><a href="#Relationship-between-Data-and-Instructions" class="headerlink" title="Relationship between Data and Instructions"></a><strong>Relationship between Data and Instructions</strong></h1><p>After obtaining the data and initial factor metadata in the previous step, they are usually highly structured and cannot be directly used for strategies. Functions and models for filtering, searching, aggregation, statistics, and other data processing exist, which have clear input, processing logic, and output. The corresponding relationships between these clear, specialized processing instructions and natural language are relatively simple and fixed.</p><p>For example:</p><div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">data = <span class="built_in">sum</span>(d0, d1, d2, d3)</span><br><span class="line">data = d0 + d1 + d2 + d3</span><br><span class="line"></span><br></pre></td></tr></table></figure></div><p>And similar expressions such as <strong>“get the sum of d0 to d3”</strong>, <strong>“sum up d0 to d3”</strong>, and <strong>“add d0 to d3”</strong> all have high semantic similarity. Therefore, the difficulty lies in the rules and generation of input and processing logic. The highest difficulty lies in the correspondence between natural language models and mathematical expressions, as well as logical expressions (which can be understood as pseudocode with fixed rules and templates). It is extremely difficult to generate and accumulate such data. Therefore, the design of this mathematical expression and logical expression system is the most fundamental and challenging work. On this basis, we need to introduce <strong>many concepts</strong>.</p><h1 id="First-Order-Logic"><a href="#First-Order-Logic" class="headerlink" title="First-Order Logic"></a><strong>First-Order Logic</strong></h1><p><figure class="image-caption"><img                       lazyload                     src="/images/loading.svg"                     data-src="/images/Untitled%201.png"                      alt="George Boole"                ><figcaption>George Boole</figcaption></figure></p><ul><li>George Boole</li></ul><p>First-order logic (FOL), also known as first-order predicate calculus, allows for quantification of statements and is a formal system used in mathematics, philosophy, linguistics, and computer science. FOL is a mathematical logic that distinguishes itself from higher-order logic by not allowing quantification over properties. Properties are characteristics of an object; therefore, a red object would be described as having the property of being red.</p><p>The language of logical programs is a subset of FOL because it is useful for many tasks. FOL can be viewed as a language for logical programs that can add disjunctions and explicit quantification. FOL is first-order because it allows for quantification over individuals in a domain. FOL neither allows for predicates to be variables nor allows for quantification over predicates.</p><p>Second-order logic allows for quantification over first-order relations and predicates whose arguments are first-order relations. These are all second-order relations. For example, the second-order logic formula</p><p>defines symmetry for second-order relations, and if its argument is a symmetric relation, it is true. FOL is recursively enumerable, which means that there is a complete proof procedure in which every true statement can be proven using a proof program on a Turing machine. Second-order logic is not recursively enumerable, so there is no complete proof procedure that can be implemented on a Turing machine.</p><p>Propositional logic deals only with simple propositional statements, while FOL also includes assertions and quantification.</p><p>An assertion is like a function that returns true or false. Consider the following sentences: “Socrates is a philosopher” and “Plato is a philosopher”. In propositional logic, the two sentences are considered as two unrelated propositions, simply labeled as p and q. However, in FOL, the two sentences can be represented using assertions in a more similar way. The assertion is Phil(a), which means a is a philosopher. Therefore, if a represents Socrates, Phil(a) is the first proposition - p; if a represents Plato, Phil(a) is the second proposition - q. A key point of FOL can be seen here: the string “Phil” is a grammatical entity, and its semantics are assigned by assigning it to be true when a is a philosopher. The assignment of a semantics is called an interpretation.</p><p>FOL allows for the use of variables to infer properties shared by many components. For example, let Phil(a) represent a philosopher, and let Schol(a) represent a scholar. Then, the formula represents that if a is a philosopher, then a is a scholar. The symbol is used to mark a conditional statement. The left side is the hypothesis, and the right side is the conclusion. The truth value of this formula depends on the element labeled as a and the interpretation of “Phil” and “Schol”.</p><p>For each a, assertions of the form “if a is a philosopher, then a is a scholar” require the use of variables and quantification. Once again, let Phil(a) represent a philosopher, and let Schol(a) represent a scholar. The FOL statement</p><p>represents that regardless of what a represents, if a is a philosopher, then a is a scholar. The universal quantifier represents a claim for “all” choices of a, and the statement in parentheses is an idea that is true.</p><p>To demonstrate that the assertion “if it is a philosopher, then it is a scholar” is false, it can be shown that there are philosophers who are not scholars. This can be</p><p>expressed using existential quantification. For example:</p><ul><li>¬(∀x)(Phil(x) → Schol(x))</li><li>¬(∀x)(Phil(x) ∧ ¬Schol(x))</li></ul><p>The negation operator ¬ is true if and only if the statement is false; in other words, if and only if a is not a scholar.<br>The conjunction operator ∧ indicates that a is a philosopher and not a scholar.</p><p>Assertions Phil(a) and Schol(a) both have only one argument. However, FOL can also represent assertions with more than one argument. For example, “There exist people who can be fooled at any time” can be represented as</p><p>Here, Person(x) is interpreted as x is a person, Time(y) is interpreted as y is a period of time, and Canfool(x,y) is interpreted as person x can be fooled at time y. Clearly, the statement represents that at least one person can be fooled at any time, which is stronger than the statement “At any time, there exists at least one person who can be fooled.” The latter does not imply that the person being fooled is always the same.</p><p>The <strong>scope</strong> of quantification is determined by the set of objects that can be used to satisfy quantification (in some of the informal examples in this section, the scope of quantification is not specified). In addition to specifying the meaning of assertion symbols such as Person and Time, an interpretation must also specify a non-empty set called the domain, which serves as the scope of quantification. Therefore, a statement of the form in a specific interpretation is true if there exist objects in the domain that can be used to assign meanings to the symbols Phil and Schol.</p><h1 id="Formation-Rules"><a href="#Formation-Rules" class="headerlink" title="Formation Rules"></a><strong>Formation Rules</strong></h1><p>Formation rules define the terms and formulas of first-order logic, which can be used to write a formal grammar for terms and formulas, because they are represented as sequences of symbols. These rules are usually context-free (the result of the rule has only a single symbol on the left-hand side), unless infinite sequences of symbols are allowed and there are many starting symbols, such as variables in terms.</p><ul><li><strong>Terms</strong></li></ul><p>Terms can be recursively defined according to the following rules:</p><ol><li><strong>Variables</strong>. Every variable is a term.</li><li><strong>Functions</strong>. Every expression <em>f</em>(<em>t</em>1, …, <em>tn</em>) with <em>n</em> parameters, where each <em>ti</em> is a term and <em>f</em> is a function symbol with <em>n</em> parameters, is a term. In addition, constant symbols are function symbols with 0 parameters, and therefore they are also terms.</li></ol><p>Only those expressions that can be obtained by applying the above rules a finite number of times are terms. For example, there are no terms containing predicate symbols.</p><ul><li><strong>Formulas</strong></li></ul><p>Formulas (or well-formed formulas) can be recursively defined according to the following rules:</p><ol><li><strong>Predicate Symbols</strong>. If <em>P</em> is an <em>n</em>ary predicate symbol and <em>t1</em>, …, <em>tn</em> are terms, then <em>P</em>(<em>t1</em>, …, <em>tn</em>) is a formula.</li><li><strong>Equality</strong>. If the equality symbol is part of the logic and <em>t1</em> and <em>t2</em> are terms, then <em>t1</em> &#x3D; <em>t2</em> is a formula.</li><li><strong>Negation</strong>. If <em>φ</em> is a formula, then ┐<em>φ</em> is a formula.</li><li><strong>Binary Connectives</strong>. If <em>φ</em> and <em>ψ</em> are formulas, then (<em>φ</em> ψ) is a formula. Other binary logical connectives can be defined similarly.</li><li><strong>Quantification</strong>. If <em>φ</em> is a formula and <em>x</em> is a variable, then and are formulas.</li></ol><p>Only those expressions that can be obtained by applying the above rules a finite number of times are formulas. Formulas obtained from the first two rules are called atomic formulas.</p><p>For example,</p><p>is a formula, where <em>f</em> is a unary function symbol, <em>P</em> is a unary predicate symbol, and <em>Q</em> is a ternary predicate symbol. On the other hand, is not a formula, although it is a string of symbols from the vocabulary.</p><p>The parentheses in the definition are used to ensure that any formula can only be obtained by recursively defining it in a single way (in other words, each formula has a unique parse tree). This property is called the <strong>unique readability</strong> of formulas. There are many conventions regarding where to use parentheses in formulas. For example, some authors use colons or dots instead of parentheses, or change the position of the parentheses. However, every author’s definition must be shown to satisfy unique readability.</p><p>The rules for defining formulas cannot define the “if-then-else” function <strong><code>ite(c, a, b)</code></strong>, where <em>c</em> is a condition represented by a formula, and <strong><code>ite(c, a, b)</code></strong> returns <em>a</em> if <em>c</em> is true and <em>b</em> if <em>c</em> is false. This is because both predicates and functions can only accept terms as their arguments, but the first argument of this function is a formula. Some languages built on top of first-order logic, such as SMT-LIB 2.0, allow such constructs.</p><p>SMT-LIB is an international initiative aimed at facilitating research and development in <a class="link"   href="http://en.wikipedia.org/wiki/Satisfiability_Modulo_Theories" >Satisfiability Modulo Theories <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> (SMT). Since its inception in 2003, the initiative has pursued these aims by focusing on the following concrete goals.</p><ul><li>Provide standard rigorous descriptions of background theories used in SMT systems.</li><li>Develop and promote common input and output languages for <a class="link"   href="http://en.wikipedia.org/wiki/Satisfiability_Modulo_Theories#SMT_solvers" >SMT solvers <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>.</li><li>Connect developers, researchers and users of SMT, and develop a community around it.</li><li>Establish and make available to the research community a large library of benchmarks for SMT solvers.</li><li>Collect and promote software tools useful to the SMT community.</li></ul><p>This website provides access to the following main artifacts of the initiative.</p><ul><li>Documents describing the SMT-LIB input&#x2F;output language for SMT solvers and its semantics;</li><li>Specifications of background theories and <em>logics</em>;</li><li>A large library of input problems, or benchmarks, written in the SMT-LIB language.</li><li>Links to SMT solvers and related tools and utilities.</li></ul><p><a class="link"   href="http://theory.stanford.edu/~nikolaj/programmingz3.html" >Programming Z3 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p><p>The Z3 engine is an efficient symbolic reasoning tool that was initially used for theorem proving and symbolic verification. However, its powerful features are now being applied in various fields.</p><p>To learn Z3, one first needs to understand how it does theorem proving (its original purpose), and then see how it can be applied to other fields.</p><p>In 1990, Halpern, J. Y. proposed two methods for solving probabilistic first-order logic. In 1998, Chiara Ghidini also proposed Distributed First Order Logic for use in distributed knowledge representation and reasoning systems (DKRS). In 2002, Anand Ranganathan Æ Roy H. Campbell used first-order logic for background-aware systems to represent information that cannot be quantified. In 2012, Fitting, M. applied first-order logic to automatic theorem proving.</p><p>With the help of the tools mentioned above, definitions, and formulas, we can say that as long as we have first-order logic, the results obtained, and the set of composite logics can convert structured (low degrees of freedom) natural language into corresponding data processing logic and executable strategies within a limited scope, which is no longer impossible to achieve.</p><h1 id="Natural-Language-Modeling"><a href="#Natural-Language-Modeling" class="headerlink" title="Natural Language Modeling"></a><strong>Natural Language Modeling</strong></h1><p><figure class="image-caption"><img src="/images/Untitled%202.png" alt="/images/Untitled%202.png"><figcaption>/images/Untitled%202.png</figcaption></figure></p><p>In reality, a natural language model that can completely replace human communication and semantic parsing has not yet been developed. Therefore, it is unnecessary to pursue the ability to process relatively contextually dependent and complex languages. Through large-scale language corpus training, the model can achieve natural language semantic parsing and convert it into a set of first-order logic in a relatively structured (lower degree of freedom) natural language environment.</p><p>We often say “don’t speak incoherently, be coherent and cohesive,” meaning that the context of the vocabulary should have semantic coherence. Based on the coherence of natural language, the language model predicts the next word based on the previous words. If the parameters of the language model are correct and the word vectors of each word are set correctly, the language model’s predictions should be relatively accurate. With countless articles in the world, training data is endless. However, context dependency means that you cannot obtain enough information from just one sentence. So, what is this information?</p><p>For example, when we use a regular voice assistant to say “call my wife,” “call my mother,” “call my father,” the predicate “call(x)” is first parsed as an item (function). The term “wife,” “mother,” “father,” and so on are then parsed as items (variables). As previously mentioned, <strong>items and formulas are represented as a string of symbols, and these rules can be used to write a formal grammar for items and formulas. These rules are usually context-free. Otherwise, there will be an infinite number of symbols.</strong></p><p>Therefore, we begin to compare symbols with existing symbols. For example, the function call() needs to know the phone number property of the input item, so it is reasonable to use “wife,” “mother” to refer to items in the symbol library. Thus, the matching is completed. The entire chain also works. We can also understand that if we use “Zhang San” or “Li Si” to refer to the item designated for dad, it will be impossible to complete the matching work without context (and there should be no context). This is the great difficulty of modern NLP compared to humans. Every normal person’s brain has a very large, fully trained context-dependent symbol system, and it is extremely difficult for a computer based on von Neumann architecture to have the same symbol system. This is also why modern language models like GPT-3 have already reached a parameter volume that home computers cannot handle. The larger the symbol system, the more connections between symbols, and the better the model’s performance. Therefore, after BERT, almost all models use pre-training. These pre-training models basically represent a basic symbol system. Based on this complete and massive symbol system, the learning difficulty and computational complexity of building larger symbol systems will be greatly reduced.</p><p>Therefore, once we have a clear understanding, we can find that by specifying the grammar rules on the input end and having a well-designed code (functions and symbol system) on the execution end, <em><strong>processing rule-based natural language into a string of executable functions is achievable.</strong></em></p><p>So, HOW?</p><h1 id="Translation-Model-OR-Generation-Model"><a href="#Translation-Model-OR-Generation-Model" class="headerlink" title="Translation Model OR Generation Model"></a><strong>Translation Model OR Generation Model</strong></h1><p>We should be clear that the few-shot learning capability of GPT-3 is not universal. Although the model has impressed people with its learning of complex tasks and patterns, it can still fail. For example, even after seeing 10,000 examples, it cannot solve a simple task like reversing a string. It is essentially a network of nodes connected in a high-dimensional word embedding space. GPT-3 transforms the input words into high-dimensional space nodes in the network as a starting point and continuously searches for shortcuts to reach the next node, which is its perceptual world. In fact, it is only trying to understand the language dimension of humans and cannot understand the perceptual cognitive dimension of humans. This is the limitation of GPT-3 that cannot be broken no matter how much the model is expanded.</p><p>However, we should also know that our needs do not actually require the model to be intelligent to any extent.</p><p>From the conventional perspective, we have two seemingly feasible technical routes:</p><ul><li>NLP translation model</li></ul><p><strong><a class="link"   href="https://github.com/huggingface/transformers" >GitHub - huggingface&#x2F;transformers: 🤗 Transformers: State-of-the-art Natural Language Processing for Pytorch, TensorFlow, and JAX. <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></strong></p><ul><li>NLU&#x2F;NLG generation model</li></ul><p><strong><a class="link"   href="https://github.com/charlesXu86/Chatbot_CN" >GitHub - charlesXu86&#x2F;Chatbot_CN: A chatbot based on finance-judiciary domain (with casual chat nature), whose main modules include information extraction, NLU, NLG, knowledge graph, etc., and integrated frontend display with Django. It has currently encapsulated nlp and kg’s restful interfaces. <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></strong></p><p>However, generally speaking, translation models have a higher probability of failure in grammar and logic after translation, and due to the much lower fault tolerance of first-order logic than natural language, the drawbacks of translation models in this task are obvious. For example, “I don’t want to eat apples.” and “I don’t eat apples.” The subtle semantic differences between these two sentences can be ignored in daily conversations, but from the perspective of logic, the semantic differences between “not,” “cannot,” and “do not want” are significant and require three separate functions to describe. The input and matching confusion in this process makes the requirement for humans very high after translation and the usability of the entire process very low.</p><p>Thus, we can understand that the core of the entire process becomes a dialogue system based on NLU, NLG, and an application layer composed of symbolic system sets. As we gradually clarify this technical solution, we can provide the following basic system structure:</p><ol><li><p>Data Layer: Dialogue business data, open-source multi-turn dialogue data, etc.</p></li><li><p>Algorithm Layer: Syntactic analysis, fine-grained analysis, entity extraction, query error correction, etc.</p></li><li><p>Capability Layer: Natural Language Understanding, Dialogue Management, Dialogue Strategy, Strategy Optimization, Dialogue Factory</p></li><li><p>Application Layer: Real-time&#x2F;historical data aggregation, statistics, analysis, visualization, backtesting, live trading</p></li></ol><p>In the data layer and application layer, the financial data, factor library data, and the system’s own database are used as support.</p><h1 id="New-Chapter-GPT4"><a href="#New-Chapter-GPT4" class="headerlink" title="New Chapter - GPT4"></a>New Chapter - GPT4</h1><p>The publish of chatgpt is new phase of artificial intelligence,  and GPT4 bring multi-modal capability in dialogue system. It have potential to revolute whole finance system.</p><p>GPT series’ capabilities are mainly reflected in the following aspects:</p><ol><li>After performing Preprompt preprocessing, GPT can have a primary logical reasoning ability that meets requirements. Although this ability is unstable, when combined with frameworks like Wolfram, its reasoning and scientific computing capabilities will be greatly expanded.</li><li>In dealing with unstructured natural language data problems, GPT has excellent analysis and restructuring abilities, enabling a vast amount of human data to be used. It can effectively transform multimodal data into structured semantics.</li><li>When faced with multi-stage problems, GPT can effectively handle task scheduling and sequencing to help design an instruction architecture that meets system requirements. Many projects have begun to demonstrate their capabilities in this area.</li></ol><p>For example:</p><p>AutoGPT:</p><p><strong><a class="link"   href="https://github.com/Significant-Gravitas/Auto-GPT" >https://github.com/Significant-Gravitas/Auto-GPT <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></strong></p><p>Microsoft Jarvis:</p><p><strong><a class="link"   href="https://github.com/microsoft/JARVIS" >https://github.com/microsoft/JARVIS <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></strong></p><p>These two projects have extensively explored the potential of LLM Server as the core of a task system. For example, in the Jarvis project:</p><p>We introduce a collaborative system that consists of <strong>an LLM as the controller</strong> and <strong>numerous expert models as collaborative executors</strong> (from HuggingFace Hub). The workflow of our system consists of four stages:</p><ul><li><strong>Task Planning</strong>: Using ChatGPT to analyze the requests of users to understand their intention, and disassemble them into possible solvable tasks.</li><li><strong>Model Selection</strong>: To solve the planned tasks, ChatGPT selects expert models hosted on Hugging Face based on their descriptions.</li><li><strong>Task Execution</strong>: Invokes and executes each selected model, and return the results to ChatGPT.</li><li><strong>Response Generation</strong>: Finally, using ChatGPT to integrate the prediction of all models, and generate responses.</li></ul><p><figure class="image-caption"><img                       lazyload                     src="/images/loading.svg"                     data-src="/images/Untitled%203.png"                      alt="Untitled"                ><figcaption>Untitled</figcaption></figure></p><h1 id="Resources"><a href="#Resources" class="headerlink" title="Resources:"></a>Resources:</h1><p><a class="link"   href="https://github.com/tokenmill/awesome-nlg" >GitHub - tokenmill&#x2F;awesome-nlg: A curated list of resources dedicated to Natural Language Generation (NLG) <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p><p><a class="link"   href="https://github.com/keon/awesome-nlp" >GitHub - keon&#x2F;awesome-nlp: A curated list of resources dedicated to Natural Language Processing (NLP) <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p><h1 id="Reference："><a href="#Reference：" class="headerlink" title="Reference："></a>Reference：</h1><ol><li>Andreas Fröhlich, Armin Biere, Christoph M. Wintersteiger, Youssef Hamadi: <a class="link"   href="http://research.microsoft.com/apps/pubs/default.aspx?id=238374" >Stochastic Local Search for Satisfiability Modulo Theories <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>. AAAI 2015.</li><li>Nikolaj Bjørner and Anh-Dung Phan and Lars Fleckenstein. <em><a class="link"   href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/nbjorner-nuz.pdf" >nu-Z: An Optimizing SMT Solver <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>.</em> TACAS April 2015.</li><li>Nikolaj Bjørner and Arie Gurfinkel.<em><a class="link"   href="https://arieg.bitbucket.io/pdf/polypdr.pdf" >Property Directed Polyhedral Abstraction. <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> VMCAI 2015.</em></em></li><li>Aleksandar Zeljic, Christoph M. Wintersteiger, and Philipp Rümmer. <a class="link"   href="http://research.microsoft.com/apps/pubs/default.aspx?id=225014" >Approximations for Model Construction <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>. IJCAR 2014.</li><li>Markus N. Rabe, Christoph M. Wintersteiger, Hillel Kugler, Boyan Yordanov, and Youssef Hamadi. <a class="link"   href="http://research.microsoft.com/apps/pubs/default.aspx?id=225014" >Symbolic Approximation of the Bounded Reachability Probability in Large Markov Chains <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>. QEST 2014.</li><li>Nikolaj Bjørner and Anh-Dung Phan. <em><a class="link"   href="http://research.microsoft.com/en-US/people/nbjorner/scss2014.pdf" >newZ: Maximal Satisfaction with Z3. <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></em> Invited paper, <a class="link"   href="http://www.easychair.org/smart-program/SCSS2014/" >in SCSS 2014 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>.</li><li>Josh Berdine and Nikolaj Bjørner. <em>Computing All Implied Equalities via SMT-based Partition Refinement. IJCAR 2014. <a class="link"   href="http://research.microsoft.com/apps/pubs/default.aspx?id=215371" >Technical Report <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>.</em></li><li>Margus Veanes, Nikolaj Bjørner, Lev Nachmanson and Sergey Bereg.<em><a class="link"   href="http://research.microsoft.com/apps/pubs/default.aspx?id=217107" >Monadic Decomposition. <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> CAV 2014.</em></li><li>Shachar Itzhaky, Nikolaj Bjørner, Thomas Reps, Mooly Sagiv, and Aditya Thakur.<em><a class="link"   href="http://digital.library.wisc.edu/1793/69022" >Property Directed Shape Analysis <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>. CAV 2014.</em></li><li>Nuno Lopes, Nikolaj Bjorner, Patrice Godefroid, Karthick Jayaraman, and George Varghese. *<a class="link"   href="http://research.microsoft.com/apps/pubs/default.aspx?id=215431" >Checking beliefs in Dynamic Networks*. <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> <em>Technical Report. Revised version to appear in NSDI 2015.</em></li><li>Thomas Ball, Nikolaj Bjørner, Aaron Gember, Shachar Itzhaky, Aleksandr Karbyshev, Mooly Sagiv, Michael Schapira and Asaf Valadarsky.<em><a class="link"   href="http://agember.com/docs/ball2014vericon.pdf" >VeriCon: Towards Verifying Controller Programs in Software-Defined Networks <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>. PLDI 2014</em></li><li>Nikolaj Bjørner, Konstantin Korovin, Arie Gurfinkel and Ori Lahav.<em><a class="link"   href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/nbjorner-zipint.pdf" >Instantiations, Zippers and EPR Interpolation <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>. Short paper at <a class="link"   href="http://lpar-19.info/" >LPAR 19 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>.</em></li><li>Josh Berdine, <em>Nikolaj Bjørner,</em> Samin Ishtiaq, Jael E. Kriener, Christoph Wintersteiger.<a class="link"   href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/nbjorner-rr-lpar19.pdf" >Resourceful Reachability as HORN-LA <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>. <em>LPAR 19.</em></li><li>Nikolaj Bjørner, Ken McMillan and Andrey Rybalchenko.<em><a class="link"   href="http://arxiv.org/abs/1306.5264" >Higher-order Program Verification as Satisfiability Modulo Theories with Algebraic Data-types <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>. In informal proceedings of HOPA 2013 (workshop on Higher-Order Program Analysis).</em></li><li>Nikolaj Bjørner, Ken McMillan and Andrey Rybalchenko.<em>On Solving Universally Quantified Horn Clauses</em>. SAS 2013</li><li>Nikolaj Bjørner, Ken McMillan, Andrey Rybalchenko.<a class="link"   href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/nbjorner-bmr-smt.pdf" >Program Verification as Satisfiability Modulo Theories <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>. SMT workshop 2012. <a class="link"   href="http://research.microsoft.com/en-us/people/nbjorner/smt-2012-7-1.pptx" >Slides <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></li><li>Nikolaj Bjørner, Vijay Ganesh, Raphael Michel, Margus Veanes. <a class="link"   href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/nbjorner-smtlibstr.pdf" >An SMT-liB Format for Sequences and Regular Expressions. <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> SMT workshop 2012.</li><li>Leonardo de Moura and Grant Passmore. <em>Computation in real closed infinitesimal and transcendental extensions of the rationals</em>. In Automated Deduction - CADE-24, 24th International Conference on Automated Deduction, Lake Placid, New York, June 9-14, 2013, Proceedings, 2013.</li><li>Leonardo de Moura and Grant Passmore. <em>The Strategy Challenge in SMT Solving</em>, volume 7788 of <em>Lecture Notes in Artificial Intelligence</em>. Springer, 2013. [.<a class="link"   href="http://leodemoura.github.io/files/smt-strategy.pdf" >pdf <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>]</li><li>Leonardo de Moura and Dejan Jovanović. A model-constructing satisfiability calculus. In <em>14th International Conference on Verification, Model Checking, and Abstract Interpretation, VMCAI, Rome, Italy, 2013</em>, 2013. [ <a class="link"   href="http://leodemoura.github.io/files/mcsat.pdf" >.pdf <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> ]</li><li>Dejan Jovanović and Leonardo de Moura. Solving non-linear arithmetic. In <em>Automated Reasoning - 6th International Joint Conference, IJCAR 2012, Manchester, UK, June 26-29, 2012. Proceedings</em>, volume 7364 of <em>Lecture Notes in Computer Science</em>, pages 339-354. Springer, 2012. [ <a class="link"   href="http://csl.sri.com/users/dejan/papers/jovanovic-ijcar2012.pdf" >.pdf <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> ]</li><li>Dejan Jovanović and Leonardo de Moura. Solving non-linear arithmetic. Technical Report MSR-TR-2012-20, Microsoft Research, 2012. [ <a class="link"   href="http://research.microsoft.com/apps/pubs/default.aspx?id=159549" >http <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> ]</li><li>Nikolaj Bjørner. Taking Satisfiability to the Next Level with Z3. IJCAR 2012.</li><li>Anh-Dung Phan, Nikolaj Bjørner, David Monniaux. Anatomy of Alternating Quantifier Satisfiability. SMT workshop 2012. [ <a class="link"   href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/nbjorner-qt-smt2012.pdf" >.pdf <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> ]</li><li>Krystof Hoder and Nikolaj Bjørner. Generalized Property Directed Reachability. In SAT 2012. [<a class="link"   href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/nbjorner-z3pdr.pdf" >.pdf <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>]</li><li>Christoph Wintersteiger, Youssef Hamadi, and Leonardo de Moura. Efficiently solving quantified bit-vector formulas. <em>Formal Methods in System Design</em>, 2012. [ <a class="link"   href="http://dx.doi.org/10.1007/s10703-012-0156-2" >http <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> | <a class="link"   href="http://leodemoura.github.io/files/ufbv_journal.pdf" >.pdf <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> ]</li><li>Nikolaj Bjørner and Leonardo de Moura. Tractability and Modern Satisfiability Modulo Theories Solvers. In <em>Handbook of Tractability</em>. Cambridge University Press, 2012. [.pdf]</li><li>Krystof Hoder, Nikolaj Bjørner, and Leonardo de Moura. muZ - an efficient engine for fixed points with constraints. In <em>Computer Aided Verification - 23rd International Conference, CAV 2011, Snowbird, UT, USA, July 14-20, 2011. Proceedings</em>, volume 6806 of <em>Lecture Notes in Computer Science</em>, pages 457-462, 2011. [<a class="link"   href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/nbjorner-z3fix.pdf" >.pdf <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>]</li><li>Leonardo de Moura and Nikolaj Bjørner. Satisfiability modulo theories: introduction and applications. <em>Commun. ACM</em>, 54(9):69-77, 2011. [ <a class="link"   href="http://dl.acm.org/citation.cfm?id=1995394" >http <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> ]</li><li>Dejan Jovanović and Leonardo de Moura. Cutting to the chase solving linear integer arithmetic. In <em>Automated Deduction - CADE-23 - 23rd International Conference on Automated Deduction, Wroclaw, Poland, July 31 - August 5, 2011. Proceedings</em>, volume 6803 of <em>Lecture Notes in Computer Science</em>, pages 338-353. Springer, 2011. [ <a class="link"   href="http://leodemoura.github.io/files/cutsat.pdf" >.pdf <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> ]</li><li>Maria Paola Bonacina, Christopher Lynch, and Leonardo de Moura. On deciding satisfiability by theorem proving with speculative inferences. <em>J. Autom. Reasoning</em>, 47(2):161-189, 2011. [ <a class="link"   href="http://leodemoura.github.io/files/JAR2010dpllSPsi.pdf" >.pdf <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> ]</li></ol>]]></content>
    
    
    <summary type="html">The publish of chatgpt is new phase of artificial intelligence,  and GPT4 bring multi-modal capability in dialogue system. It have potential to revolute whole finance system.....</summary>
    
    
    
    <category term="Quantitative trading" scheme="http://winshare.tech/categories/Quantitative-trading/"/>
    
    
    <category term="NLP" scheme="http://winshare.tech/source/tags/NLP/"/>
    
    <category term="CommandSystem" scheme="http://winshare.tech/source/tags/CommandSystem/"/>
    
    <category term="GPT" scheme="http://winshare.tech/source/tags/GPT/"/>
    
    <category term="Quantitative trading" scheme="http://winshare.tech/source/tags/Quantitative-trading/"/>
    
  </entry>
  
</feed>
