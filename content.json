{"meta":{"title":"Winshare","subtitle":"Winshare 's Blog","description":"Research about HCI/CG/VR/AR","author":"Tom winshare","url":"http://winshare.tech"},"pages":[{"title":"About","date":"2017-03-20T12:57:33.000Z","updated":"2017-09-29T08:27:49.395Z","comments":true,"path":"about/index.html","permalink":"http://winshare.tech/about/index.html","excerpt":"","text":"Here is Winsahre ‘s Blog"},{"title":"Friends Links","date":"2017-05-06T11:56:21.237Z","updated":"2017-05-06T11:56:21.237Z","comments":true,"path":"friends/index.html","permalink":"http://winshare.tech/friends/index.html","excerpt":"","text":""},{"title":"tags","date":"2017-11-25T14:29:33.000Z","updated":"2017-11-25T14:29:33.624Z","comments":true,"path":"tags/index.html","permalink":"http://winshare.tech/tags/index.html","excerpt":"","text":""},{"title":"categories","date":"2017-11-25T14:28:08.000Z","updated":"2017-11-25T14:28:08.670Z","comments":true,"path":"categories/index.html","permalink":"http://winshare.tech/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"Monte-carlo Ray tracer system(1) design ,theory, struct and build.","slug":"Monte-Carlo Ray Tracing System (一)原理以及架构设计","date":"2017-09-21T04:29:44.521Z","updated":"2017-11-25T14:08:44.715Z","comments":true,"path":"2017/09/21/Monte-Carlo Ray Tracing System (一)原理以及架构设计/","link":"","permalink":"http://winshare.tech/2017/09/21/Monte-Carlo Ray Tracing System (一)原理以及架构设计/","excerpt":"实时全局光照对于现在的CG相关行业来说 就如同一个待跨越的圣杯一样。而在GPU不断进步的过程中，我们却对实现全局光照越来越没有信心 。性能不够也是我们最常在嘴上提到的词语但是可以说其核心原理早就实现了 在这些年其核心原理并没有取得很大的突破这也是现阶段无法实现实时全局光照的原因之一。","text":"实时全局光照对于现在的CG相关行业来说 就如同一个待跨越的圣杯一样。而在GPU不断进步的过程中，我们却对实现全局光照越来越没有信心 。性能不够也是我们最常在嘴上提到的词语但是可以说其核心原理早就实现了 在这些年其核心原理并没有取得很大的突破这也是现阶段无法实现实时全局光照的原因之一。 对待这样一个系统来说 我们要先从原理说起也就是Monte-Carlo 数值积分。因此第一篇文章着重于算法和设计 具体的代码将不会很多。 Chapter （1）从 \\int_{0}^{1}x^{2}dx=\\frac{1}{3}说起在通常的过程中 对于这样一个简单的定积分我们人脑的求解过程是以固定的微分积分公式计算，公式虽然能方便计算出定积分的精确值，但是有一个局限就是要首先通过不定积分得到被积函数的原函数。有的时候，求原函数是非常困难的，而有的函数，如 f(x) = \\frac{\\sin x}{x}，已经被证明不存在初等原函数，这样，就无法用Newton-Leibniz公式，只能另想办法。 我们以$y&lt;(x^2)$作为判断依据去划分区域来判断区域划分 再通过随机生成的点去重复的做判断 当随机点数量到达一定之后 我们以两个区域的点的数量作为依据 即可得出结果 且点数越多误差越小根据伯努利大数法则：事件发生的频率依概率收敛于事件的概率p 如下图： 而一般来讲Monte Carlo方法虽然可以解决很多疑难杂症 但是对于复杂度要求极高的光线追踪领域 其结果十分惊艳 但并不能够称之为一个十分简洁的算法 下面我们进入下一章 光我们在其他文章中讲到了光照模型这一概念 然而应用在传统的实时渲染领域 光照模型则是一个相对高效但是低质的概念 所在实时渲染领域 其多数是考虑怎么尽量的使用障眼法去得到一个更逼近数值积分方法的结果 在洪培技术预计算的技术发展方面 类似于UE4的静态效果 Paris demo 在美术和实时光照技术的双重作用下 其效果已经达到了现有计算条件下画质的巅峰 但是相比真正的全局光照，效果仍旧差了一些。也许会有人说 如此大的代价 去提升那20-30%的画质 值不值得 ？ 当然值得！！在讲解下一章之前我们来了解一下传统的光栅化渲染技术 什么是光栅化？什么是光栅？光栅是光学中一种常见的概念 意为大量等距平行狭缝然而在实际中光栅化的意义接近于像素化，离散化；用已知概念去理解 类似于透过纱窗去看外面的世界传统构成三维观察方法常用的为等轴测投影和透视投影。 首先要讨论的是如何把一个三维模型的数据集绘制成相应的模型 这个阶段其实在《Real time Rending》这本书和之前的文章里介绍的很清楚了 渲染管线的基础结构分为： 1.Application应用阶段需要渲染的几何体从一个固定的数据结构被传递到几何阶段。这传递过去的东西被称为图元，例如点、线、三角形，这些图元有可能最终显示到屏幕上。这是应用阶段最重要的任务。由软件实现的应用阶段的问题可能在于，它不能像几何和光栅化阶段那样划分为多个子阶段。但是，为了提高性能，这一阶段经常是由多核并行执行。在设计中，这称之为超标量体系， 2.Geometry几何阶段在这个阶段一般是对模型进行视图变换 对操作进行响应 对顶点进行着色 投影 裁剪和屏幕映射 相应的例如变换过程如下 如裁剪过程 裁剪之后的图像 还不能用来显示 现代操作系统的图像大多数运行在窗口之下 所以针对已经计算好的显示方式来说还需要最后一步 那就是图像帧对屏幕相应区域的映射 过程如下图： 从另一个角度我们也可以考虑到 为什么全屏运行的游戏 效果会更好一些 这与省略了映射阶段也有着一定的关系 3.Rasterizer光栅器在这个阶段的细分任务中我们算是可以看出这些效果的成因 渲染的过程大致相当于： 至于牵扯到具体的光效 ，阴影 等信息着色器就开始担当大任啦具体可见：着色器部分 讲完了光栅化体系 我们可以看得到 其效果都是由理论模型模拟效果 效率在现在的光栅化芯片加持下 还算不错 在好的硬件中如GTX1080Ti 甚至能把一个4K 的普遍场景渲染到120Hz 但是在大多数作品中 我们不可能达到非常好的效果 因为即使类似Unreal Paris demo这种 预渲染的效果 已经计算好了光照 美术和设计还有着色器方面的设计要求实在是太高了 那么 我们实现实时全局光照的意义在哪里？ 举个例子 如果在一个场景之下 我们对一个像素需要30条光线来收敛 以最小的720p 也就是1280720分辨率 再加上60hz的刷新率 可以看到每秒钟需要处理的光线数量达到了*16亿5000万条 那我们以一个正常效果的收敛来计算收敛采样数为200 1080p分辨率 60hz刷新率每秒钟需要处理的光线数量达到了248亿 不得不承认在传统的SIMD GPU架构上光线追踪的效率被大大折扣 因此移动GPU巨头 多年为苹果设计GPU的Imagination甚至收购了一些企业 制作了光线追踪加速卡 以至于我们可以在移动端的功耗前提下实现稳定的光线追踪技术以下为相应的架构图 而我们再看看SIMD 因此实时光线追踪绝不是遥不可及的技术 但是仅仅这些我们不足以对光线追踪产生如此大的兴趣 因此实时光线追踪的好处甚至包含了准确反映光的衍射，色散，等等光学特性 这在传统体系之下几乎是无法做到的 最终结合计算物理中的流体模拟，动力学模拟，甚至量子物理模拟 在计算机中建立一个完全拟真的世界 永远是人类为之努力的目标很庆幸的是 这其中很多技术都取得了关键突破 Chapter（2）1979年，TurnerWhitted在光线投射的基础上，加入光与物体表面的交互，是光线在物体表面沿着反射，折射以及散射方式上继续传播，直到与光源相交这一方法后来也被称为经典光线跟踪方法、递归式光线追踪（Recursive Ray Tracing）方法，或 Whitted-style 光线跟踪方法。 其主要思想是从视点向成像平面上的像素发射光线，找到与该光线相交的最近物体的交点，如果该点处的表面是散射面，则计算光源直接照射该点产生的颜色；如果该点处表面是镜面或折射面，则继续向反射或折射方向跟踪另一条光线，如此递归下去，直到光线逃逸出场景或达到设定的最大递归深度。by浅墨 原理：我们如果能看到一个物体的某个点 这个点必然反射/折射了光线而对于光线追踪这个过程本身来讲就像是自然世界的逆过程，朝着我们能看到的所有点发射光线，追踪次光线（shadow ,reflection ,refraction）。必然能够回到光源。 图中的几个部分分别说明了 对象的表示 光线的求解方式相交的求解方式 等等 我们分公式来举例说明一下每个公式怎样用代码求解 基础定义类三位向量运算类123456789101112131415161718192021222324252627282930313233343536373839404142434445template&lt;typename T&gt;class Vec3&#123;public: T x, y, z; Vec3() : x(T(0)), y(T(0)), z(T(0)) &#123;&#125; Vec3(T xx) : x(xx), y(xx), z(xx) &#123;&#125; Vec3(T xx, T yy, T zz) : x(xx), y(yy), z(zz) &#123;&#125; //正规化 Vec3&amp; normalize() &#123; T nor2 = length2(); if (nor2 &gt; 0) &#123; T invNor = 1 / sqrt(nor2); x *= invNor, y *= invNor, z *= invNor; &#125; return *this; &#125; //运算定义 Vec3&lt;T&gt; operator * (const T &amp;f) const &#123; return Vec3&lt;T&gt;(x * f, y * f, z * f); &#125; //标量*向量 Vec3&lt;T&gt; operator * (const Vec3&lt;T&gt; &amp;v) const &#123; return Vec3&lt;T&gt;(x * v.x, y * v.y, z * v.z); &#125; //向量1*向量2 T dot(const Vec3&lt;T&gt; &amp;v) const &#123; return x * v.x + y * v.y + z * v.z; &#125; //点积 Vec3&lt;T&gt; operator - (const Vec3&lt;T&gt; &amp;v) const &#123; return Vec3&lt;T&gt;(x - v.x, y - v.y, z - v.z); &#125; //向量1-向量2 Vec3&lt;T&gt; operator + (const Vec3&lt;T&gt; &amp;v) const &#123; return Vec3&lt;T&gt;(x + v.x, y + v.y, z + v.z); &#125; //向量1+向量2 Vec3&lt;T&gt;&amp; operator += (const Vec3&lt;T&gt; &amp;v) &#123; x += v.x, y += v.y, z += v.z; return *this; &#125; //向量自增 Vec3&lt;T&gt;&amp; operator *= (const Vec3&lt;T&gt; &amp;v) &#123; x *= v.x, y *= v.y, z *= v.z; return *this; &#125; //向量自乘 Vec3&lt;T&gt; operator - () const &#123; return Vec3&lt;T&gt;(-x, -y, -z); &#125; //求负 T length2() const &#123; return x * x + y * y + z * z; &#125; //模^2 T length() const &#123; return sqrt(length2()); &#125; //模 friend std::ostream &amp; operator &lt;&lt; (std::ostream &amp;os, const Vec3&lt;T&gt; &amp;v) &#123; os &lt;&lt; \"[\" &lt;&lt; v.x &lt;&lt; \" \" &lt;&lt; v.y &lt;&lt; \" \" &lt;&lt; v.z &lt;&lt; \"]\"; return os; &#125;&#125;; 当然 这是较为精简的写法和部分运算 下篇文章中 我们将着重来尝试优化渲染效率和效果 但是其中涉及的复杂运算不利于基础概念的理解 所以我们用比较基础的运算来说明 同时按照图中顺序 我们将对这整个过程作一个说明 Sphere / Ray intersection (给出光线和球的表达式 求相交)Sphere equation/三维向量的球面表达式 可以想象球面点到球心的差的平方为半径的平方\\left ( \\vec{p}-\\vec{c} \\right )\\cdot \\left ( \\vec{p}-\\vec{c} \\right )=r^{2}123456789101112131415Vec3f center; /// position of the spherefloat radius, radius2; /// sphere radius and radius^2Vec3f surfaceColor, emissionColor; /// surface color and emission (light)float transparency, reflection; /// surface transparency and reflectivitySphere( const Vec3f &amp;c, const float &amp;r, const Vec3f &amp;sc, const float &amp;refl = 0, const float &amp;transp = 0, const Vec3f &amp;ec = 0) : center(c), radius(r), radius2(r * r), surfaceColor(sc), emissionColor(ec), transparency(transp), reflection(refl)&#123; /* empty */ &#125; Ray equation\\vec{r}\\left ( t \\right )=\\vec{o}+t\\vec{d}这个应该就不用说了 发射点向量和发射的方向向量 仅需要两个参数12const Vec3f &amp;rayorig; const Vec3f &amp;raydir; Intersection(1) \\left ( \\vec{o}+t\\vec{d}-\\vec{c} \\right )\\cdot \\left ( \\vec{o}+t\\vec{d}-\\vec{c} \\right )= r^{2}or t^{2}\\left ( \\vec{d}\\cdot \\vec{d} \\right )+2\\left ( \\vec{o}-\\vec{c} \\right )t\\vec{d}+ \\left ( \\vec{o}-\\vec{c} \\right )\\cdot \\left ( \\vec{o}-\\vec{c} \\right )-r^{2}=0 值得注意的是 intersect是定义在结构体当中的 并非独立 而最终判断是否相交需要bool类型做判断 即判断给定光线和给定球体是否相交 123456789101112bool intersect(const Vec3f &amp;rayorig, const Vec3f &amp;raydir, float &amp;t0, float &amp;t1) const&#123; Vec3f l = center - rayorig; float tca = l.dot(raydir); if (tca &lt; 0) return false; float d2 = l.dot(l) - tca * tca; if (d2 &gt; radius2) return false; float thc = sqrt(radius2 - d2); t0 = tca - thc; t1 = tca + thc; return true;&#125; 当然 这仅仅是与球体的相交检验 更多的 和各种几何体和各种网格的检验代码 我们将在以后的文章中提及 Illumination Equation(光照方程)在上图中 Blin-Phone 光照方程如下 I=k_{a}I_{a}+I_{i}\\left ( k_{d}\\left ( \\vec{L}\\cdot \\vec{N} \\right )+k_{s} \\left ( \\vec{V}\\cdot \\vec{R} \\right )^{n} \\right )+k_{t}I_{t}+k_{r}I_{r}$I{a}K{a}$为递归元素 但是我们作为基本传参的方程样式应该是渲染方程中的 猛地一看这么长确实很懵逼 现在市面上很多的书籍教材都不会对参数做详解所以就需要我们把这个渲染方程分开来看 看看每一部分到底代表什么 事实上 我们也可以发现 渲染方程都是分开求解的 最后的结果是所有光照类型部分结果的总和 1. （环境光）$I{amb}=k{a}I_{a}$$I{a}$是环境光的强度$k{a}$代表表面环境光反射率在0-1之间但是在基本的渲染方程中环境光被包含在漫反射中 2. （漫反射）$I{diff}=K{d}I{p}cos\\left (\\theta \\right )=K{d}I{p}\\left (\\vec{N}\\cdot \\vec{L} \\right )+k{a}I_{a}$$K_{d}$为表面漫反射率 $I_{p}$为点光源强度 $\\vec{N}$为表面法向量 $\\vec{L}$为入射光方向 123456789101112131415161718192021222324252627282930313233343536 #define MAX_RAY_DEPTH 5 Vec3f phit = rayorig + raydir * tnear; // point of intersection Vec3f nhit = phit - sphere-&gt;center; // normal at the intersection point float bias = 1e-4; // add some bias to the point from which we will be tracing 在追踪中加入偏移float mix(const float &amp;a, const float &amp;b, const float &amp;mix)&#123; return b * mix + a * (1 - mix);&#125; if ((sphere-&gt;transparency &gt; 0 || sphere-&gt;reflection &gt; 0) &amp;&amp; depth &lt; MAX_RAY_DEPTH) &#123; //如果 （球体不透明度或者反射率大于0）且深度小于最大递归深度 float facingratio = -raydir.dot(nhit); // change the mix value to tweak the effect float fresneleffect = mix(pow(1 - facingratio, 3), 1, 0.1); // 计算反射方向 // compute reflection direction (not need to normalize because all vectors // are already normalized) Vec3f refldir = raydir - nhit * 2 * raydir.dot(nhit); refldir.normalize(); Vec3f reflection = trace(phit + nhit * bias, refldir, spheres, depth + 1);//递归 Vec3f refraction = 0; //此处应该包含前面的折射代码 // the result is a mix of reflection and refraction (if the sphere is transparent) //结果混合折射和反射 surfaceColor = (reflection * fresneleffect + refraction * (1 - fresneleffect) * sphere-&gt;transparency) * sphere-&gt;surfaceColor; &#125; 3. （高光Phong Model）$I{spec}=K{s}I{p}\\cos^{n}\\left( \\phi \\right)=K{s}I_{p}\\left( \\vec{R}\\cdot\\vec{V} \\right)^{n}$ $K_{s}$代表表面高光反射率 $I_{p}$代表之前的点光源强度 n代表高光反射参数 设绝对高光镜面（即反射所有光线）为无穷 以此我们可以看得出 当在交点以法向量做判断求 反射光线如果能返回到光源 则这个区域都是高光区域如下图所示 当高光说完之后 我们对整个光照方程应该有了一个较为清晰的认识 在我之前的博客中也讲过Phone光照模型 I=I_{amb}+I_{diff}+I_{spec}=k_{a}I_{a}+I_{i}\\left ( k_{d}\\left ( \\vec{L}\\cdot \\vec{N} \\right )+k_{s} \\left ( \\vec{V}\\cdot \\vec{R} \\right )^{n} \\right ) Snell’s Law(折射定律)\\frac{\\sin \\Theta _{1}}{\\sin \\Theta _{2}}= \\frac{v1}{v2} =\\frac{n1}{n2}n_{air}\\sin_{i}=n_{glass}sin\\Theta_{t}我们看到不同介质的折射率是不同的 12345678910111213141516171819202122 //如果球是透明 计算折射光线 if (sphere-&gt;transparency) &#123; float ior = 1.1, eta = (inside) ? ior : 1 / ior; // are we inside or outside the surface? float cosi = -nhit.dot(raydir); float k = 1 - eta * eta * (1 - cosi * cosi); //1-(eta*sin(i))^2 Vec3f refrdir = raydir * eta + nhit * (eta * cosi - sqrt(k)); refrdir.normalize(); refraction = trace(phit - nhit * bias, refrdir, spheres, depth + 1); &#125; // the result is a mix of reflection and refraction (if the sphere is transparent) surfaceColor = ( reflection * fresneleffect + refraction * (1 - fresneleffect) * sphere-&gt;transparency) * sphere-&gt;surfaceColor;&#125; // the result is a mix of reflection and refraction (if the sphere is transparent) surfaceColor = (reflection * fresneleffect + refraction * (1 - fresneleffect) * sphere-&gt;transparency) * sphere-&gt;surfaceColor; &#125; 当然还有很多可以细化的地方 比如高光的边缘可以有更多的虚化效果 还有不同材质的追踪效果 这些进阶的光线追踪处理方法 我们在下篇文章介绍 用以下一个伪代码来说明一下光线追踪的过程 1234567891011121314151617181920212223242526272829303132for each pixel of the screen//循环 视平面中的每个像素&#123; Final color = 0; Ray = &#123; starting point, direction &#125;;// 常见的三维矢量 描述起点的位置 和光线的方向 Repeat &#123; for each object in the scene //循环 场景中 物体 &#123; determine closest ray object/intersection; //判定最近的和光线相交的物体 &#125; if intersection exists//如果相交存在 &#123; for each light in the scene//对场景中的每一束光 &#123; if the light is not in shadow of another object//如果光不在其他物体的影子内 &#123; add this light contribution to computed color;//添加这束光的采样到已经计算的颜色中 &#125; &#125; &#125; Final color = Final color + computed color * previous // 最终的颜色+=已经计算的颜色*之前的颜色 reflection factor;//反射系数 reflection factor = reflection factor * surface reflectionproperty; //反射系数*=表面反射属性 increment depth; //深度增量 &#125; until reflection factor is 0 or maximumdepth is reached //直到反射系数为零或者到达最大值&#125; 有了这段伪代码我们算是能够在一定程度上了解了光线追踪的过程 但是并不直观 也并不易懂 光线追踪的内核我们用一段代码来帮助我们理解一下1234567891011121314151617181920212223242526272829303132333435363738394041void render(const std::vector&lt;Sphere&gt; &amp;spheres)&#123; unsigned width = 640, height = 320; Vec3f *image = new Vec3f[width * height], *pixel = image; float invWidth = 1 / float(width), invHeight = 1 / float(height); float fov = 30, aspectratio = width / float(height); float angle = tan(M_PI * 0.5 * fov / 180.); // Trace rays for (unsigned y = 0; y &lt; height; ++y) &#123; for (unsigned x = 0; x &lt; width; ++x, ++pixel) &#123; //像素遍历 float xx = (2 * ((x + 0.5) * invWidth) - 1) * angle * aspectratio; float yy = (1 - 2 * ((y + 0.5) * invHeight)) * angle; //坐标转化 Vec3f raydir(xx, yy, -1); //方向 raydir.normalize(); // cout&lt;&lt;\" x: \"&lt;&lt;x&lt;&lt;\" y: \"&lt;&lt;y&lt;&lt;endl; *pixel = trace(Vec3f(0), raydir, spheres, 0); //递归追踪 递增深度也就是上面伪代码中的 &#125; &#125; //完成追踪 缓存写入文件 // Save result to a PPM image (keep these flags if you compile under Windows) std::ofstream ofs(\"./untitledHD.ppm\", std::ios::out | std::ios::binary); ofs &lt;&lt; \"P6\\n\" &lt;&lt; width &lt;&lt; \" \" &lt;&lt; height &lt;&lt; \"\\n255\\n\"; for (unsigned i = 0; i &lt; width * height; ++i) &#123; ofs &lt;&lt; (unsigned char)(std::min(float(1), image[i].x) * 255) &lt;&lt; (unsigned char)(std::min(float(1), image[i].y) * 255) &lt;&lt; (unsigned char)(std::min(float(1), image[i].z) * 255); // cout&lt;&lt;\"Pixel ID\"&lt;&lt;i &lt;&lt;\"Red : \"&lt;&lt; (unsigned char)(std::min(float(1), image[i].x) * 255) &lt;&lt; // \"Green : \"&lt;&lt;(unsigned char)(std::min(float(1), image[i].y) * 255) &lt;&lt; // \"Blue : \"&lt;&lt;(unsigned char)(std::min(float(1), image[i].z) * 255)&lt;&lt;endl; //输出像素ID和颜色值 &#125; ofs.close(); delete [] image;&#125; 还有一个可能会引起疑惑的问题光源定义：123456789std::vector&lt;Sphere&gt; spheres;// position, radius, surface color, reflectivity, transparency, emission colorspheres.push_back(Sphere(Vec3f( 0.0, -10004, -20), 10000, Vec3f(0.20, 0.20, 0.20), 0, 0.0));spheres.push_back(Sphere(Vec3f( 0.0, 0, -20), 4, Vec3f(1.00, 0.32, 0.36), 1, 0.5));spheres.push_back(Sphere(Vec3f( 5.0, -1, -15), 2, Vec3f(0.90, 0.76, 0.46), 1, 0.0));spheres.push_back(Sphere(Vec3f( 5.0, 0, -25), 3, Vec3f(0.65, 0.77, 0.97), 1, 0.0));spheres.push_back(Sphere(Vec3f(-5.5, 0, -15), 3, Vec3f(0.90, 0.90, 0.90), 1, 0.0));// light 最后这项就是光源 spheres.push_back(Sphere(Vec3f( 0.0, 20, -30), 3, Vec3f(0.00, 0.00, 0.00), 0, 0.0, Vec3f(3))); 所以最后判断光线回到光源需要递归的次数来确定相交点的颜色 最后： 在此基础上 基础性代码里没有完成的例如 对复杂几何网格的追踪， 对含有不同材质，纹理的追踪， BRDF双向反射分布函数 焦散 等等我们将在下个文章中详细说明。","categories":[],"tags":[{"name":"Rendering","slug":"Rendering","permalink":"http://winshare.tech/tags/Rendering/"}]},{"title":"LaTex Math Editor","slug":"Latex-math-editor","date":"2017-05-10T13:25:55.000Z","updated":"2017-11-25T14:31:34.673Z","comments":true,"path":"2017/05/10/Latex-math-editor/","link":"","permalink":"http://winshare.tech/2017/05/10/Latex-math-editor/","excerpt":"","text":"","categories":[],"tags":[{"name":"Tool","slug":"Tool","permalink":"http://winshare.tech/tags/Tool/"}]},{"title":"Project_Video","slug":"Project-Video","date":"2017-05-06T13:44:33.000Z","updated":"2017-11-25T13:21:53.561Z","comments":true,"path":"2017/05/06/Project-Video/","link":"","permalink":"http://winshare.tech/2017/05/06/Project-Video/","excerpt":"Project Myhouse Demo 1 &gt;","text":"Project Myhouse Demo 1 &gt; Project Myhouse Demo 2 &gt; Project CADRO demo1 &gt; Project Touch Board &gt;","categories":[],"tags":[{"name":"video","slug":"video","permalink":"http://winshare.tech/tags/video/"}]},{"title":"Media Support","slug":"Video","date":"2017-05-06T13:26:08.000Z","updated":"2017-11-25T14:01:23.471Z","comments":true,"path":"2017/05/06/Video/","link":"","permalink":"http://winshare.tech/2017/05/06/Video/","excerpt":"Video part Full Page:模拟液体与毛发交互的多尺度模型 【SIGGRAPH 2017】","text":"Video part Full Page:模拟液体与毛发交互的多尺度模型 【SIGGRAPH 2017】 ### code (youku support): 123456&lt;iframe height=498 width=510 src=\"http://www.bilibili.com/video/av10127056/?from=search&amp;seid=17769389126359913539\" frameborder=0 allowfullscreen&gt; &lt;/iframe&gt; # Video part Play Window： > > ### code is : 123&lt;body&gt; &lt;embed height=\"415\" width=\"544\" quality=\"high\" allowfullscreen=\"true\" type=\"application/x-shockwave-flash\" src=\"//static.hdslb.com/miniloader.swf\" flashvars=\"aid=10127056&amp;page=1\" pluginspage=\"//www.adobe.com/shockwave/download/download.cgi?P1_Prod_Version=ShockwaveFlash\"&gt;&lt;/embed&gt;&lt;/body&gt;&gt; **** # music part Music.163.com gnenrate the play url:Music Link the code is1&lt;iframe frameborder=\"no\" border=\"0\" marginwidth=\"0\" marginheight=\"0\" width=330 height=86 src=\"//music.163.com/outchain/player?type=2&amp;id=16323797&amp;auto=1&amp;height=66\"&gt;&lt;/iframe&gt; Google analytics：","categories":[],"tags":[]},{"title":"LEAP MOTION  Core Asstet 2.3 Full Analyse","slug":"LEAP2.3_Core_analyse","date":"2017-05-06T10:44:48.247Z","updated":"2017-11-25T14:08:50.642Z","comments":true,"path":"2017/05/06/LEAP2.3_Core_analyse/","link":"","permalink":"http://winshare.tech/2017/05/06/LEAP2.3_Core_analyse/","excerpt":"本系列文章将会从一个初学者的脚步去讲解unity和leapmotion协同开发的一系列问题： 基础 环境搭建 场景创建 核心组件使用 sdk使用 脚本编写与功能实现方法 代码优化 UI交互部分","text":"本系列文章将会从一个初学者的脚步去讲解unity和leapmotion协同开发的一系列问题： 基础 环境搭建 场景创建 核心组件使用 sdk使用 脚本编写与功能实现方法 代码优化 UI交互部分 特：本人水平有限所以有错误请指正本人也会引用一些代码 如果有所侵犯请联系删除 自2015.11.22开始周更 第一部分基-基础首先，关于leapmotion 我想会看此类文章的应该都知道这是什么，无关将来这个产品的发展会如何，它作为虚拟现实或现实增强开发的练手是非常合适的。因为他有着非常舒适的开发环境，简单而成熟的SDK。最最重要的是结合unity/unreal，更是一种让你能在短时间之内通过引擎完成高质量手势识别应用的方法。 关于原理，和底层算法，因为代码封装完善，你根本不可能窥探到什么（当然肯定有人可以）。所以我的评价仅仅从实际效果出发先对leapmotion做出一个评价。 下图为leapmotion传感器的识别区域： 我们可以看到在y轴也就是高度上 leapmotion的识别距离真的是小的可怜（根据我实际测试不会超过50cm）也就是说如果不和其他硬件搭配leapmotion的使用范围很窄 单单的桌面使用的话，基本没有什么实用价值原因有二： 1.桌面使用场景下，手势识别很累低效 2.leap仅仅依靠景深画面和算法得出的手势识别精度高，但是精确度差。也就是说可以识别你手势动作很微小的变化，但是对这些变化的呈现又表现出很大的偏差。 在和oculus dk2结合之后，leapmotion的实用性总算提高了一些，但是效果仍然不理想。 因此，后续leap在不推出新硬件的条件下，我十分不看好这个传感器的发展，未来的leap，要么被OVR等厂家收购，要么倒闭。 ok 有点跑题，绕回来。虽然他这不好那不好，但这是我们在市场上能获取到的最优秀的性价比最高的手势识别设备。以他和oculus来学习虚拟现实开发，是最合适不过的了 那废话说够了，开始吧 first 基础 准备阶段： https://developer.leapmotion.com/getting-started/unity 当然是download everything_准备工具包括: unity（最好5.0以上版本） http://unity3d.com/cn/get-unity/download leapmotion应用&amp;SDK https://developer.leapmotion.com/ leapmotion unity core asset https://developer.leapmotion.com/downloads/unity（有朋友反应找不到leap core asset2.3下载地址在这里） 以上下载完毕之后接入leap使用visualizer检视和利用控制面板校准的过程我就不再赘述了，都有详细的引导。 那么既然是unity开发，c#自然是非常合适的了。所以对于刚刚接触unity的同学。了解unity的构成，以及c#脚本语言是非常重要的。 但是相比起来c#脚本教学可就多了去了，因此我只是做归纳总结。不作深入探究 下面我们简单的从leap的视角来看看unity/c#的一些特性： 头文件篇： using UnityEngine; using System.Collections; using System; using Leap; 命名空间类似其他语言中的库，所有脚本代码都要写在命名空间的类中。命名空间leap就是整个leapmotion脚本运作的核心。但是这和传统的c#有一些不同，例如在vs环境中的c#新建后会产生以下引用： using System; using System.Collections.Generic; using System.Linq; using System.Text; 从两段引用中我们也可以看出，c#语言在库上和某些早期的语言思路不太一致。至于详细的应用我们会在以后的更新中完整的介绍 正式代码篇： unity： public class NewBehaviourScript : MonoBehaviour { //初始化函数，在游戏开始时系统自动调用。一般用来创建变量之类的东西。 void Awake () { } // 在所有Update函数前系统自动条用。一般用来给变量赋值。 void Start () { } // 每帧调用一次 void Update () { } //固定时间间隔调用一次 void FixedUpdate（） { } //每一个Update执行之后执行一次 void LateUpdate（） { } } vs： namespace ConsoleApplication1 { class Program { static void Main(string[] args)//相当于c++中等main函数 { //____code___// } } } 我们看到 vs中需要自己定义命名空间 再以类的形式组织代码而unity cs中只能继承于 MonoBehaviour这个命名空间，至于mono~是一种框架，鉴于初学贴的定位我们就不深入了。在此原则之下，只要没有碰到的C#script和传统的c#的区别我就一概不讲了。以免喧宾夺主。 至于unity的界面以及使用的教程有人写的水平比我高很多于是我就转载啦： http://www.cnblogs.com/fortomorrow/archive/2012/10/28/unity01.html 总的来说，如果你有其他面对对象语言的基础。那么学习c#的成本将会非常低。如果你以前熟悉javascript/java，那么C#特性的异同在大多数情况下甚至可以忽略。 unity开发如果对实现效果不是极为苛刻那么开发的效率是非常高的。 如果你是个初学者，我会贴一段代码供大家熟悉c#特性的代码。供大家调试，修改。当然这些特性很多不会直接出现在脚本的编写中，但熟悉他们对于初学者来说对之后的工作有着非常大的好处 ： 1.1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950using System;using System.Collections.Generic;using System.Linq;using System.Text;namespace _11&#123;class Program&#123; static void Main(string[] args) &#123; Person p1 = new Person(); p1.Hello(); p1.Age = 21; p1.Name =&quot;Kungge&quot;; //p1.Nickname = &quot;Dogegg&quot;;// 注意这个外部不能使用 Console.WriteLine(p1.Name ); //p1.Hello2();//这个外部也不可使用 p1.GiveNn(&quot;Gumzhep&quot;); Console.ReadKey(); &#125; class Person &#123; public int Age; public string Name; private string Nickname; public void GiveNn(string nickname) &#123; if (nickname == &quot;Dogegg&quot;) &#123; return; &#125; this.Nickname = nickname; &#125; private void Hello2() &#123; &#125; public void Hello() &#123; Console.WriteLine(&quot;HelloWorld&quot;); Console.WriteLine(&quot;&#123;0&#125; &#123;1&#125; &#123;2&#125;&quot;,this.Age,this.Name,this.Nickname);//this.是我自己的 &#125; &#125;&#125;&#125; 2.属性：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798using System;using System.Collections.Generic;using System.Linq;using System.Text;namespace _11&#123;class Program&#123; static void Main(string[] args) &#123; Person p = new Person(); p.Age = 20; Console.WriteLine(p.Age); p.Age = -1;//非法值 无用 Console.WriteLine(p.Age); p.Nage = 20; Console.WriteLine(p.Nage); /*p.Dage = 20; Console.WriteLine(p.Dage );*/ //这将出现死循环 /* Person2 p2 = new Person2(); p2.Age = 20;//其是只读的 Console.WriteLine(p2 .Age);*/ Person3 p3 = new Person3(); p3.Age = 21; Console.WriteLine(p3.Age); Console.ReadKey(); &#125; class Person &#123; private int age; public int Age &#123; set//set用来赋值 &#123; if (value &lt; 0)//public字段和属性的区别 ：属性可以进行非法设置值的判断 &#123; return; &#125; this.age = value;//value是用户赋过来的值 &#125; get//get用来取值 &#123; return this.age; &#125; &#125; private int nage; public int Nage &#123; set &#123; this.nage = value; &#125; get &#123; return 18;//返回值是多少就是多少 &#125; &#125; private int dage; public int Dage &#123; set &#123; this.Dage = value;//将出现死循环 &#125; get &#123; return this.Dage; &#125; &#125; &#125; /* class Person2 &#123; public int Age &#123; get//这是只读的 &#123; &#125; &#125; &#125;*/ class Person3 &#123; public int Age//编译器自动生成私有字段和set get代码块 &#123; get; set; &#125; &#125;&#125;&#125; 3.练习一：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889using System;using System.Collections.Generic;using System.Linq;using System.Text;namespace _11&#123;class Program&#123; static void Main(string[] args) &#123; Robot r1 = new Robot(); r1.Name = &quot;K1&quot;; Robot r2 = new Robot(); r2.Name = &quot;K2&quot;; Robot r; Console.WriteLine(&quot;请选择1：r1,2:r2&quot;); string s = Console.ReadLine(); if (s == &quot;1&quot;) &#123; r = r1; &#125; else &#123; r = r2; &#125; Console.WriteLine(&quot;Hello,I&apos;m robot.&quot;); r.Eat(5); while (true) &#123; string str = Console.ReadLine(); r.Speak(str); &#125; Console.ReadKey(); &#125;&#125;class Robot&#123; public string Name &#123; set; get; &#125; private int full &#123; set; get; &#125; public void SayHello() &#123; Console.WriteLine(&quot;Hello,my name is &#123;0&#125;&quot;, Name); &#125; public void Speak(string str) &#123; if (str.Contains(&quot;你&quot;) &amp;&amp; (str.Contains(&quot;名字&quot;) || str.Contains(&quot;姓名&quot;))) &#123; this.SayHello(); &#125; else if (str.Contains(&quot;你&quot;) &amp;&amp; str.Contains(&quot;女朋友&quot;)) &#123; Console.WriteLine(&quot;我还没有了，要不你给我介绍一个&quot;); &#125; else if (str.Contains(&quot;今天&quot;) &amp;&amp; str.Contains(&quot;天气&quot;)) &#123; Console.WriteLine(&quot;天气很好&quot;); &#125; else if (str.Contains(&quot;你&quot;) &amp;&amp; str.Contains(&quot;吃饭&quot;)) &#123; Console.WriteLine(&quot;我已经吃过了&quot;); &#125; else if (str.Contains(&quot;再见&quot;) || str.Contains(&quot;拜&quot;) || str.Contains(&quot;8&quot;)) &#123; Console.WriteLine(&quot;拜，下次聊&quot;); return; &#125; else if (full &lt;= 0) &#123; Console.WriteLine(&quot;I&apos;m hungry! Give some food.Please input the number.&quot;); string str1 = Console.ReadLine(); this.Eat(Convert.ToInt32(str1)); &#125; else &#123; Console.WriteLine(&quot;听不懂&quot;); &#125; full--; &#125; public void Eat(int food) &#123; full = full + food; &#125;&#125;&#125; 4.对象的引用：1234567891011121314151617181920212223242526272829303132333435363738394041424344using System;using System.Collections.Generic;using System.Linq;using System.Text;namespace _11&#123;class Program&#123; static void Main(string[] args) &#123; int i = 10;//int,char,bool,datetime等类型都是值类型（value type），赋值的时候是传递拷贝 int j = i; i++; Console.WriteLine(j); Person p1 = new Person(10);//普通的对象则是引用类型，赋值的时候是传递引用 Person p2 = p1; p1.Age++; Console.WriteLine(p2.Age); IncAge(p2); Console.WriteLine(p2.Age);//传递给函数也是引用传递 static void IncAge(Person p) &#123; p.Age++; &#125; Console.ReadKey(); &#125;&#125;class Person&#123; public int Age &#123; get; set; &#125; public Person(int age) &#123; this.Age = age; &#125;&#125;&#125; 5.构造函数：12345678910111213141516171819202122232425262728293031323334353637383940using System;using System.Collections.Generic;using System.Linq;using System.Text;namespace _11&#123;class Program&#123; static void Main(string[] args) &#123; Person p1 = new Person(); Person p2 = new Person(&quot;K1&quot;); Person p3 = new Person(&quot;K2&quot;,20); Console.WriteLine(&quot;&#123;0&#125; &#123;1&#125;&quot;,p1 .Name,p1 .Age); Console.WriteLine(&quot;&#123;0&#125; &#123;1&#125;&quot;, p2.Name, p2.Age); Console.WriteLine(&quot;&#123;0&#125; &#123;1&#125;&quot;, p3.Name, p3.Age); Console.ReadKey(); &#125;&#125;class Person&#123; public int Age &#123; set; get; &#125; public string Name &#123; set; get; &#125; public Person()//构造函数和类名相同 可以重载 &#123; Name = &quot;unknown&quot;; Age = 1; &#125; public Person(string name) &#123; this.Name = name; &#125; public Person(string name, int age) &#123; this.Name = name; this.Age = age; &#125;&#125;&#125; 6.继承：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061using System;using System.Collections.Generic;using System.Linq;using System.Text;namespace 继承&#123;class Program&#123; static void Main(string[] args) &#123; Chinese c1 = new Chinese(); c1.Name = &quot;张三&quot;; c1 .Age =21; c1.Say(); c1.HaveTea(); American a1 = new American(); a1.Name = &quot;Gump&quot;; Japaniese j1=new Japaniese (); //American a4=new Person ();//错误 Person p1 = c1;//这是正确的 //American a2=p1;//错误的 //American a3 =(American) p1;//强制转换错误 Person p2 = j1; Person p3 = new Person(); Chinese c2 = (Chinese)p3;//想想为什么强制转换没有成功 Console.ReadKey(); &#125;&#125;class Person//所有的类都直接或间接继承Object类 其是所有类的基类&#123; public int Age &#123; set; get; &#125; public string Name &#123; set; get; &#125; public void Say() &#123; Console.WriteLine(&quot;&#123;0&#125;&quot;,Name); &#125;&#125;class Chinese : Person&#123; public string Tea &#123; set; get; &#125; public void HaveTea() &#123; Console.WriteLine(&quot;Chinese Tea is good!&quot;); &#125;&#125;class American : Person&#123; public void Westmeal() &#123; Console.WriteLine(&quot;Make a difference.&quot;); &#125;&#125;class Japaniese : Person&#123;&#125;&#125; 7.异常及异常处理1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950using System;using System.Collections.Generic;using System.Linq;using System.Text;namespace 异常&#123;class Program&#123; static void Main(string[] args) &#123; try &#123; int i = Convert.ToInt32(&quot;asd&quot;); Console.WriteLine(&quot;Convert 之后&quot;); &#125; catch(Exception ex) &#123; Console.WriteLine(&quot;数据错误：&quot;+ex.Message +ex.StackTrace); Console.WriteLine(&quot;数据错误之后&quot;); &#125; try &#123; string str = DescAge(200); &#125; catch(Exception ex) &#123; Console.WriteLine(&quot;数据错误：&quot;+ex.Message); &#125; Console.ReadKey(); &#125; static string DescAge(int age) &#123; if (age &gt;= 0 &amp;&amp; age &lt;= 150) &#123; return &quot;正常&quot;; &#125; else if (age &gt; 150) &#123; throw new Exception(&quot;神人啊&quot;); &#125; else &#123; throw new Exception(&quot;不正常&quot;); &#125; &#125;&#125;&#125; 8.常量,变量及static成员 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586using System;using System.Collections.Generic;using System.Linq;using System.Text;namespace 常量,变量及static成员&#123;class Program&#123; public const int Week = 7;//const常量 常量名要大写 static void Main(string[] args) &#123; const int Pi = 3;//不可变的量 注意这种用法 // Pi = 4;// Console.WriteLine(3*Pi); Person.height = 172;//注意 Person.Say();//不用new就能使用的方法static方法 Horse.Run(); //Person.Sing();// Person p = new Person(); p.Sing(); p.Age =20; //Rabbit r = new Rabbit();// Rabbit .Weigth =8; //Rabbit.Walk(); Rabbit.Eat(); Console.ReadKey(); &#125;&#125;public class Person&#123; public static int height; public int Age; public static void Say() &#123; Console.WriteLine(height); //Console.WriteLine(Age);//在static成员中不能直接调用非static成员 //Person.Sing(); &#125; public void Sing() &#123; Console.WriteLine(height); Console.WriteLine(Age); Person.Say();//在非static方法中可以调用static方法中的字段 方法 &#125;&#125;public class Horse&#123; public static int Size; public int Ability; public static void Run() &#123; Console.WriteLine(Person.height); // Console.WriteLine(Person.Age);// Person.Say();//在static方法中可以调用其它static方法的字段，属性，但不能调用非static的 //Person.Sing(); &#125; public void Leap() &#123; Console.WriteLine(Person.height); // Console.WriteLine(Person.Age); Person.Say(); //Person.Sing(); &#125;&#125;static class Rabbit//这是一个静态类&#123; public static int Weigth; public string Name; public static void Eat() &#123; Console.WriteLine(Horse.Size); // Console.WriteLine(Horse.Ability); &#125; public void Walk() &#123; Console.WriteLine(Horse.Size); &#125;&#125;&#125; 9.命名空间 1234567891011121314151617181920212223242526using System;using System.Collections.Generic;using System.Linq;using System.Text;using 命名空间.hr;namespace 命名空间&#123;class Program&#123; static void Main(string[] args) &#123; Person p = new Person();//这是本命名空间的类 命名空间.wk.Person p2 = new 命名空间.wk.Person(); p2.Say(); Dog d = new Dog();//using 命名空间.hr Convert.ToInt32(&quot;12&quot;);//using System Console.ReadKey(); &#125;&#125;class Person&#123;&#125;&#125; 1234567891011121314151617using System;using System.Collections.Generic;using System.Linq;using System.Text;namespace 命名空间.wk&#123;class Person&#123; public void Say() &#123; Console.WriteLine(&quot;Hello&quot;); &#125;&#125;&#125; 1234567891011using System;using System.Collections.Generic;using System.Linq;using System.Text;namespace 命名空间.hr&#123;class Dog&#123;&#125;&#125; 10.索引12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364using System;using System.Collections.Generic;using System.Linq;using System.Text;namespace 索引&#123;class Program&#123; static void Main(string[] args) &#123; Person p = new Person(); p[1]=172; Console.WriteLine(&quot;&#123;0&#125; &#123;1&#125;&quot;,p[1],p[2]); Console.WriteLine(p[&quot;Tom&quot;,1,2]); Console.ReadKey(); &#125;&#125;class Person&#123; public int Num1=168; public int Num2=173; public int this[int index] &#123; set &#123; if (index == 1) &#123; Num1 = value; &#125; else if (index == 2) &#123; Num2 = value; &#125; else &#123; throw new Exception (&quot;数据错误&quot;); &#125; &#125; get &#123; if (index == 1) &#123; return Num1; &#125; else if (index == 2) &#123; return Num2; &#125; else &#123; throw new Exception(&quot;数据错误&quot;); &#125; &#125; &#125; public string this[string name,int i1,int i2] &#123; get &#123; return name + i1 + i2; &#125; &#125;&#125;&#125; 动手是最重要的，在调试这些代码的过程中。你会深入的了解c#中的一些特性。 Now，just do it. goodbye next week~ 第二部分：环境搭建 本周我们将着重介绍unity&amp;leapmotion协同开发中的环境搭建，场景创建问题 这章内容和核心组件使用有着很强的关系所以作为先导请务必认真阅读 首先我们需要认识一下(xxxx.unitypackage)文件的应用 unitypackage格式的文件可以直接import到unity中,记住最好是在打开unity的情况下,在project面板里右击,然后在import packages-&gt;custom package中选中你要导入的资源。 那么我们先来看看 core Asset中都有些什么吧 可以说 leap对这个SDK做了很好的梳理Gizmos中仅存储着传感器在场景中的贴图 而leapmotion下的东西才是我们真正要用到的东西 也就是说如果你只进行桌面的应用开发的话 那么leapmotion+ovr还有OVR这两个文件夹几乎可以删除了。 那么我们怎么才在场景中看到手呢？ 此时unity强大之处就来了 接下来跟我做： 为了让大家能尽快的获取（运行）一些能看得东西 now 我们在文件视图中看到了搜索框是吧在里面搜索 HandController 将蓝色的prefab（预制体）拖入Hierarchy 于是我们可以看到一个这样的场景 现在可以运行啦！！！（不要告诉我不知道怎么运行） 是不是看到了两个小小的手！！！！ 是这样 unity和各个三维文件之间的单位换算有着区别因此我们如果想看见一双正常的手 要么把摄像机拉近拉的离控制器更近要么把 控制器的scale参数调大 （为了方便计算，十的整数倍的倍率比较好） OK我们终于能看到了写一个unity程序的入门之法了 &lt;/id=3&gt; 在unity的core Asset下我们可以看到很多的demo 。这些demo给我们提供了很多思路，其下的脚本也很有参考性。其中某些写法对我们构建程序来说，有着很强大的指导意义。 甚至对于一些代码经验贫乏的童鞋来说 根本不用自己写代码 仅仅靠ctrl+c&amp;ctrl+v就可以创建一个demo来完成某些功能 但是说实在的我并不鼓励这样做 毕竟我们的目标是学习一些技能 一些知识来为以后的虚拟现实开发奠基 下周我们将正式开始讲解unity&amp;leap的程序开发的初章 因此我们需要知道unity中一些重要的事情 预制体（prefab）model 上图中我们可以看到 handcontroller 就是一个预制体 它包含了脚本 预设置 模型等等 可以说成是一个集合 里面装着这个元素在场景中得以运行所需要的所有文件。可以被复制，重用，使得游戏的编写，场景创建变得高效。比如我们可以把一栋房子，他所有的组件，脚本，模型等等打包为预制体 然后在场景中复制粘贴为更多的房子 成为一个小区等等 此外我们看到handcontroller sandbox当我们把他点开以后发现它是由一个个平面拼接而成的 当我们点进prefab下更多的预制体 会发现更多手的模型 其中文件夹的命名也让你能清楚地理解内容 而在scenes文件夹下你也可以找到更多的工程从而进入更多的脚本去预先了解一些代码的写法。 坐标系 你可能会想 这有什么问题 ？ 但是这说起来是个大问题，因为unity中存在着多种坐标判断体系 ——视口坐标 ——世界坐标 ——屏幕坐标 ——GUI坐标 1、World Space（世界坐标）：我们在场景中添加物体（如：Cube），他们都是以世界坐标显示在场景中的。transform.position可以获得该位置坐标。 2、Screen Space（屏幕坐标）:以像素来定义的，以屏幕的左下角为（0，0）点，右上角为（Screen.width，Screen.height），Z的位置是以相机的世界单位来衡量的。注：鼠标位置坐标属于屏幕坐标，Input.mousePosition可以获得该位置坐标，手指触摸屏幕也为屏幕坐标， Input.GetTouch(0).position//可以获得单个手指触摸屏幕坐标。 Screen.width = Camera.pixelWidth Screen.height = Camera.pixelHeigth 3、ViewPort Space（视口坐标）:视口坐标是标准的和相对于相机的。相机的左下角为（0，0）点，右上角为（1，1）点，Z的位置是以相机的世界单位来衡量的。 4、绘制GUI界面的坐标系：这个坐标系与屏幕坐标系相似，不同的是该坐标系以屏幕的左上角为（0，0）点，右下角为 （Screen.width，Screen.height） 在此仅仅是粗略介绍， 今后在具体问题下 我们才能更好地认识和学习 此周务必多进行探索，下周将进行大量内容的讲解。 1，核心组件的使用。在unity的官方文档中中很明显并没有给出如何去怎样很好的去使用给出的资源那我们先来明确一下 core asset中的资源都是用来干什么的 （1）.handcontroller（以下简化为hc）这个组件的目的就是在空间具象化出传感器检测到的手，以及传感器本身的检测范围，我们可以在inspector 面板中清楚地看到他的构成 这里的命名十分清楚，在hc的脚本中包含了左右手的模型，包括 图像模型物理模型工具模型是否头戴的选项（主要用于协同oculus的开发）以及其他一些可供调整的选项 让我们点进图像模型去看又会发现一些更有意思的问题 首先我们会发现这些图像模型都是一些预制体他们由统一的skeletalhand脚本控制 这是他们的灵魂所在 是这个脚本把一些零散的模型组合在一起成为一个手 统一之下既然会有skeletalhand 那么skeletalfinger 这些脚本共同控制着在场景中手的运动是符合人体规律，也符合数据的（虽然在具体过程中还是会出现偏差和bug） 了解了由骨骼拼成的图像化手的模型，再来了解物理模型与图像模型进行比较 我们会发现从中发现很大的不同 物理模型的网格为了减少计算提高性能仅仅用一些粗略的网格去勾绘触发区域 但是 这也基本足够用 因为触发本身就是不精确的 且此种网格因为涉及了很多计算本身就是极为耗费性能的。 在这套物理系统中 我们可以轻松方便的设计触发 ，碰撞当你新建了一个预设的cube或者其他物体且使用他们的collider的话可以用下面一段代码轻松地检测碰撞以及触发： 12345void OnTriggerEnter(Collider collider) &#123; print(collider.gameObject.name + &quot;:&quot; + Time.time); &#125; 当然你也可能发现 我们在选择图形模型的时候出现了很多预制体，实际上这里出现的预制体也就都是手的不同的图形模型 我们可以根据左右手分别选择左右手的图形模型 其中包括了机器，仿真，纯白，为了达到更高的调试效果 我们推荐使用白色基础模型 因为他的渲染需求小很多 能够更清晰的反馈问题 此外工具模式可用性极低 在我的测试中即使工具异常明显 识别率成功率几乎是不可用的 因此我们在程序中几乎不需要考虑工具模式。 （2）.SCENCE在scence文件夹中 存在着很多leap用作演示的工程 他们统一基于core asset中的公用资源编写 所以所有文件都是可见的 都是可重用的 他们为我们的开发带来了很多思路 以及方法比如我们以其中的imagine hand 就可以清晰的看出 leapmotion的工作进程以及识别算法的思路：在正常的识别模式之下 采用了高噪点的模式同时蓝色边沿就是景深图像经过算法处理后 形成单帧的手势运算图形 我们如果直接采集图像和图形化检视面板作比较的话 就不难发现 这种描边+景深处理的形式 在这写预置的场景中甚至有一些解决了我们无从下手的设计问题 在这些设计工作上我们可以根据这些例子 这些demo直接去设计从而省去了很多的探索过程 鉴于下一章直接要讲一些功能的实现方式 我们在此直接贴出一些unity中物体操作的代码供大家调试 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177using UnityEngine;using System.Collections;public class mover : MonoBehaviour &#123; // Use this for initialization void Start () &#123; //x轴坐标 //float xPostion = -5f; //z轴坐标 //float zPostion = 10f; //直接将当前物体移动到x轴为xPostion，y轴为0，z轴为zPostion的三维空间位置。 transform.position = new Vector3(0.1f,0.1f,0.1f);//初始化坐标 &#125; // Update is called once per frame /*void Update () &#123; /* //移动速度 float TranslateSpeed = 0.1f; //Vector3.forward 表示“向前” transform.Translate(Vector3.forward *TranslateSpeed); //单方向移动*/ /* //轴移动速度移动速度 float xSpeed = 0.01f; //z轴移动速度移动速度 float zSpeed = 0.01f; float ySpeed = 0.01f; //向x轴移动xSpeed，同时想z轴移动zSpeed，y轴不动 transform.Translate(xSpeed,ySpeed,zSpeed); */ /* //按下键盘“上方向键”控制cube的位置 if(Input.GetKey(KeyCode.UpArrow)) &#123; Debug.Log (&quot;up&quot;); transform.Translate(0.1f,0f,0f);&#125; if(Input.GetKey(KeyCode.LeftArrow)) &#123; Debug.Log(&quot;left&quot;); transform.Translate(0f,0.1f,0f);&#125; if(Input.GetKey(KeyCode.DownArrow)) &#123; Debug.Log(&quot;down&quot;); transform.Translate(-0.1f,0f,0f);&#125; if(Input.GetKey(KeyCode.RightArrow)) &#123; Debug.Log(&quot;right&quot;); transform.Translate(0f,-0.1f,0f);&#125; //按下鼠标左键（0对应左键 ， 1对应右键 ， 2对应中键） /* if(Input.GetMouseButton(0)) Debug.Log (&quot;mouse down&quot;); Input.GetAxis(&quot;Mouse X&quot;);//鼠标横向增量（横向移动） Input.GetAxis(&quot;Mouse Y&quot;);//鼠标纵向增量（纵向移动） */ /* //旋转 this.transform.Rotate (Vector3.up, 0.3f); this.transform.Rotate (Vector3.right, 0.3f); this.transform.Rotate (Vector3.forward, 0.3F);*/ /* //缩放 float speed = 0.1f; float x; float z; x = Input.GetAxis(&quot;Horizontal&quot;) * Time.deltaTime * speed; //水平 z = Input.GetAxis(&quot;Vertical&quot;) * Time.deltaTime * speed; //垂直//&quot;Fire1&quot;，&quot;Fine2&quot;，&quot;Fine3&quot;映射到Ctrl，Alt，Cmd键和鼠标的三键或腰杆按钮。新的输入轴可以在Input Manager中添加。 transform.localScale += new Vector3(x, 0, z); */ //鼠标按着左键移动/* void Update() &#123; move (); &#125; void move()//move函数可复用 &#123; float speed = 0.1f; float y; float x; if (Input.GetMouseButton (0))&#123; y = Input.GetAxis (&quot;Mouse X&quot;) * Time.deltaTime * speed; x = Input.GetAxis (&quot;Mouse Y&quot;) * Time.deltaTime * speed; transform.Translate(x*5,y*5,0); Debug.Log(&quot;x=&quot;+x); Debug.Log(&quot;y=&quot;+y); &#125; &#125;*//* float speed = 100.0f; float x; float z; float y; //鼠标控制旋转 void Update () &#123; if(Input.GetMouseButton(0))&#123;//鼠标按着左键移动 y = Input.GetAxis(&quot;Mouse X&quot;) * Time.deltaTime * speed; x = Input.GetAxis(&quot;Mouse Y&quot;) * Time.deltaTime * speed; Debug.Log(&quot;X=&quot;+x); Debug.Log(&quot;y=&quot;+y); &#125; else&#123;x = y = 0 ;&#125;//检测鼠标如果没有在按压状态下移动的话，返回坐标归零 transform.Rotate(new Vector3(x,y,0)); /**---------------其它旋转方式----------------**///transform.Rotate(Vector3.up *Time.deltaTime * speed);//绕Y轴 旋转//用于平滑旋转至自定义目标 /* pinghuaxuanzhuan();&#125; //平滑旋转至自定义角度 void OnGUI()&#123;if(GUI.Button(new Rect(Screen.width - 110,10,100,50),&quot;set Rotation&quot;))&#123;//自定义角度 targetRotation = Quaternion.Euler(45.0f,45.0f,45.0f);// 直接设置旋转角度 iszhuan = true;&#125; &#125; bool iszhuan= false; Quaternion targetRotation; void pinghuaxuanzhuan()&#123;if(iszhuan)&#123; transform.rotation = Quaternion.Slerp(transform.rotation, targetRotation, Time.deltaTime * 3);//平缓旋转函数可复用 &#125; &#125; */ /* * 脚本bug处理总结： * 1，情况一：官方样板如果出现bug，则为编译框架问题改正方法：project-&gt;assembly csoption-&gt;build/general-&gt;target framework由3.5改为4.5 * 2，情况二：如果提示符号问题，很可能是空格所带来的问题，mono对编辑区空格宽容度较低，提示脚本中某行的问题，如果确定语法没错，很可能是因为空格的问题 * 3，情况三：单精度后必须加f 1.0 错 1.0f对 * 4，情况四：复制粘贴的代码需要大量精力来重新对格式进行debug，因此如果不是两三百行以上，尽量自己重写 * 5，情况五：如果编译错误很可能是因为空白区域留有字符 * /*/&#125; 注：以上代码均为不同功能片段凑成 不是直接复制粘贴运行就能完成功能 至于怎么修改和去除注释 我想就不用我教了 此外我们需要对摄像机的位置进行调整的话 可以用以下代码 用以保证摄像机永远对着物体拍摄以下代码的脚本需附在摄像机上 以此摄像机的轨迹就是以物体为球心的球面 1234567891011121314151617181920212223242526272829using UnityEngine;using System.Collections;public class camral : MonoBehaviour &#123; public Vector3 v1, v2; public GameObject cube; // Use this for initialization void Start () &#123; cube = GameObject.Find(&quot;House N251015&quot;);//house xxxx为物体的名字 &#125; // Update is called once per frame void Update () &#123; if (Input.GetKey (KeyCode.UpArrow)) this.transform.RotateAround (cube.transform.position, Vector3.right, Time.deltaTime*10f); if (Input.GetKey (KeyCode.DownArrow)) this.transform.RotateAround (cube.transform.position, Vector3.left, Time.deltaTime * 10f); if (Input.GetKey (KeyCode.LeftArrow)) this.transform.RotateAround (cube.transform.position, Vector3.down, Time.deltaTime * 10f); if (Input.GetKey (KeyCode.RightArrow)) this.transform.RotateAround (cube.transform.position, Vector3.up, Time.deltaTime * 10f); &#125;&#125; 在后期的开发中我们还需要对物体的坐标进行世界坐标化 以免旋转过后因为自身坐标的变化而引起方向的混乱 因此 我们物体的操作 都要有基于世界坐标的版本 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485using UnityEngine;using System.Collections;public class world_v : MonoBehaviour &#123; public GameObject cube; // Use this for initialization void Start () &#123; this.cube.transform.position = new Vector3 (0f, 0f, 0f); &#125; // Update is called once per frame void Update () &#123; if(Input.GetKey(KeyCode.UpArrow)) &#123; Debug.Log (&quot;up&quot;); this.cube.transform.Translate(Vector3.up * Time.deltaTime, Space.World); // this.cube.transform.Translate(0f,0.1f,0f); &#125; if(Input.GetKey(KeyCode.LeftArrow)) &#123; Debug.Log(&quot;left&quot;); this.cube.transform.Translate(Vector3.left * Time.deltaTime, Space.World); &#125; //this.cube.transform.Translate(-0.1f,0f,0f);&#125; if(Input.GetKey(KeyCode.DownArrow)) &#123; Debug.Log(&quot;down&quot;); this.cube.transform.Translate(Vector3.down * Time.deltaTime, Space.World); //this.cube.transform.Translate(0f,-0.1f,0f); &#125; if(Input.GetKey(KeyCode.RightArrow)) &#123; Debug.Log(&quot;right&quot;); this.cube.transform.Translate(Vector3.right * Time.deltaTime, Space.World); //this.cube.transform.Translate(0.1f,0f,0f); &#125; if (Input.GetKey (KeyCode.W)) &#123; Debug.Log (&quot;z+&quot;); this.cube.transform.Translate(Vector3.forward * Time.deltaTime, Space.World); // this.cube.transform.Translate (0f, 0f, 0.1f); &#125; if (Input.GetKey (KeyCode.S)) &#123; Debug.Log(&quot;z-&quot;); this.cube.transform.Translate(Vector3.back* Time.deltaTime, Space.World); //this.cube.transform.Translate(0f,0f,-0.1f);//________________________________________________________________ &#125; if (Input.GetKey (KeyCode.Y)) &#123; //this.cube.transform.Rotate(new Vector3(1,0,0)); this.cube.transform.Rotate(Vector3.up *1f, Space.World); &#125; if(Input.GetKey(KeyCode.U)) &#123; //this.cube.transform.Rotate(new Vector3(0,1,0)); this.cube.transform.Rotate(Vector3.left *1f, Space.World); &#125; if(Input.GetKey(KeyCode.I)) &#123; //this.cube.transform.Rotate(new Vector3(0,0,1)); this.cube.transform.Rotate(Vector3.forward *1f, Space.World); &#125; if (Input.GetKey (KeyCode.H)) &#123; //this.cube.transform.Rotate(new Vector3(-1,0,0)); this.cube.transform.Rotate(Vector3.down *1f, Space.World); &#125; if (Input.GetKey (KeyCode.J)) &#123; //this.cube.transform.Rotate(new Vector3(0,-1,0)); this.cube.transform.Rotate(Vector3.right *1f, Space.World); &#125; if (Input.GetKey (KeyCode.K)) &#123; //this.cube.transform.Rotate(new Vector3(0,0,-1)); this.cube.transform.Rotate(Vector3.back *1f, Space.World); &#125; &#125;&#125; 描述了以上一些操作 在unity中你就可以让物体动起来了并且按照一定的路线去规定物体怎么去运动 也为我们的进一步交互打好了基础 下周的内容将是真正意义上开发的开始 请仔细完成以上代码的功能 本周着重开始讲解leap开发中的实际问题 首先我们必须对一些核心的脚本进行熟悉 明白他们的工作原理 ： 1.重中之重simple.cs 作为官方编写的文档 几乎出现了所有的api 函数所有的返回数据 所有的方法 除去一些需要自己经验的写法 基本全部囊括其中了 但是 以下代码 基本见不到了simple.cs的影子 鉴于是教程 那我的定位是代码讲解 采取分立介绍最后汇总 不是铺陈代码tip ： 以下代码片段都不是直接复制粘贴就能运行的 小白还是回去看我之前的内容以下代码片段都不是直接复制粘贴就能运行的 小白还是回去看我之前的内容以下代码片段都不是直接复制粘贴就能运行的 小白还是回去看我之前的内容 头文件部分 因为设计到了一些list 或是一些UI绘制 所以头文件显得多了一些（当然以后会更多) 123456using UnityEngine;using UnityEngine.UI;using System.Collections;using System;using Leap;using System.Collections.Generic; 在脚本类中的定义工作 （以后的脚本基本基于以下定义工作，如不作特殊说明则默认为以下定义） 1234567 public HandController hc; //控制器 private HandModel hm; //手部模型public GameObject cubePrefab; //可不定义public Vector squizehand; //紧握得手vectorprivate GameObject cube = null;Frame currentFrame = null;//定义当前帧Frame lastFrame = null;//上一帧 函数部分借助返回的数据 我们可以设计更多的手势 比如在大量测试后 我们发现35左右的值在leap设计中是关键的参数所以： 1234567bool squize(float radius)//判断手势是否为握持 阀值为35 &#123; if (radius &lt; 37) return true; else return false; &#125; 另外 如果你有自己的想法 或是对返回值有所要求or不想用官方给的东西 那么可以自己写一个判断双手距离的函数： 1234567double distance(Vector a,Vector b)//双手距离判断 退出机制触发阀值为35 &#123; double c=Math.Sqrt (Math.Pow ((a.x-b.x), 2) + Math.Pow ((a.y-b.y), 2) + Math.Pow ((a.z-b.z), 2)); Debug.Log (&quot;TWO hand distance=&quot;+c); return c; &#125; 以上两个非常简单的函数共同使用 就诞生了更多的用法 我们后续会介绍 并且经过测试 其稳定性甚至要高于某些官方的预制手势那好既然说道预制手势 下面我们就来讨论一下 预制手势的用法：首先需要在start()中定义 打开预制手势： 12345hc.GetLeapController().EnableGesture(Gesture.GestureType.TYPECIRCLE); //环绕hc.GetLeapController().EnableGesture(Gesture.GestureType.TYPESWIPE); //挥动hc.GetLeapController().EnableGesture(Gesture.GestureType.TYPE_SCREEN_TAP); // ？hc.GetLeapController ().EnableGesture (Gesture.GestureType.TYPEKEYTAP); //点击hc.GetLeapController ().EnableGesture (Gesture.GestureType.TYPEINVALID); //无效 在此之后我们就可以通过foreach来调用各种预制手势 但说实话 相比起来 预制手势能完成的工作实在是太少了 1234567891011121314foreach (Gesture g in gestures) &#123; Debug.Log (g.Type); //----code----// //此中循环为调取手势列表中预制的手势 //leap在API中预置了手势即： //Gesture.GestureType.TYPESWIPE //Gesture.GestureType.TYPE_SCREEN_TAP //Gesture.GestureType.TYPEKEYTAP //Gesture.GestureType.TYPECIRCLE //等 //以此预制手势来实现操作则在此编码 &#125; 以上为预制手势使用的基本框架 下面就是预制手势完成的小demo ： 返回发生keytap手势时手的位置123456789foreach (Hand hand in frame.Hands) &#123; foreach (Gesture g in gestures) &#123; Debug.Log (g.Type); if (g.Type == Gesture.GestureType.TYPEKEYTAP) &#123; Debug.Log(&quot;tip position&quot;+hand.PalmPosition); &#125; &#125; &#125; （其中值得注意的是： swipe 和keytap这两个手势互相干扰非常严重 所以我们需要注意 这两个预制手势的共同使用是相当糟糕的） 那么讲完了预制手势，我们来讲讲返回值。首先，既然要完成手势的设计，能获取各种方法的返回值才是最重要的： 123456789101112131415161718192021public void OnFrame (HandController controller) &#123; //获取基本信息 Frame frame = controller.GetFrame(); //当前帧 Frame lastframe = controller.getlastframe ();//之前帧 星标1后续会重点讲这里记住 Debug.Log (&quot;Frame id: &quot; + frame.Id //帧ID + &quot;, timestamp: &quot; + frame.Timestamp //帧时间戳：从捕捉开始经过了多少毫秒 + &quot;, hands: &quot; + frame.Hands.Count //有几只手 + &quot;, fingers: &quot; + frame.Fingers.Count //有几只手指 + &quot;, tools: &quot; + frame.Tools.Count //有几个工具 + &quot;, gestures: &quot; + frame.Gestures ().Count); //手势计数 Debug.Log (&quot;lastFrame id: &quot; + lastframe.Id + &quot;, lasttimestamp: &quot; + lastframe.Timestamp + &quot;, lasthands: &quot; + lastframe.Hands.Count + &quot;, lastfingers: &quot; + lastframe.Fingers.Count + &quot;, lasttools: &quot; + lastframe.Tools.Count + &quot;, lastgestures: &quot; + lastframe.Gestures ().Count); &#125; 以上这个方法清楚的显示了leap代码构建的逻辑： 控制器下有一个记录每帧数据的容器 我们从每个数据帧中获得我们想要的信息 通过和之前帧对比来达到我们的目的如果我们想启用以上函数打印一些基本信息 1OnFrame(hc);//平时不必调用 （至于怎么修改获取容器中的值 我们稍后就会讲到 所以大家先看我讲的东西） frame ：就是我们所说的帧 之下的方法也就是在一帧之内我们能得到的 所有工作基本基于 frame展开 那么就是说 基本工作的展开都是从定义帧开始 12 Frame frame = hc.GetFrame ();Frame lastframe = hc.getlastframe (); 12 this.currentFrame = hc.GetFrame ();GestureList gestures = this.currentFrame.Gestures (); 在此基础上我们后续的工作才能展开 以下为在左手右手基础上的 代码框架 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051 Vector lefthand = null;Vector righthand = null;bool lefthandexist = false;//判断左右手是否在场景中存在bool righthandexist = false;foreach (var h in hc.GetFrame().Hands) &#123; if (h.IsLeft) &#123; lefthandexist=true; Debug.Log (&quot;lefthand exist? =&quot; + lefthandexist); lefthand = h.PalmPosition; //____code____// /* 此中h即为左手，可按照手的一切操作方式来编码 */ &#125; if (h.IsRight) &#123; righthandexist=true; Debug.Log (&quot;righthandexist? =&quot; + righthandexist); righthand=h.PalmPosition; foreach (Finger finger in righthand.Fingers) &#123; Finger.FingerType type=finger.Type(); Debug.Log (&quot; Finger id: &quot; + finger.Id + &quot;, &quot; + finger.Type().ToString() + &quot;, length: &quot; + finger.Length + &quot;mm, width: &quot; + finger.Width + &quot;mm&quot;); if(type==Finger.FingerType.TYPE_INDEX)// 手指类型的判断 Debug.Log(&quot;tip position=&quot;+finger.TipPosition+ &quot;tip direction=&quot;+finger.Direction); //____code____// &#125; if(lefthandexist&amp;&amp;righthandexist) &#123; //____code____// //如果左右手同时存在情况下的代码放在如下 &#125;&#125; 以上基本为手势部分代码设计框架还有很多内容没法全部细讲 那么我就直接贴上来代码了 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293/*控制台输出debug。log与using system之中 console。writeline用法相同 * 代码使用foreach来循环以达到返回所有手部数据的要求因此设计中可以带来更多设计 * keytap可用来点选 * type circle可用来旋转目标 * 挥舞可用来滑动菜单 * UI检测方式可用跟踪手的位置 如果：palm_position&lt;e(UI模块范围)&amp;&amp;gesture==keytap 则生成交互 * * 在此基础上改变交互规则： * * 以下为可收集数据中的注释 全可在以上对帧的循环下执行 * WriteLine (&quot;Frame id: &quot; + frame.Id + &quot;, timestamp: &quot; + frame.Timestamp + &quot;, hands: &quot; + frame.Hands.Count + &quot;, fingers: &quot; + frame.Fingers.Count + &quot;, tools: &quot; + frame.Tools.Count + &quot;, gestures: &quot; + frame.Gestures ().Count); * //pass * WriteLine (&quot; Hand id: &quot; + hand.Id + &quot;, palm position: &quot; + hand.PalmPosition); // Get the hand&apos;s normal vector and direction Vector normal = hand.PalmNormal; Vector direction = hand.Direction; // 计算手的角度 翻滚，偏离角 WriteLine (&quot; Hand pitch: &quot; + direction.Pitch * 180.0f / (float)Math.PI + &quot; degrees, &quot; + &quot;roll: &quot; + normal.Roll * 180.0f / (float)Math.PI + &quot; degrees, &quot; + &quot;yaw: &quot; + direction.Yaw * 180.0f / (float)Math.PI + &quot; degrees&quot;); // 获得胳膊的骨骼 Arm arm = hand.Arm; WriteLine (&quot; Arm direction: &quot; + arm.Direction + &quot;, wrist position: &quot; + arm.WristPosition + &quot;, elbow position: &quot; + arm.ElbowPosition); // 获得手指 foreach也可嵌套 foreach (Finger finger in hand.Fingers) &#123; SafeWriteLine (&quot; Finger id: &quot; + finger.Id + &quot;, &quot; + finger.Type().ToString() + &quot;, length: &quot; + finger.Length + &quot;mm, width: &quot; + finger.Width + &quot;mm&quot;); // 获得手指的骨骼 Bone bone; foreach (Bone.BoneType boneType in (Bone.BoneType[]) Enum.GetValues(typeof(Bone.BoneType))) &#123; bone = finger.Bone(boneType); SafeWriteLine(&quot; Bone: &quot; + boneType + &quot;, start: &quot; + bone.PrevJoint + &quot;, end: &quot; + bone.NextJoint + &quot;, direction: &quot; + bone.Direction); &#125; &#125; * * * * —————————————————————————————————————————————————————————————————— * 以下为prefab手势的扩展与详解 * * 旋转手势 顺时针与逆时针的判断规则： * case Gesture.GestureType.TYPE_CIRCLE: CircleGesture circle = new CircleGesture (gesture); // Calculate clock direction using the angle between circle normal and pointable String clockwiseness; if (circle.Pointable.Direction.AngleTo (circle.Normal) &lt;= Math.PI / 2) &#123; //Clockwise if angle is less than 90 degrees clockwiseness = &quot;clockwise&quot;; &#125; else &#123; clockwiseness = &quot;counterclockwise&quot;; &#125; * 计算旋转手势转过的角度： * float sweptAngle = 0;//初始化角度为零 // 计算从上一帧到这一帧的角度 if (circle.State != Gesture.GestureState.STATE_START) &#123; CircleGesture previousUpdate = new CircleGesture (controller.Frame (1).Gesture (circle.Id)); sweptAngle = (circle.Progress - previousUpdate.Progress) * 360; &#125; WriteLine (&quot; Circle id: &quot; + circle.Id + &quot;, &quot; + circle.State + &quot;, progress: &quot; + circle.Progress + &quot;, radius: &quot; + circle.Radius + &quot;, angle: &quot; + sweptAngle + &quot;, &quot; + clockwiseness); * * * */ 手势脚本部分引路工作基本完成 下面介绍另一个比较重要的脚本 2.HandController.cs这个脚本是leapmotion核心之一 上面脚本中多数方法 从handcontroller这个脚本中调用所以为了方便与满足我们的开发需求 对这个脚本的改动是最方便的 但是鉴于接近500line的体量 我不可能一一讲请 所以挑重点：也就是我们刚刚所提到的 frame 123456public Frame GetFrame() &#123; if (enableRecordPlayback &amp;&amp; recorder_.state == RecorderState.Playing) return recorder_.GetCurrentFrame(); return leap_controller_.Frame();&#125; 也就是说 我们使用的get frame() 原型在这里 所做的也就是从更深层的leap_controller()中获取但是 我们细心就会发现 这是个方法 所以 我们可以举一反三 1public Frame getlastframe(int i)&#123;return leap_controller_.Frame (i);&#125; 通过这个定义 我们就可以在今后的脚本中直接使用自己的getlastframe()获取自己想要的帧如果想要上一帧 那就hc.getlastframe(1)就好了 tips： 如果你想设计效果更好的手势建议去通读handcontroller 以及与之相关有继承关系的脚本 基于本节所讲的设计框架：我们可以根据所给代码设计一系列的动作 去做一些触发 模拟 控制至于剩下的内容 多着眼于 代码优化 动作设计更多的是一些关于渲染器 着色器 触发器 等等的内容本周内容较多 请多做练习 good bye next week （or next year） 本周 我们着重将讲解代码的优化问题 首先经过了上周我们 讲解的代码框架 以及设计规则 我们都有了足够的手法去设计一些自己想要的动作 但是 在一番编写之后 你肯定会发现 有很多方面并不能达到你设想的那样 其中涉及的一些很隐性的问题 表述起来比较繁杂 因此 我将会更多的以图片来展示问题 那些比较动态的问题 将会很难理解 所以 你应该尝试着跟着我的描述去做 其次 一些有问题的代码 因为我们的开发过程没有版本更替 所以一些有问题的代码没有保存 我只能从比较显眼的问题入手 第一点：世界坐标我们之前提到过的世界坐标的问题 我也附上了代码 想了解的可以去看之前的博客 但是没有细讲 下面着重来说这个问题 根据上次提供的脚本 新建一个脚本将代码复制附在摄像机上 然后新建一个cube 将物体与代码重定义的物体绑定我们将两个方块一个初始化在（000）点，一个初始化在（020）点 下面我们修改脚本 12345678if(Input.GetKey(KeyCode.UpArrow))&#123; Debug.Log (&quot;up&quot;); //this.cube.transform.Translate(0,0.1f,0,Space.World); this.cube.transform.Translate(0f,0.1f,0f);&#125; 以此类推 将带space.world的脚本注释 将不带spac.world的语句取消注释 下面我们根据所定义的按键来操作 发现上下左右都没问题 下面来旋转 同样的旋转系数 同样的操作 他们的坐标系根本不一致！！！这时候 我们再去操纵他们前后左右 我们分别点选坐标系就能看出端倪 世界坐标的作用是统一采用世界的坐标系来规定物体的旋转 如果不指定 物体的变换则是根据自身的坐标来的 所以经过旋转的物体 他们的运动在自己的坐标系内 很可能出现和你的坐标系相反 你输入的指令 是左 他却往右跑 正所以 世界坐标是规范物体运动的最好方法 第二点：awake 这点其实没什么好展示 因为这是unity开发中常会遇到的问题 脚本执行顺序说明： 先执行所有子脚本中的awake(); 在执行所有脚本中的start(); 然后执行所有update(); 当所有脚本中的update();执行一遍之后，则执行fixupdate();和lateupdate(); 即unity中没有多线程概念 且如果在awake中掺杂了关于获取对象的定义 那么脚本之间执行顺序不同就有可能出现空指针 第三点 ：触发网格我们从图片上可知 仅仅是触发网格 也是有一个一个简单的网格拼凑而成 与之相比较我们再来看看 模型的网格的结构 所以当我们设计捏取这个动作的时候 触发网格的误差足以让你发疯 所以 如果你想设计捏取动作 那么最好不要牵扯捏取的手指对物体做误差触发否则 就和官方程序里 那个下国际象棋的demo和 把头拼在机器人身上那个demo体验一样差 我的做法是 每当捏取的两个手指 发生捏取手势的时候 在捏取点生成一个半径固定（不能太大）球体触发网格 每当物体与球体发生触发 求出触发列表 把列表中每一个物体的触发点到球心的距离 求出最后把最距离最小的那个 物体设为 捏取物体至于代码 ： nothing ~ i can’t show that 第三点：UI相信这点困扰了一些人 因为鼠标键盘 体系的UI 乃至触屏体系的UI 都是直接集成在unity的我们可以方便的调用 但是 如果设计这种三维空间内的交互设计还是比较复杂的 如果没有相关文档支持 或者例子来借鉴 那么设计工作确实有些 难以展开 但是我们自己探索中就会发现wight这个东西：在搜索框中搜索 wight然后加载其中的设置当我们运行了wight之后就可以发现两种可手势交互的组件 一个是按钮 一个是滑动条 我们仔细观察他们的组织结构 就能清晰的发现 手势设计和 UI的组织结构 设计方法 组织方法 ** 经过观察 123using UnityEngine;using System.Collections;using LMWidgets; 我们可以首先发现 这个系列的脚本有着多层的继承关系 1234567891011protected override void Start()&#123; base.Start();&#125;protected override void FixedUpdate()&#123; base.FixedUpdate(); UpdateGraphics();&#125; 再往源头去 123456789101112131415161718192021using UnityEngine;using System;using System.Collections;namespace LMWidgets&#123; public abstract class SliderBase : LeapPhysicsSpring, AnalogInteractionHandler&lt;float&gt;, IDataBoundWidget&lt;SliderBase, float&gt; &#123; protected DataBinderSlider m_dataBinder; // Binary Interaction Handler - Fires when interaction with the widget starts. public event EventHandler&lt;LMWidgets.EventArg&lt;float&gt;&gt; StartHandler; // Analog Interaction Handler - Fires while widget is being interacted with. public event EventHandler&lt;LMWidgets.EventArg&lt;float&gt;&gt; ChangeHandler; // Binary Interaction Handler - Fires when interaction with the widget ends. public event EventHandler&lt;LMWidgets.EventArg&lt;float&gt;&gt; EndHandler; public GameObject upperLimit; public GameObject lowerLimit; protected float m_localTriggerDistance; 源头上LMxxxx的这些代码 的含义其实我们不必去细究 如果你没有涉及高层次的变动 复制粘贴 就好了 这种UI设计工作 说起来是个繁杂的工作 因此往往脚本的编写更加要求成体系 结构明了 所以要比功能编写付出充分的耐心 这些问题 不难 但是极其细致 繁复 我们要掌握的是设计思想 即 我们需要 熟悉button/slider的脚本 以及相关UI元素的使用 我们以button为例看一下这个设计该怎么展开 1234567891011121314151617181920212223242526272829303132333435363738394041424344using UnityEngine;using UnityEngine.UI;using System.Collections;public class ButtonDemoGraphics : MonoBehaviour&#123; public void SetActive(bool status) &#123; Renderer[] renderers = GetComponentsInChildren&lt;Renderer&gt;(); Text[] texts = GetComponentsInChildren&lt;Text&gt;(); Image[] GUIimages = GetComponentsInChildren&lt;Image&gt;(); foreach (Renderer renderer in renderers) &#123; renderer.enabled = status; &#125; foreach(Text text in texts)&#123; text.enabled = status; &#125; foreach(Image image in GUIimages)&#123; image.enabled = status; &#125; &#125; public void SetColor(Color color)//这个不用我说了吧 &#123; Renderer[] renderers = GetComponentsInChildren&lt;Renderer&gt;(); Text[] texts = GetComponentsInChildren&lt;Text&gt;(); Image[] GUIimages = GetComponentsInChildren&lt;Image&gt;(); //获取组件 foreach (Renderer renderer in renderers) &#123; renderer.material.color = color; &#125; foreach (Text text in texts)&#123; text.color = color; &#125; foreach(Image image in GUIimages)&#123; image.color = color; &#125; &#125;&#125; 在以上这个命名空间里 我们可以看出 他的思路是 这个脚本中完成和定义的工作 都是为了 button的绘图做准备 设置颜色 设置样式如何如何再看下一个 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768using UnityEngine;using System.Collections;using LMWidgets;public class ButtonDemoToggle : ButtonToggleBase&#123; public ButtonDemoGraphics onGraphics; public ButtonDemoGraphics offGraphics; public ButtonDemoGraphics midGraphics; public ButtonDemoGraphics botGraphics; public Color MidGraphicsOnColor = new Color(0.0f, 0.5f, 0.5f, 1.0f); public Color BotGraphicsOnColor = new Color(0.0f, 1.0f, 1.0f, 1.0f); public Color MidGraphicsOffColor = new Color(0.0f, 0.5f, 0.5f, 0.1f); public Color BotGraphicsOffColor = new Color(0.0f, 0.25f, 0.25f, 1.0f); public override void ButtonTurnsOn() &#123; TurnsOnGraphics(); &#125; public override void ButtonTurnsOff() &#123; TurnsOffGraphics(); &#125; private void TurnsOnGraphics() &#123; onGraphics.SetActive(true); offGraphics.SetActive(false); midGraphics.SetColor(MidGraphicsOnColor); botGraphics.SetColor(BotGraphicsOnColor); &#125; private void TurnsOffGraphics() &#123; onGraphics.SetActive(false); offGraphics.SetActive(true); midGraphics.SetColor(MidGraphicsOffColor); botGraphics.SetColor(BotGraphicsOffColor); &#125; private void UpdateGraphics() &#123; Vector3 position = transform.localPosition; position.z = Mathf.Min(position.z, m_localTriggerDistance); onGraphics.transform.localPosition = position; offGraphics.transform.localPosition = position; Vector3 bot_position = position; bot_position.z = Mathf.Max(bot_position.z, m_localTriggerDistance - m_localCushionThickness); botGraphics.transform.localPosition = bot_position; Vector3 mid_position = position; mid_position.z = (position.z + bot_position.z) / 2.0f; midGraphics.transform.localPosition = mid_position; &#125; protected override void Start() &#123; base.Start();// &#125; protected override void FixedUpdate() &#123; base.FixedUpdate();// UpdateGraphics();// &#125;&#125; 我们通过鼠标停留就可以发现 这些继承关系的源头 12345678protected override void Start() &#123; if ( m_dataBinder != null ) &#123; setButtonState(m_dataBinder.GetCurrentData(), true); // Initilize widget value &#125; else &#123; setButtonState(false, true); &#125; &#125; 所以我们可以用这种方法探究整个UIwight的工作机制 在这种情况下 我们可以清楚的认识到 整个UI的脚本资源之间的组织形式 和生动了解 总结编写方法 甚至官方这些 方法可以被我们复用以达到 真正的设计我们的新的 手势交互UI 以上图来看 在世界坐标视野中 我们可以看到 UI都被拥有box cllider 不同形式的UI设计 有着 不同的触发器样式 思路一下子就变得很清晰 在 三维的组织形式下 触发器的 工作形式需要好好调整 普遍是一个拥有冗余度的触发器 并且触发器的位置可以被推动 很好的模拟了现实世界的情况 在2016年三月 左右 我会写一套 手势识别 UI设计框架 所以一些 代码能力稍弱的童鞋 尽请期待 因为这个问题是个可以无限被讨论的问题 所以剩下的 更多的探索工作留给读者 我只是 指引一条方向供大家参考因此 如果有更好的方式也请加入qq群我们一起讨论 343074971 第四点：缩放手势我对这个功能的编写出现了很多延伸版本一开始的想法是 调用上一帧 和这一帧的双手位置进行计算 差值为正则放大 差值为负则缩小但是我显然高估了我对执行顺序的把控能力 基本上这个思路需要脚本的控制能力达到炉火纯青的地步才会写对 后期 对数据的检查发现 这个差距实在是太小以及上一帧的数据重复性导致的判断进程根本无法控制 后来又想了一个双手向量相加取模的类似的想法 但是也因为精度等等 原因 失败 经过多次的 实验 测试 记录 我发现 270是一个比较合适的 取值因此 针对双手的绝对距离 来设计这个缩放手势 最后又发现 这个方式不符合人的操作 又返回对比相对值的思路 最后 更改了 leap的传值方式 在当前帧 计算 前一帧得手的距离 和当前帧 手的距离 进行对比 最后实现了一个 比较好的结果 定义 123456789101112131415Hand lefthand=null;Hand righthand = null;Hand last_lefthand = null;Hand last_righthand = null;bool lefthandexist = false;//判断左右手是否在场景中存在bool righthandexist = false;double scale=0f;double dis=0f;double last_dis= 0f;double handdis(Hand a,Hand b)&#123; double c=Math.Sqrt (Math.Pow ((a.PalmPosition.x-b.PalmPosition.x), 2) + Math.Pow ((a.PalmPosition.y-b.PalmPosition.y), 2) + Math.Pow ((a.PalmPosition.z-b.PalmPosition.z), 2)); return c;&#125; 代码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253//左右手模块_________________________________________________________________________________________________________ foreach (var h in hc.GetFrame().Hands) &#123; if (h.IsLeft) &#123; lefthandexist = true; lefthand = h; Debug.Log (&quot;lefthand exist? =&quot; + lefthandexist); Debug.Log (&quot;lefthand position=&quot; + lefthand.PalmPosition); Debug.Log (&quot;lefthand squize?=&quot; + squize (lefthand.SphereRadius)); &#125; if (h.IsRight) &#123; righthandexist = true; righthand = h; Debug.Log (&quot;righthandexist? =&quot; + righthandexist); Debug.Log (&quot;righthand position=&quot; + righthand.PalmPosition); Debug.Log (&quot;righthand squize?=&quot; + squize (righthand.SphereRadius)); &#125; &#125; if((lefthandexist)&amp;&amp;(righthandexist)) &#123; if((squize(lefthand.SphereRadius))&amp;&amp;(squize(righthand.SphereRadius))) &#123; foreach (Hand hand in frame.Hands)//当前帧的手 &#123; foreach(Hand lastframe_hand in lastframe.Hands) &#123; if(hand.IsLeft)&#123;lefthand=hand;&#125; if(hand.IsRight)&#123;righthand=hand;&#125; if(lastframe_hand.IsLeft)&#123;last_lefthand=lastframe_hand;&#125; if(lastframe_hand.IsRight)&#123;last_righthand=lastframe_hand;&#125; &#125; &#125; dis=handdis(lefthand,righthand); last_dis=handdis(last_lefthand,last_righthand); if(dis&gt;last_dis) &#123;Debug.Log(&quot;++++++++++&quot;); this.cube.transform.localScale+=(new Vector3(1f,1f,1f));&#125; if(dis&lt;last_dis) &#123;Debug.Log(&quot;__________&quot;); this.cube.transform.localScale+=(new Vector3(-1f,-1f,-1f));&#125; &#125; &#125; 最后：我想说一些总结的设计原则 能保证你 做出来的东西至少是有实用性的： 设计动作最好 符合直觉 如果你有着较好的 代码能力 尽量不要使用预制手势 不要使用识别有冲突的手势 不要使用工具（tool模式） 不要相信官方宣传的精度 shit~ 很抱歉的是，之前说的LEAP/UI框架设计可能只有两篇 因为个人时间实在是不允许 这个问题如果展开去写的话 那么说写本书都是不为过的 且因为内容修改很是杂乱 所以我第一篇文章用来介绍LEAP预置ＵＩ的结构第二篇用来讲How to design&amp;build~ 鉴于直接涉及交互问题 因此这篇文章的受众显得很尴尬 但是相信 认真按照我之前博客学习的同学都能够理解其中的意思 关于leap这个东西 我在第一篇文章中就提到过 ——just a toy.所以只是用来开发的练手，根本别指望交互效果能够很好 根据我的经验来讲 手势识别的交互UI根据交互方式大概分为三种 1，触发式操作2，手势操作（下一期）3，映射性操作（下一期）所以 我从最基本的触发操作ui开始入手 预警：这篇文章very very long~~入门：从leap coreAsset当中找到 widght这个文件夹那先找个demo运行一下吧 SENCES下的运行一下咯~ 好 我们就由这个开始 unity UI和leap交互的前导首先 我们来熟悉 官方预设的四种UI样式 分别是： dial\\滚轮菜单 scrolltext\\可滑动的字体 slider\\滑动条 toggle button\\按钮 当我们把这四种prefab拖入场景加以调整再加上控制器 就算已经完整地展示了 所有的 官方预制形式 那么我们就来一个一个说吧 1.最简单的scrolltext\\可滑动的字体这个组件的主要控制过程在这里scrollhandle 我们可以看到他的结构相当简单 boxcollider检测触发 文本上下边界 和显示框上下边界 当text的上边界高于显示框的时候会以一个速度贴合回来 并且因为使用localposition 这个组件的工作不会因为坐标的颠倒而出错 123456protected virtual void ResetPivots() &#123; m_pivot = transform.localPosition; if (m_target != null) m_targetPivot = transform.parent.InverseTransformPoint(m_target.transform.position); &#125; 针对 TEXT组件的修改 我们可以直接在inspectors中修改文字等等操作 而直接生成一个类似阅读器之类的应用 在脚本中我们可以看到来龙去脉 首先是这个类LeapPhysicsBase： 相信有一定基础的小伙伴都知道 既然 设置了触发器 那么肯定会有 检测函数 12345678910111213141516171819202122protected virtual void OnTriggerEnter(Collider collider) &#123; //检测是否是手 if (m_target == null &amp;&amp; IsHand(collider) &amp;&amp; State != LeapPhysicsState.Disabled) &#123; State = LeapPhysicsState.Interacting; m_target = collider.gameObject; ResetPivots(); &#125; &#125; protected virtual void OnTriggerExit(Collider collider) &#123; if (collider.gameObject == m_target) &#123; State = LeapPhysicsState.Reflecting; m_target = null; &#125; &#125; 以上两个函数清楚的写了触发执行的过程 那既然是检测不只是要判断是否出发 还要对造成出发的对象进行判断 是否为手于是调用了以下这个函数 1234private bool IsHand(Collider collider)&#123; return collider.transform.parent &amp;&amp; collider.transform.parent.parent &amp;&amp; collider.transform.parent.parent.GetComponent&lt;HandModel&gt;();&#125; 以上三个部分共同工作，就生成了最基本的触发事件 而整个组建的状态更改 控制 识别都放在一个FixedUpdate();里面 12345678910111213141516171819202122protected virtual void FixedUpdate() &#123; if (m_target == null &amp;&amp; State == LeapPhysicsState.Interacting) &#123; State = LeapPhysicsState.Reflecting; &#125; switch (State) &#123; case LeapPhysicsState.Interacting://交互 ApplyInteractions(); break; case LeapPhysicsState.Reflecting://反映 ApplyPhysics(); break; case LeapPhysicsState.Disabled://无 break; default: break; &#125; ApplyConstraints(); &#125; 代码清晰易懂 对组件的3种状态做了规整的编写 代码结构十分清晰 123456public enum LeapPhysicsState &#123; Interacting, // Responsible for moving the widgets with the fingers Reflecting, // Responsible for reflecting widget information and simulating the physics Disabled // State in which the widget is disabled &#125; 在不同的状态下 对应不同的执行过程 非常规整、 值得一提的是 leap官方的代码风格很适合我们去仔细钻研 其中不乏一些亮点 对于我们来说很值得借鉴 对于没有形成良好代码风格的新手来说十分值得学习 1234567protected virtual void Awake() &#123; if (GetComponent&lt;Collider&gt;() == null) &#123; Debug.LogWarning(&quot;This Widget lacks a collider. Will not function as expected.&quot;); &#125;//碰撞其检测与error/warning输出 &#125; 在这个基类的脚本中 我们基本了解了这个组件的运行机理下面就来看第二个脚本ScrollBase 这个脚本中有几个重要的常数1，弹簧力（SnapSpringForce）；2，阻力（drag）；3，交互比例（InteractionScale）； 这几个参数决定着你出发这个组件并滑动之后 多久能停下来 惯性运行的时间 等等效果其中甚至运用到了一些公式运算 m_dampingForce = Mathf.Sqrt(4.0f * SnapSpringForce); （阻尼/力）类似这种运算 但最重要的还是定义了文本组件的上下界和显示框的上下界 我们可以清晰地看到 在这个组件的下方 文明本下界要长的多 从文本的属性来看 我们也可以清楚地看到纵横比也可以修改文字 而从脚本层面我们可以看到更多的这种继承关系 这是基类中的 123456protected virtual void ResetPivots() &#123; m_pivot = transform.localPosition; if (m_target != null) m_targetPivot = transform.parent.InverseTransformPoint(m_target.transform.position); &#125; 这是scrollbase中的 1234protected override void ResetPivots() &#123; base.ResetPivots(); m_contentPivot = ContentTransform.localPosition; &#125; 最后不得不佩服的是 为了实现 惯性这种细微的操作感代码的复杂程度高了不少 以至于催生了很多的计算方法 123456//计算一维弹簧力 protected float calculate1DSpringForce(float offsetVector) &#123; float springForce = offsetVector * SnapSpringForce; float dampingForce = m_dampingForce * (m_velocity); return springForce - dampingForce;&#125; 12345678910111213141516171819protected float calculateOverrunMagnitude() &#123;//计算超过量（文本边界超过显示边界的量） float overrunDistance = 0.0f; // Put all positions in object space. Vector3 localContentTop = transform.InverseTransformPoint(ContentTopBound.position); Vector3 localContentBottom = transform.InverseTransformPoint(ContentBottomBound.position); Vector3 localContainerTop = transform.InverseTransformPoint(ContainerTopBound.position); Vector3 localContainerBottom = transform.InverseTransformPoint(ContainerBottomBound.position); if (localContentTop.y &lt; localContainerTop.y) &#123; overrunDistance = localContainerTop.y - localContentTop.y; &#125; else if (localContentBottom.y &gt; localContainerBottom.y) &#123; overrunDistance = localContainerBottom.y - localContentBottom.y; &#125; return overrunDistance; &#125; 至于一些 基类中的状态判断循环所采用的应用方法 我只贴一个例子 ApplyInteractions(); 基类中定义了它的抽象方法在状态循环中 当状态为 case LeapPhysicsState.Interacting: 时调用了ApplyInteractions(); 而在scrollbase类中 整个重载了这个方法 1234567891011121314protected override void ApplyInteractions() &#123; Vector3 targetInteractorPositionChange = transform.parent.InverseTransformPoint(m_target.transform.position) - m_targetPivot; targetInteractorPositionChange *= InteractionScale; targetInteractorPositionChange.x = 0.0f; targetInteractorPositionChange.z = 0.0f; Vector3 contentCurrentPosition = ContentTransform.localPosition; Vector3 newContentPosition = m_contentPivot + targetInteractorPositionChange; Vector3 velocity = (newContentPosition - contentCurrentPosition) / Time.deltaTime; m_velocity = velocity.y; ContentTransform.localPosition = newContentPosition;&#125; 在这种结构下 我们其实如果只是想实现一个交互 那么还是很简单的 但是如果想加强操控感受 改善交互效果 可以说难度非常大 已经超出了新手的能力范围 因为其中涉及到了太多的 ＵＩ交互设计技巧 经验和逻辑。 OK~ NEXT 2.按钮照旧 我们先看他的构成 非常清晰有没有四种图像分别对应 打开状态关闭状态转移状态通用元素 接下来我们抛开他的素材去看代码这两个类的规模就要小很多了 因为没有很复杂的交互优化 整个组件非常清爽在ButtonDemoGraphics脚本中 1234567891011121314151617public void SetActive(bool status) &#123; Renderer[] renderers = GetComponentsInChildren&lt;Renderer&gt;(); Text[] texts = GetComponentsInChildren&lt;Text&gt;(); Image[] GUIimages = GetComponentsInChildren&lt;Image&gt;(); foreach (Renderer renderer in renderers) &#123; renderer.enabled = status; &#125; foreach(Text text in texts)&#123; text.enabled = status; &#125; foreach(Image image in GUIimages)&#123; image.enabled = status; &#125; &#125; 设置激活的方法显得非常干练包括对材质，图片，文字的遍历 12345678910111213141516public void SetColor(Color color) &#123; Renderer[] renderers = GetComponentsInChildren&lt;Renderer&gt;(); Text[] texts = GetComponentsInChildren&lt;Text&gt;(); Image[] GUIimages = GetComponentsInChildren&lt;Image&gt;(); foreach (Renderer renderer in renderers) &#123; renderer.material.color = color; &#125; foreach (Text text in texts)&#123; text.color = color; &#125; foreach(Image image in GUIimages)&#123; image.color = color; &#125; &#125; 包括对颜色更改也是 而在对此基类调用的时候ButtonDemoToggle类这种代码结构异常的清晰明了（真的好棒！！啊） 123456789101112131415private void TurnsOnGraphics() &#123; onGraphics.SetActive(true); offGraphics.SetActive(false);midGraphics.SetColor(MidGraphicsOnColor);botGraphics.SetColor(BotGraphicsOnColor); &#125; private void TurnsOffGraphics() &#123; onGraphics.SetActive(false); offGraphics.SetActive(true);midGraphics.SetColor(MidGraphicsOffColor);botGraphics.SetColor(BotGraphicsOffColor); &#125; 如果你想使用这个按钮 做一个状态判断的话 12345678910public override void ButtonTurnsOn()&#123; TurnsOnGraphics();&#125;public override void ButtonTurnsOff()&#123; TurnsOffGraphics();&#125; 写在这两个方法下 的话 就能达成你的目的啦比如 我想按钮显示关闭的时候的时候程序暂停运行 那就 1234567public override void ButtonTurnsOff()&#123; TurnsOffGraphics(); Debug.Break();&#125; 至于替换原本的ON/OFF的UI纹理 那就不用我教了 相信 能看到这里的都会操作 我们去如何设计按键触发的过程就有了一个清晰的方案 自定义按钮样式替换元素 -&gt;继承以重用脚本设计-&gt;自定义触发操作-&gt;完成总结：按钮为什么这里就总结了？答：按钮的类继承关系非常复杂 但是 组件本身有着很好的可修改性 重用性 因此 对于这种良心 组件 我们也不用想着从 脚本角度去修改 替换按钮的外观 和样式 保留官方这种成熟的继承风格 对于我们生成 的软件的稳定性至关重要； public abstract class ButtonToggleBase : ButtonBase, BinaryInteractionHandler &lt; bool &gt; , IDataBoundWidget &lt; ButtonToggleBase, bool&gt; 随意感受一下这个继承 3.滑动条（slider）先看图 我们可以看到 为了达成滑动条这个组件 所需要的 步骤 就多得多了虽然在hierarchy里面全部展开以后很吓人的样子但是其实 只有三类 1.top2.line3.dot 我们先从top开始看其实 他就是按键的马甲而已，SliderDemoGraphics负责控制这个按键的图像 top的结构从这个拆分能清楚的看清每个部分 toplayer：圆点按钮中心 midlayer：填充材质（slidersecondary）botlayer：选定高亮边框 所以在这个类当中 我们会看到按钮中出现过的套路 12345678public void SetActive(bool status) &#123; Renderer[] renderers = GetComponentsInChildren&lt;Renderer&gt;(); foreach (Renderer renderer in renderers) &#123; renderer.enabled = status; &#125; &#125; 12345678public void SetColor(Color color) &#123; Renderer[] renderers = GetComponentsInChildren&lt;Renderer&gt;(); foreach (Renderer renderer in renderers) &#123; renderer.material.color = color; &#125; &#125; Top的构成很简单 但是整个滑动条还是比较复杂的 就是因为这个类SliderDemo的继承SliderBase又继承于 LeapPhysicsSpring 这种继承关系导致我们想从自上而下的修改功能变得不是那么容易而我们只能从底层向上寻找Sliderdemo： 12345678910111213protected override void sliderPressed()&#123;//按下 base.sliderPressed(); PressedGraphics();&#125;protected override void sliderReleased()&#123;//释放 base.sliderReleased(); ReleasedGraphics();&#125; 这两个函数描述了按下后和释放后的指令 所以从这里来看 我们可以把一切我们想要的滑动条的按钮触发释放 来激活的事件 写在这两个方法里 最重要的检查触发被放在了高一级的类Sliderbase中的CheckTrigger()方法： 12345678910private void CheckTrigger() &#123; if (State == LeapPhysicsState.Interacting) &#123; //状态确定 fireSliderChanged (GetSliderFraction ()); if (m_dataBinder != null) &#123; m_dataBinder.SetCurrentData (GetSliderFraction ()); &#125; &#125; &#125; 而最根本的监听来自于一个诡异的方法 12345678private void onStateChanged(object sender, EventArg&lt;LeapPhysicsState&gt; arg) &#123; if ( arg.CurrentValue == LeapPhysicsState.Interacting ) &#123; sliderPressed();//按下 &#125; else if ( arg.CurrentValue == LeapPhysicsState.Reflecting ) &#123; sliderReleased();//释放 &#125; &#125; EventArg是包含事件数据的类的基类，而onStateChanged()方法中前者是一个对象（其实这里传递的是对象的引用，如button的click事件则sender就是button，相信有过c#/xaml/winfrom/编程经验得同学都见到过这个用法），后面是包含事件数据的类的基类。而在这个代码中sender就是leap中的一个对象 后面的基类将状态参数CurrentValue 表达出来 讲完了触发那么现在该进一步了arg.CurrentValue同时将修改State的值 这个值相当于整个类中的状态参量 代表按钮是否被按下 而在这个脚本中 还要根据state的值来进行更多的操作 123456public enum LeapPhysicsState &#123; Interacting, //手指等 触发按钮 Reflecting, //模拟物理特性 从触发被改变回到预置位置 Disabled // 关闭（正常）状态 &#125; .Enum 类型是所有枚举类型的抽象基类（它是一种与枚举类型的基础类型不同的独特类型）这里用到enum来准确描述状态 使得代码清晰易懂 易于维护 所以 当我们找到FixedUpdate中的UpdateGraphics()方法后12345678910111213141516171819202122232425262728private void UpdateGraphics() &#123; float handleFraction = GetHandleFraction(); Vector3 topPosition = transform.localPosition; topPosition.x = 0f; topPosition.y = 0f; topPosition.z -= (1.0f - handleFraction) * 0.25f; topPosition.z = Mathf.Min(topPosition.z, -0.003f); // -0.003 为保证dots和top永不相交的中间层 topLayer.transform.localPosition = topPosition; Vector3 botPosition = transform.localPosition; botPosition.x = 0f; topPosition.y = 0f; botPosition.z = -0.001f; botLayer.transform.localPosition = botPosition; midLayer.transform.localPosition = (topPosition + botPosition) / 2.0f;//___________________________________________________________________ if (activeBar) &#123; UpdateActiveBar();//激活 &#125; //______________________________________________________________________ if (numberOfDots &gt; 0) &#123; UpdateDots();//根据bot的位置判断 &#125; &#125; 在此我们只从Dot展开去讲 因为其他的过程基本上是 八九不离十在 123456789101112131415161718192021222324private void UpdateDots() &#123; for (int i = 0; i &lt; dots.Count; ++i) &#123;//dot的数量 根据此位置dot的x坐标 和 top的x轴自身坐标对比判断 来逐个绘制 小于高亮 大于常亮 if (dots[i].transform.localPosition.x &lt; transform.localPosition.x) &#123; Renderer[] renderers = dots[i].GetComponentsInChildren&lt;Renderer&gt;(); foreach (Renderer renderer in renderers) &#123; renderer.material.color = DotsOnColor; renderer.material.SetFloat(&quot;_Gain&quot;, 3.0f);//高亮 &#125; &#125; else &#123; Renderer[] renderers = dots[i].GetComponentsInChildren&lt;Renderer&gt;(); foreach (Renderer renderer in renderers) &#123; renderer.material.color = DotsOffColor; renderer.material.SetFloat(&quot;_Gain&quot;, 1.0f);//常亮 &#125; &#125; &#125; &#125; 而我们在先前的inspector中也看到了DotsOnColor/DotsOffColor 在其他部分的调用中 和Dots的绘制如出一辙 基本都是结合状态参量来进行判断 例如 1234public void SetWidgetValue(float value) &#123; if ( State == LeapPhysicsState.Interacting || State == LeapPhysicsState.Disabled ) &#123; return; &#125; // 使得状态在交互过程中稳定 SetPositionFromFraction (value); &#125; 那么最后来看这个LeapPhysicsBase类中state的终极目的： 12345678910111213141516171819202122protected virtual void FixedUpdate()&#123; if (m_target == null &amp;&amp; State == LeapPhysicsState.Interacting) &#123; State = LeapPhysicsState.Reflecting; &#125; switch (State) &#123; case LeapPhysicsState.Interacting://交互状态 ApplyInteractions(); break; case LeapPhysicsState.Reflecting://从交互状态返回正常状态 ApplyPhysics(); break; case LeapPhysicsState.Disabled://关闭（正常）状态 break; default: break; &#125; ApplyConstraints();&#125; 这是一个大写的清晰明了 之前对State枚举类型在这里一下就亮了用Switch来确定状态执行相应状态的方法集 至此 总分总式的把Solider说完了 已经 洋洋洒洒的说了1w字了 那么 我就继续吧 滚轮/表盘（Dial）照例先看图： 从trigger的网格来看就非常的复杂 所以要是自己想设计一个这种手势操作的UI组件 可以说难度非常大并且 坦白说 这个组件如果不经过自定义或者修改非常的华而不实 因为 他的选项实在是太多了 多到你手退出操作区域的时候 都会产生误操作 那么我们就先从可见外观结构说起 1.picker//选择器2.maskpanel//荫罩面3.backpanel //背景面 更进一步： 从这开始就开始有意思了起来首先 这是两个collider 小的这个被设置为滚轮上的字在这个区域被显示为高亮（HighLight）HilightTextVolume这个类中 清晰的表明了这一点 通过 触发器trigger的三个函数 巧妙的控制了字体的高亮显示 12345678910111213141516171819 //进入 void OnTriggerEnter(Collider other) &#123; Text text = other.GetComponentInChildren&lt;Text&gt;(); if (text == null) &#123; return; &#125; text.color = Color.white; &#125;//保持 void OnTriggerStay(Collider other)&#123; Text text = other.GetComponentInChildren&lt;Text&gt;(); if (text == null) &#123; return; &#125; text.color = Color.white; CurrentHilightValue = text.text; &#125; //离开 void OnTriggerExit(Collider other) &#123; Text text = other.GetComponentInChildren&lt;Text&gt; (); if (text == null) &#123; return; &#125; text.color = textColor; &#125; 这给我们提供了一个设计技巧 对于UI设计提升期的童鞋来说 是个相当有用的模式进入-&gt;保持-&gt;离开 |__| 而之后的用于隐藏的collider原理几乎一致在DatePickerHideVolume类中： 123456789101112void OnTriggerEnter(Collider other) &#123; Text text = other.GetComponentInChildren&lt;Text&gt; (); if (text == null) &#123; return; &#125; text.enabled = false;//设置隐藏&#125;void OnTriggerExit(Collider other) &#123; Text text = other.GetComponentInChildren&lt;Text&gt; (); if (text == null) &#123; return; &#125; text.enabled = true;//设置显示&#125; 那个大的collider 被放在转盘的圆心位置 所以转盘总有一半是被隐藏的 这样就保证了前视的时候后面的文字不会对前面的造成干扰 都是利用触发器来实现 但是还有个 比较有趣的问题 再来看图 我们发现 从下到上 文字的透明度越高这是怎么做到的呢？ 首先 定义了一条曲线 public AnimationCurve FadeCurve; 在曲线之后通过曲线来计算 透明值 12float opacityMod = FadeCurve.Evaluate(referenceDotDirection);//计算不透明度模float goalOpacity = m_originalLabelOpacity * opacityMod;//目标透明度 123456 foreach(Text textComponent in m_textLabels) &#123; //遍历设定 Color textColor = textComponent.color; textColor.a = goalOpacity;//对文字颜色的Alpha通道进行修改 textComponent.color = textColor;&#125; 讲完了这个外在 再来讲内在的控制部分 准备好受虐吧 这部分我也不太懂了 所以我尽量说我的理解 有错误请指出 先是生成label public List&lt; string &gt; DialLabels; 根据字符串List的数量来生成label 这个数量我们当然可以确定 所以 我们想使用这个控件 的话当然 应该使得这个list.count的数量趋近合理 这样不仅使得控件简洁明了 还是得交互变得更容易 准确性更高1234567891011121314151617181920212223private void generateAndLayoutLabels() &#123; float currentLayoutXAngle = LabelAngleRangeStart; for( int i=1; i&lt;=DialLabels.Count; i++ ) &#123; Transform labelPrefab = Instantiate(LabelPrefab, DialCenter.transform.position, transform.rotation) as Transform; //生成 labelPrefab.Rotate(currentLayoutXAngle, 0f, 0f); LabelAngles.Add (-currentLayoutXAngle); labelPrefab.parent = DialCenter; labelPrefab.localScale = new Vector3(1f, 1f, 1f); Text labelText = labelPrefab.GetComponentInChildren&lt;Text&gt;(); labelText.text = DialLabels[i - 1]; DialLabelAngles.Add(DialLabels[i - 1], -currentLayoutXAngle); labelText.transform.localPosition = new Vector3(0f, 0f, -DialRadius); currentLayoutXAngle = ((Mathf.Abs(LabelAngleRangeStart) + Mathf.Abs(LabelAngleRangeEnd))/(DialLabels.Count)) * -i; //调整 &#125; LabelPrefab.gameObject.SetActive(false); // Turn off the original prefab that was copied. &#125; 开始句柄更改句柄结束句柄1234//模拟交互的句柄 public event EventHandler&lt;EventArg&lt;int&gt;&gt; ChangeHandler; public event EventHandler&lt;EventArg&lt;int&gt;&gt; StartHandler; public event EventHandler&lt;EventArg&lt;int&gt;&gt; EndHandler; 当然触发检测是必不可少的 1234567891011121314151617181920 void OnTriggerEnter (Collider other)&#123; if (target_ == null &amp;&amp; IsHand (other)) &#123; //像之前一样确定触发体是手 target_ = other.gameObject;//旋转角 pivot_ = transform.InverseTransformPoint (target_.transform.position) - transform.localPosition;//旋转轴心 if (GetComponent&lt;Rigidbody&gt;().isKinematic == false) transform.GetComponent&lt;Rigidbody&gt;().angularVelocity = Vector3.zero; interacting_ = true; if (dialGraphics) dialGraphics.HilightDial (); &#125;&#125;void OnTriggerExit (Collider other)&#123; if (other.gameObject == target_) &#123; EndInteraction ();//结束交互 &#125;&#125; 从触发检测部分计算出的目标角度和旋转轴心 然后我们找到应用的方法 1234567protected virtual void ApplyRotations ()&#123;//旋转至目标角度 Vector3 curr_direction = transform.InverseTransformPoint (target_.transform.position) - transform.localPosition; //轴心 transform.localRotation = Quaternion.FromToRotation (pivot_, curr_direction) * transform.localRotation;&#125; 而这一切都在基类的FixedUpdate()中运行 123456789101112void FixedUpdate ()&#123; if (target_ == null &amp;&amp; interacting_) &#123; // 当交互时手已经被销毁 EndInteraction ();//结束交互 &#125; if (target_ != null) &#123; ApplyRotations ();//应用旋转 &#125; ApplyConstraints ();//应用约束以保证交互结束后 返回相应位置&#125; 至此 一些零碎的约束我已经无力再写下去了 就来归纳一下组件共同拥有的一些特性： 1.触发检测用于检测手和组件的交互 同时一般返回 ： 触发初始信息 触发过程信息 触发结束信息 2.约束条件：一般含有交互产生的改变量交互后根据规则的对改变量的判断对判断结果的执行 3.静止状态：一般含有系统用于初始化的初始量对于不产生交互状态下的静态量一般为产生触发后约束条件的结果 至此我们讲完了所有四个预置控件的结构与应用方法为我们在unity3D引擎中设计 VR/AR环境下的交互逻辑铺平了道路；但是很明显的是 在VR环境中设计交互操作明显有一定的方法论 触发设计，特效设计，逻辑设计每个部分单独拿出来都可以写一本书 并且在讲求经验的情况下 这和以前的UI设计相去甚远 平面UI的难度因为操控体系的健全而变得较为容易 但在三维环境下 无论是对手的模拟 还是对现实环境的模拟 都使得UI设计变得没有统一规则你可以虚拟出一个平面实现来类触屏操作而套用平面UI的设计方法更可以通过虚拟物体来体现虚拟现实技术的优势 这就使得设计变得无限可能这两种方式并没有优劣之分 各个应用环境之下 恰当的采用 效果才是最佳的。 最后 因为这系列文章过长 因此下次更新可能会在较长之后了（都是眼泪）； Bye~ See you next month~过了这么久才来更这篇实在是因为项目工程量实在是不允许首先声明我并不是专业的UI设计人员 我们所有的leap UI设计全部来源与项目需求 且因为项目不是商业项目 所以设计方法看起来有一种“邪门歪道”的既视感 但是为VR/AR环境中的交互设计提供了一种思路 特别提示：以下内容并不是针对初学者而言的 如果你是个unity/leap开发的双面小白 那么基本可以不用看这篇文章了 整个项目的效果可以去这里看视频 OK~言归正传 我们先来看看效果： 这是一个用手势控制选择的界面选择的时候会根据手势的挥动方向来进行左右切换也就是我们上一篇文章中提到的手势操作交互，这类操作不与UI元素进行交运算（触发）所以设计起来相对独立 也就是说 这类UI元素的制作可以按照普通的UI制作方式来进行 所以 在整个软件中 这个UI显得最普通 但是就是普通依旧不是那么好做 想实现一个类似IPhone音乐的选择界面并不是那么容易像这样 这种动态效果通过静态图片无法很好地展示 但是想试想一个细微的效果实际上需要大量的工作 这个UI整个比较复杂所以我只能不太完整的去讲解这是它的目录结构 在某一个版本中 我曾经写了动态生成这些展示标记 但是由于数量变化会引起后面的缩放系数bug 我就改回了手动添加这是每个UI元素的组成 其中有些组件是不必要的主要是为了原先鼠标操作而设计（ 后来整体取消了软件鼠标操作的功能 但保留了这些组件 比如碰撞器 对于一个手势操纵的UI类型来说完全是没必要的） 所以针对这个UI元素来说 可讲的就只剩下 1.怎么细致的实现元素转动效果2.怎么用手势控制旋转 一，转动效果 这其实很多demo里面都会出现 而这个实现的那我们来看看主要的结构命名清晰明了 enhance控制器 控制 gameobject(UItexture)UItexture下放了一个canvas 然后canvas上有三个text组件放置三组文字 sprite是背景控制（这里的sprite其实就是截取图形的插件） 有了六七列表我们就可以在控制器里通过代码来控制了 有两个类一个 EnhancelScrollView一个 EnhanceItem首先定义 EnhanceItem脚本附在每个UItexture上面 设置flag 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889using UnityEngine;using System.Collections;public class EnhanceItem : MonoBehaviour&#123; // 在ScrollViewitem中的索引 internal int scrollViewItemIndex = 0; // 夹角大小 internal float angla = 0f; // 动画时间值 internal float dValueTime = 0f; // 前后项 internal EnhanceItem front, back; /* * * * * * internal关键字是类型和类型成员的访问修饰符。只有在同一个程序集的文件中，内部类型或者是成员才可以访问。 * 这是msdn上对internal的描述。 * 类型就是enum（枚举类型），class（类），interface（接口），struct（结构）等类型。 * 类型成员如函数，成员变量等。 * * 一个完整的.exe或者是.dll文件就是一个程序集，一般伴随着exe程序集产生的还有一个程序集清单 * ，.exe.config文件。下面我就用一个例子来说明“internal关键字是类型和类型成员的访问修饰符。 * 只有在同一个程序集的文件中，内部类型或者是成员才可以访问”。 * * */ public int flag = 777;//flag private Vector3 targetPos = Vector3.one; private Vector3 targetScale = Vector3.one; private Transform mTrs; private UITexture mTexture; void Awake() &#123; mTrs = this.transform; mTexture = this.GetComponent&lt;UITexture&gt;(); &#125; void Start() &#123; UIEventListener.Get(this.gameObject).onClick = OnClickScrollViewItem; &#125; // 当点击Item，将该item移动到中间位置 private void OnClickScrollViewItem(GameObject obj) &#123; EnhancelScrollView.GetInstance().SetHorizontalTargetItemIndex(scrollViewItemIndex); &#125; /// &lt;summary&gt; /// 更新该Item的缩放和位移 /// &lt;/summary&gt; public void UpdateScrollViewItems(float xValue, float yValue, float scaleValue) &#123; targetPos.x = xValue; targetPos.y = yValue; targetScale.x = targetScale.y = scaleValue; mTrs.localPosition = targetPos; mTrs.localScale = targetScale; &#125; public void SetSelectColor(bool isCenter) &#123; if (mTexture == null) mTexture = this.GetComponent&lt;UITexture&gt;(); if (isCenter) mTexture.color = Color.white; else mTexture.color = Color.gray; &#125;&#125; EnhancelScrollView脚本作为控制脚本附着在控制物体上他就相当于每个物体 那么手势控制： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449using UnityEngine;using System.Collections;using System.Collections.Generic;using Leap;// [ExecuteInEditMode]public class EnhancelScrollView : MonoBehaviour&#123; // 含有滑动项目的面板 public GameObject enhanceScrollView; // 缩放曲线 public AnimationCurve scaleCurve; // 位移曲线 public AnimationCurve positionCurve; // 动画时间 public float duration = 0.2f; // 宽度 public float width = 800.0f; // y轴坐标固定值(所有的item的y坐标一致) public float yPositionValue = 46.0f; // 中间显示目标时间线(0显示第一个，0.5显示中间一个) public float horizontalTargetValue = 0.0f; // 滑动起始力 public float touchStartPower = 0.5f; // 滑动阻力 public int touchForce = 120; // 目标对象列表 private List&lt;EnhanceItem&gt; scrollViewItems; // 目标对象Widget脚本，用于depth排序 private List&lt;UITexture&gt; textureTargets; // 开始X坐标 private float startXPos = 0f; // 当前处于中间的item public EnhanceItem centerItem; // 当前出移动中，不能进行点击切换 private bool isInChange = false; // 位置动画的中间位置时间 private float positionCenterTime = 0.5f; // 当前精度小数位 private int curACC = 4; // 横向变量值 private float horizontalValue = 0.0f; // 移动动画参数 private float originHorizontalValue = 0.0f; private float currentDuration = 0.0f; private static EnhancelScrollView instance; internal static EnhancelScrollView GetInstance() &#123; return instance; &#125; //内部类型或成员才是可访问的 //__________________________________________________________// 动作识别部分定义 public HandController hc; Hand lefthand=null; Hand righthand = null; Hand last_lefthand = null; Hand last_righthand = null; Frame currentFrame = null;//定义当前帧 bool lefthandexist = false;//判断左右手是否在场景中存在 bool righthandexist = false; float sweptAngle = 0;//初始化角度为零 int mark=0;//标记 与下面的函数作用// 0代表不转动，-1代表向左转，1代表向右转 //____________________________________________________________ void checkmark(int sign) &#123; if (sign == 1) &#123; SetHorizontalTargetItemIndex(centerItem.front.scrollViewItemIndex); &#125; if (sign == -1) &#123; SetHorizontalTargetItemIndex(centerItem.back.scrollViewItemIndex); &#125; mark = 0; &#125; //执行转动的真正操作 检查标记从而确保只执行一次否则一次挥动将转动多次 void Awake() &#123; instance = this; &#125; void Start() &#123; hc.GetLeapController().EnableGesture(Gesture.GestureType.TYPECIRCLE); hc.GetLeapController().EnableGesture(Gesture.GestureType.TYPESWIPE); hc.GetLeapController().EnableGesture(Gesture.GestureType.TYPE_SCREEN_TAP); hc.GetLeapController ().EnableGesture (Gesture.GestureType.TYPEKEYTAP); hc.GetLeapController ().EnableGesture (Gesture.GestureType.TYPEINVALID); //开启所有手势 其实在这个脚本中只开启typeswipe就够了// ____________________________________________ InitData();//初始化数据 // 设置第一个为选中状态 SetHorizontalTargetItemIndex(0); &#125; /// &lt;summary&gt; /// 初始化数据 /// &lt;/summary&gt; private void InitData() &#123; startXPos = -(width / 2); scrollViewItems = new List&lt;EnhanceItem&gt;(); scrollViewItems.AddRange(enhanceScrollView.GetComponentsInChildren&lt;EnhanceItem&gt;()); if (textureTargets == null) textureTargets = new List&lt;UITexture&gt;(); float anglaDValue = 360 / scrollViewItems.Count; int centerIndex = scrollViewItems.Count / 2; for (int i = 0; i &lt; scrollViewItems.Count; i++) &#123; scrollViewItems[i].scrollViewItemIndex = i; scrollViewItems[i].angla = anglaDValue * i; scrollViewItems[i].dValueTime = GetCurveTimePos(scrollViewItems[i].angla); // 构造环形链 scrollViewItems[i].front = i == 0 ? scrollViewItems[scrollViewItems.Count - 1] : scrollViewItems[i - 1]; scrollViewItems[i].back = i == (scrollViewItems.Count - 1) ? scrollViewItems[0] : scrollViewItems[i + 1]; UITexture tmpTexture = scrollViewItems[i].gameObject.GetComponent&lt;UITexture&gt;(); textureTargets.Add(tmpTexture); scrollViewItems[i].SetSelectColor(false);//设为选中状态 调用了enhanceitem中的方法将mtexture中的混合颜色设为白色以显示高亮 &#125; &#125; //_____________________________________________________________________________________________ void Update() &#123; if (!isInChange) &#123; touch(); return; &#125; currentDuration += Time.deltaTime; float percent = currentDuration / duration; horizontalValue = Mathf.Lerp(originHorizontalValue, horizontalTargetValue, percent); UpdateEnhanceScrollView(horizontalValue); SortDepth(); if (currentDuration &gt; duration) &#123; centerItem = textureTargets[textureTargets.Count - 1].gameObject.GetComponent&lt;EnhanceItem&gt;(); centerItem.SetSelectColor(true); isInChange = false; &#125; &#125; /// &lt;summary&gt; /// 更新水平滚动 /// &lt;/summary&gt; /// &lt;param name=&quot;fValue&quot;&gt;&lt;/param&gt; private void UpdateEnhanceScrollView(float fValue) &#123; for (int i = 0; i &lt; scrollViewItems.Count; i++) &#123; EnhanceItem itemScript = scrollViewItems[i]; float xValue = GetXPosValue(fValue, itemScript.dValueTime); float scaleValue = GetScaleValue(fValue, itemScript.dValueTime); itemScript.UpdateScrollViewItems(xValue, yPositionValue, scaleValue); &#125; &#125; //滑动X轴增量位置 float xMoved; private void touch() &#123; // 记录滑动位置 if (Input.touchCount == 1 &amp;&amp; Input.GetTouch(0).phase == TouchPhase.Moved) &#123; //获取手指自最后一帧的移动 float x = Input.GetTouch(0).deltaPosition.x; xMoved = x; &#125; // 滑动结束时判断故事翻页 if (Input.touchCount == 1 &amp;&amp; Input.GetTouch(0).phase == TouchPhase.Ended) &#123; if (centerItem == null || Mathf.Abs(xMoved) &lt; touchStartPower) return; int count = (int)(Mathf.Abs(xMoved * scrollViewItems.Count/ touchForce)) + 1; int minHalfCount = Mathf.CeilToInt((float)scrollViewItems.Count / 2) - 1; if (count &gt; minHalfCount) &#123; count = minHalfCount; &#125; if(xMoved &gt; 0) &#123; SetHorizontalTargetItemIndex(GetMoveIndex(centerItem, -count)); &#125; else if (xMoved &lt; 0) &#123; SetHorizontalTargetItemIndex(GetMoveIndex(centerItem, count)); &#125; xMoved = 0; &#125; &#125; /// &lt;summary&gt; /// 缩放曲线模拟当前缩放值 /// &lt;/summary&gt; private float GetScaleValue(float sliderValue, float added) &#123; float scaleValue = scaleCurve.Evaluate(positionCenterTime + sliderValue + added); return scaleValue; &#125; /// &lt;summary&gt; /// 位置曲线模拟当前x轴位置 /// &lt;/summary&gt; private float GetXPosValue(float sliderValue, float added) &#123; float evaluateValue = startXPos + positionCurve.Evaluate(positionCenterTime + sliderValue + added) * width; return evaluateValue; &#125; /// &lt;summary&gt; /// 计算位置动画中的时间点 /// &lt;/summary&gt; /// &lt;param name=&quot;anga&quot;&gt;角度值,360度=1&lt;/param&gt; /// &lt;returns&gt;&lt;/returns&gt; private float GetCurveTimePos(float anga) &#123; // 设定0.5为位置中间 return Round(anga / 360f, curACC); &#125; // 获取项目A到项目B之间最小的时间差值（圆形角度计算,1=360度） private float GetCurveTimeDValue(EnhanceItem itemA, EnhanceItem itemB) &#123; return Round((Mathf.DeltaAngle(itemA.angla, itemB.angla)) / 360f, curACC); &#125; private void SortDepth() &#123; textureTargets.Sort(new CompareDepthMethod()); for (int i = 0; i &lt; textureTargets.Count; i++) textureTargets[i].depth = i; &#125; /// &lt;summary&gt; /// 用于层级对比接口 /// &lt;/summary&gt; private class CompareDepthMethod : IComparer&lt;UITexture&gt; &#123; public int Compare(UITexture left, UITexture right) &#123; if (left.transform.localScale.x &gt; right.transform.localScale.x) return 1; else if (left.transform.localScale.x &lt; right.transform.localScale.x) return -1; else return 0; &#125; &#125; //核心滚动函数 /// &lt;summary&gt; /// 设置横向轴参数，根据缩放曲线和位移曲线更新缩放和位置 /// &lt;/summary&gt; internal void SetHorizontalTargetItemIndex(int itemIndex) &#123; if (isInChange) return; EnhanceItem item = scrollViewItems[itemIndex];//_____________新场景中根据这个来判断 if (centerItem == item) return; Debug.Log (&quot;item = &quot; + item.name); if (item.name == &quot;Texture01&quot;) &#123; //Debug.Log(&quot;YES&quot;); &#125;// _________________________________________________________________________________________ float dvalue = centerItem == null ? 0 : GetCurveTimeDValue(centerItem, item); // 更改target数值，平滑移动,设负数倒着转 horizontalTargetValue += -dvalue; beginScroll(horizontalValue, horizontalTargetValue); &#125; void FixedUpdate() &#123;// ___________________________________________________________________________________手势swipe模块 this.currentFrame = hc.GetFrame (); Frame frame = hc.GetFrame (); Frame lastframe = hc.getlastframe (); GestureList gestures = this.currentFrame.Gestures (); Vector swipedirection=null; foreach (Gesture g in gestures) &#123; if(g.Type==Gesture.GestureType.TYPE_SWIPE) &#123; SwipeGesture swipe=new SwipeGesture(g); swipedirection=swipe.Direction; //Debug.Log(&quot;direction is &quot;+swipedirection); &#125; &#125; if (swipedirection.x &gt; 0) &#123;//判断手势向左还是向右参数向左则小于0向右则大于0 Debug.Log(&quot;right&quot;); mark=1; &#125; if (swipedirection.x &lt; 0) &#123; Debug.Log(&quot;left&quot;); mark=-1; &#125; checkmark (mark);//检查参数以完成UI的旋转// ———————————————————————————————————————————————————————————————————————————————————————————————————————————— &#125; /// &lt;summary&gt; /// 开始滚动 /// &lt;/summary&gt; /// &lt;param name=&quot;startTime&quot;&gt;&lt;/param&gt; /// &lt;param name=&quot;endTime&quot;&gt;&lt;/param&gt; private void beginScroll(float startTime, float endTime) &#123; if (isInChange) return; foreach (EnhanceItem item in scrollViewItems) &#123; item.SetSelectColor(false); &#125; originHorizontalValue = Round(startTime, curACC); horizontalTargetValue = Round(endTime, curACC); currentDuration = 0.0f; isInChange = true; &#125; /// &lt;summary&gt; /// 向右选择角色按钮 /// &lt;/summary&gt; public void OnBtnRightClick() &#123; if (isInChange) return; SetHorizontalTargetItemIndex(centerItem.back.scrollViewItemIndex); &#125; /// &lt;summary&gt; /// 向左选择按钮 /// &lt;/summary&gt; public void OnBtnLeftClick() &#123; if (isInChange) return; SetHorizontalTargetItemIndex(centerItem.front.scrollViewItemIndex); &#125; /// &lt;summary&gt; /// 获取移动后的项目索引 /// &lt;/summary&gt; /// &lt;param name=&quot;item&quot;&gt;当前项目&lt;/param&gt; /// &lt;param name=&quot;count&quot;&gt;移动位数，负数表示倒移&lt;/param&gt; /// &lt;returns&gt;&lt;/returns&gt; private int GetMoveIndex(EnhanceItem item, int count) &#123; EnhanceItem curItem = item; for (int i = 0; i &lt; Mathf.Abs(count); i++) &#123; curItem = count &gt; 0 ? curItem.back : curItem.front; &#125; return curItem.scrollViewItemIndex; &#125; /// &lt;summary&gt; /// 按指定小数位舍入 /// &lt;/summary&gt; /// &lt;param name=&quot;f&quot;&gt;&lt;/param&gt; /// &lt;param name=&quot;acc&quot;&gt;&lt;/param&gt; /// &lt;returns&gt;&lt;/returns&gt; private float Round(float f, int acc) &#123; float temp = f * Mathf.Pow(10, acc); return Mathf.Round(temp) / Mathf.Pow(10, acc); &#125; /// &lt;summary&gt; /// 截取小数 /// &lt;/summary&gt; /// &lt;param name=&quot;f&quot;&gt;&lt;/param&gt; /// &lt;returns&gt;&lt;/returns&gt; private float CutDecimal(float f) &#123; return f - (int)f; &#125;&#125; 以缩放曲线来决定 元素在位置发生转动后 大小的变化规则以位移曲线来规定 元素的运动位置轨迹两条曲线分别为： 可见一个小功能的实现竟然用了500+line虽然不难 但是这个排除bug 保证逻辑正确的过程是在太令人头疼 构造环形链的代码也比较抽象 12scrollViewItems = new List&lt;EnhanceItem&gt;();scrollViewItems.AddRange(enhanceScrollView.GetComponentsInChildren&lt;EnhanceItem&gt;()); 而之后的代码将手势识别的代码也包括进去了 主要思路就是判断挥动手势的方向 根据这个参数来确定UItexture整体转动的方向 至此我们的这个类型的UI代码讲解也结束了总结一下手势控制类UI： 1，此类UI构建方式和普通UI区别较小（几乎没区别）无论是平面，立体。2，此类UI的控制方式最好生成一个统一的操作函数例如turnleft(),turnright();之后直接用手势触发就好3，如果使用单一手势触发的话最好设置一定的时延 否则 误操作将会非常多 最后也就是这个系列的最后一些内容我来讲讲印射式UI（或者说印射操作） 这里用到的就是 射线leap和射线可以说是非常蛋疼的组合 我本身对这个功能的探索时间长达一个月我就细细说一下这个奇葩的功能的由来： 首先面对一个模型我们想把它散开 再在每个子物体上加上盒触发器 这种算法在unity里简直好像一坨屎结果就如下图：boxcollider不能很好的契合模型Meshcollider又因为面数限制而不能使用那只能用box凑活了 这就导致一个问题用手来触发这一坨屎一样的东西自然是很不精确的并且一旦触及百万面的工业模型 性能就迅速下降到崩溃边缘： 像这样 于是我们怎么才能解决这个精确触发的问题呢？这是问题一 其二leapmotion的手的大小和识别区域是绑定的 所以放大识别区域的结果是必然要放大手的模型比如我想增大在空间内控制器的操作范围就会产生这种画面 手的模型变大严重阻碍了软件的使用，所以又要保证手的大小适中作指示而手的操作范围被限制在控制器识别范围之内。这就诞生了一个设计上的矛盾。画面上要求手变小 操作范围上要求手变大。于是就有了射线 初次写射线功能其实和leap并不能很好的一起工作，因为有太多的隐含参数数值需要去探索 用这种方法可以进行精确化的触发，选择。在这个基础上进行设计可以很多leap官方demo完成不了的操作那下面我们先来看看代码 这个脚本挂camera上 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218using UnityEngine;using System.Collections;using Leap;public class ray : MonoBehaviour &#123; public hand_script2 control_script;//控制脚本定义 public HandController hc=null; public RaycastHit hit; public Vector3 handdir; public Vector3 handpos; //public GameObject cube = null; public GameObject highlight=null; float hx, hy, hz=0; float dx, dy, dz = 0; public GameObject particle_light=null; float xr,yr,zr; private float index=0; Hand lefthand=null; Hand righthand=null; public GameObject color_apply=null; Color origin=Color.black; public Color apply_color;// ______________________________________________________________ bool squize(float radius)//判断手势是否为握持 阀值为35 &#123; if (radius &lt; 37) return true; else return false; &#125;// --------------------------------------------------------------------------- private bool IsHand(Collider collider) &#123; return collider.transform.parent &amp;&amp; collider.transform.parent.parent &amp;&amp; collider.transform.parent.parent.GetComponent&lt;HandModel&gt;(); &#125;//判断触发器是否是手 void Awake() &#123; &#125; // Use this for initialization void Start () &#123; Debug.Log (&quot;Start&quot;); //空间两点距离计算：sqrt(pow(x1-x2，2)+pow(y1-y2，2)+pow(z1-z2，2)) index = hc.transform.localScale.x / 1000;//计算后面的缩放指数 &#125; // Update is called once per frame void Update () &#123; bool lefthandexit = false; bool righthandexit = false; //Debug.Log (&quot;Update&quot;); //Vector3 fwd = new Vector3 (0, 0,10 ); Frame frame = hc.GetFrame (); Frame lastframe = hc.getlastframe (); apply_color = color_apply.gameObject.GetComponent&lt;RGB&gt; ().rgb;//获取color混合界面的颜色值可去掉 foreach (Hand hand in frame.Hands) &#123; if (hand.IsLeft) &#123; lefthandexit = true; lefthand = hand; &#125; if (hand.IsRight) &#123; righthandexit = true; righthand = hand; foreach (Finger finger in righthand.Fingers) &#123; Finger.FingerType type=finger.Type(); if (type == Finger.FingerType.TYPE_INDEX) &#123; dx = finger.Direction.x; dy = finger.Direction.y; dz = finger.Direction.z; hx = finger.TipPosition.x; hy = finger.TipPosition.y; hz = finger.TipPosition.z; &#125; //获取中指的信息finger_INDEX &#125; //dx = hand.Direction.x; //dy = hand.Direction.y; //dz = hand.Direction.z; handdir = new Vector3 (dx*index,dy*index,-dz*index);//必须乘指数 // ---------------------------------------------------------------------- //hx = hand.PalmPosition.x; //hy = hand.PalmPosition.y; //hz = hand.PalmPosition.z; handpos = new Vector3 (hx*index, hy*index,-hz*index);//同样乘指数 // ---------------------------------------------------------- //Debug.Log (&quot;righthand_position is &quot; + handpos + &quot;righthand dir is &quot; + handdir); //Debug.Log (&quot;reall date is&quot; + hand.PalmPosition + &quot; /// &quot; + hand.Direction); xr = hand.RotationAngle (lastframe, Vector.XAxis); yr = hand.RotationAngle (lastframe, Vector.YAxis); zr = hand.RotationAngle (lastframe, Vector.ZAxis); &#125; &#125; //cube.transform.Rotate (new Vector3(xr*index,yr*index,-zr*index),Space.World); //原先用cube表示手的信息与射线做对照 /* float x = this.transform.rotation.x; float y = this.transform.rotation.y; float z = this.transform.rotation.z; Vector3 rota = new Vector3 (x, y, z); Debug.Log (&quot;this.position=&quot; + this.transform.position); dx = this.transform.position.x; dy = this.transform.position.y; dz = this.transform.position.z; Vector3 position = new Vector3 (dx,dy+100,dz); */ if (squize(lefthand.SphereRadius) &amp;&amp; (!squize (righthand.SphereRadius))) &#123; //如果左手握持且右手不握持 //bool Physics.Raycast(Ray ray, Vector3 direction, RaycastHit out hit, float distance, int layerMask) if (Physics.Raycast(handpos,handdir,out hit,10000,1)) &#123; //(Physics.Raycast(射出点,射出方向向量,输出触发信息存储点,长度,1)) particle_light.transform.position =new Vector3(hit.point.x,hit.point.y,hit.point.z-2);//此处为粒子系统 用粒子系统跟随触发点以显示触发位置 if ((highlight.gameObject.name.ToString() != hit.collider.gameObject.name.ToString()) &amp;&amp; origin == Color.black&amp;&amp; (!IsHand(hit.collider))&amp;&amp; (hit.collider.gameObject.GetComponent&lt;Renderer&gt;()!=null)) &#123; //判断是否第一次触发 Debug.Log (&quot;first&quot;); highlight = hit.collider.gameObject; control_script.main_son = hit.collider.gameObject; origin = highlight.gameObject.GetComponent&lt;Renderer&gt; ().material.color; highlight.gameObject.GetComponent&lt;Renderer&gt; ().material.color = Color.gray; &#125; if ((highlight.gameObject.name.ToString () != hit.collider.gameObject.name.ToString ()) &amp;&amp; origin != Color.black&amp;&amp; (!IsHand(hit.collider))&amp;&amp; ((hit.collider.gameObject.GetComponent&lt;Renderer&gt;()!=null))) &#123; //判断是否变更触发物体 Debug.Log (&quot;change&quot;); control_script.main_son = hit.collider.gameObject; highlight.gameObject.GetComponent&lt;Renderer&gt; ().material.color = origin; highlight = hit.collider.gameObject; origin = highlight.gameObject.GetComponent&lt;Renderer&gt; ().material.color; highlight.gameObject.GetComponent&lt;Renderer&gt; ().material.color = Color.gray; &#125;//以上用来交换信息 坐到触发高亮 /* if((highlight.gameObject.name.ToString()==hit.collider.gameObject.name.ToString())&amp;&amp;origin!=Color.black) &#123; highlight = hit.collider.gameObject; highlight.gameObject.GetComponent&lt;Renderer&gt; ().material.color = Color.red; &#125; */ //hit.collider.gameObject.GetComponent&lt;Renderer&gt; ().material.color = Color.red; Debug.Log (&quot;OBJ-name is &quot; + hit.collider.gameObject); //Debug.Log (&quot;hit point is &quot; + hit.point + &quot; distance = &quot; + hit.distance); //Debug.Log (&quot;Success&quot;); Debug.DrawLine (handpos, hit.point, Color.red); //在sence中显示射线并设置为红色 //Debug.Break (); &#125; if (lefthandexit==true) &#123; Debug.Log (&quot;________________&quot;); //Debug.Break(); &#125; &#125; &#125;&#125; //射线脚本bug汇总： /* * 1.发射点以世界坐标为准则： * 如handcontroller的放大倍率为100则数乘index指数为0.1 * 2.必须将控制器的位置考虑进去 * 3.射线距离尽可能大 */ 脚本毕来说一些特殊的地方那些隐含的值最后确定为 index = hc.transform.localScale.x / 1000;//计算后面的缩放指数 而以上都基于 控制器在原点也就是（0，0，0）而针对 非原点的情况 要把控制器的坐标也算进去才能保证你的射线是从指尖发出去的如果想更改射线发射的位置 那么判断进其他的手指类型就好了 代码里面非常清楚 同时 在射线的位置用一个粒子特效做一个触发位置提示 效果像这样 在这个体系之下 你就可以把手指当做一个三维环境里的鼠标 对任意一个点进行触发操作以进一步的执行其他部分 所以我们的触发UI可以不用再设计在控制器的范围之内 我们可以用射线功能触发几乎无限远的元素 比如在一个环境中我们通过一定映射关系去触发区域之外的按钮 如图所示 至此所有LeapUI设计专题所有内容都讲完了洋洋洒洒的九万多字再次： 本人水平有限,有错误请联系qq：785929784也欢迎有兴趣的开发者加入qq群：343074971共同交流共同进步。 感谢群友对本博客的支持 后续将更新 欢迎支持","categories":[],"tags":[{"name":"Gesture tracking","slug":"Gesture-tracking","permalink":"http://winshare.tech/tags/Gesture-tracking/"}]},{"title":"unity & Computer graphics Chapter(1)","slug":"《Unity Shader 与 计算机图形学》第一章","date":"2017-05-06T10:44:48.245Z","updated":"2017-11-25T14:19:02.681Z","comments":true,"path":"2017/05/06/《Unity Shader 与 计算机图形学》第一章/","link":"","permalink":"http://winshare.tech/2017/05/06/《Unity Shader 与 计算机图形学》第一章/","excerpt":"问题：入图形学大坑这么久，看了不少书，却发现一个严重的问题。大部分时间在知其然不知其所以然。没有一篇文章从GPU讲到游戏引擎再到游戏。这种自底向上的架构性的东西对于图形学程序员来说可谓至关重要 我初学的时候就无时不刻在为GPU怎么参与图形运算shader是干吗的？ 管线是个什么鬼？ 那些牛逼闪闪的demo效果为什么的那么好？","text":"问题：入图形学大坑这么久，看了不少书，却发现一个严重的问题。大部分时间在知其然不知其所以然。没有一篇文章从GPU讲到游戏引擎再到游戏。这种自底向上的架构性的东西对于图形学程序员来说可谓至关重要 我初学的时候就无时不刻在为GPU怎么参与图形运算shader是干吗的？ 管线是个什么鬼？ 那些牛逼闪闪的demo效果为什么的那么好？ 所以：这个系列三篇文章将从GPU工作到绘图过程~从一个史诗级unity 官方demo的shader技术~最终清楚地描述GPU/OPEN GL/D3D/Shader/管线/渲染器/实时渲染算法/等等一大堆名词之间的关系，最终，我们将分析unity和unreal的画质究竟为什么会有差异，并以一个工程来证明，unity的画质也可以很好。 提示：本系列文章分为 硬件编程入门工程实践 因为硬件部分比较枯燥和陌生。所以如果对于硬件没有兴趣可以直接关注后续文章。本系列从2106年12月开始月更 在2017年2月之前更新完三篇 最底层——GPU/硬件原理 硬件的工作原理其实简单理解起来用一个视频就能说明Mythbusters Demo GPU versus CPU但是基于明确的说明 我们还是用Nvdia的文档来了解一下GPU的不同之处和工作机制这是现代典型GPU和CPU的不同之处 我们看到真正的计算单元也就是绿色的部分GPU采用来大量的计算核心也就是Nvdia口中的Cuda核心来进行高数据密度的运算 #铺垫： 先来了解计算机内部这些运算器控制器都是用来干嘛的~ 1.ALU：Arithmetic Logic Unit 算数逻辑单元 大部分ALU都可以完成以下运算∶ 整数算术运算（加、减，有时还包括乘和除，不过成本较高） 位逻辑运算（与、或、非、异或） 移位运算（将一个字向左或向右移位或浮动特定位，而无符号延伸），移位可被认为是乘以2或除以 2。 Alu可以说是计算机处理器的核心部件之一 2.Cache：通常人们所说的Cache就是指缓存SRAM。 SRAM叫静态内存，“静态”指的是当我们将一笔数据写入SRAM后，除非重新写入新数据或关闭电源，否则写入的数据保持不变。由于CPU的速度比内存和硬盘的速度要快得多，所以在存取数据时会使CPU等待，影响计算机的速度。SRAM的存取速度比其它内存和硬盘都要快，所以它被用作电脑的高速缓存(Cache)。 对于一个典型的CPU来说 Alu部分会很强大 可以在很少的时钟周期内完成算数计算对于一个64bit双精度的CPU来说 浮点加法和乘法只需要1-3个时钟周期而相比动辄2GHZ 10^9 的cpu来说对于逻辑和算数运算的处理能力就非常强了大的cache也将延时降低很多 结合了现在的各种高级调节技术比如超线程 多核 等技术CPU对于复杂逻辑的运算能力得到了极大提升 对于典型的GPU来说ALU的数量会非常大 功能会更少 能耗很低 cache就会很小这样带来的好处就是针对大吞吐量的需要简单计算的数据来说 处理效率就高了非常多。如果有很多线程需要访问同一个相同的数据，缓存会合并这些访问，然后再去访问dram（因为需要访问的数据保存在dram中而不是cache里面），获取数据后cache会转发这个数据给对应的线程，这个时候是数据转发的角色。但是由于需要访问dram，自然会带来延时的问题。 GPU的控制单元（左边黄色区域块）可以把多个的访问合并成少的访问。 GPU的虽然有dram延时，却有非常多的ALU和非常多线程. 为啦平衡内存延时的问题，我们可以中充分利用多的ALU的特性达到一个非常大的吞吐量的效果。尽可能多的分配多的线程.通常来看GPU ALU会有非常重的pipeline就是因为这样。 对比结构我们可以先得出一个简单结论，那就是。针对今天的显卡来说。更适合做高并行，高数据密度，简单逻辑的运算。 然而在硬件上更进一步的架构中在这里Nvdia和AMD这两大家的方案技术路线不同 因此我们需要对比一下 在之前下面这段有几个概念说明：1.4D向量和4+13D物件的成像過程中，VS（Vertex Shader，顶点着色引擎）&amp;PS（Pixel Shader，像素著色引擎）最主要的作用就是运算坐标（XYZW）@（RGBA）。此时数据的基本单位是scalar（标量），1个单位的变量操作，为1D标量简称1D。而跟标量相對的就是vector（向量），向量是由多個标量构成。例如每個周期可执行4個向量平行运算，就称为4D向量架构。若GPU指令发射口只有1个，卻可執行4個数据的平行运算，这就是SIMD架构。 后来这个架构变成了4+1结构 2.运算单元计算机制以GPU的矩阵加法为例： NVIDIA标注的是Stream Processing(流处理器)数量，NVIDIA的流处理器每个都具有完整的ALU(可以理解为数学、逻辑等运算)。NVIDIA从G80以后采用全标量设计，所有运算全都转为标量计算。但是这么做一旦遇到4D矢量运算时，就需要4次运算才能完成，所以NVIDIA显卡的Shader频率几乎比核心频率高一倍，就是为了弥补这个缺点。NV的流处理器都具有完整的ALU功能，所以每个流处理器消耗的晶体管数量较多，成本较高。在加上现在的CUDA功能所以晶体管数量大幅多于AMD-ATI。 AMD/ATI标注的是Stream Processing Units(统一渲染单元)数量，也可以叫流处理器单元。AMD-ATI从RV670以后，流处理器是5个固定的统一渲染单元为一组，4D矢量+1D标量组合。其中4个只能进行MADD(乘加)运算，1个可以进行超运算(函数等运算)。因为是5个固定为一组，不能拆分，所以遇到纯标量运算时就会有4个SPU处于闲置状态而无法加入其它SP组合协助运算。但换句话说如果分配得当让每个SPU都充分工作，那么AMD显卡的效率可是非常高的。这也是玩家公认A卡驱动提升性能比N卡要高，但也就是这个原因导致A卡驱动设计难度非常高，游戏想要为A卡优化的难度也一样很高。 由于咱们主要讲软件 ALU CU这种数字逻辑部分的知识就不深入了 知道了硬件的区别下面来看看他们的计算原理 先来普及一个比较无关概念——波阵面（Wavefront） 波在传递过程中有振动相位 就像三角函数sin有波峰有波谷当我们取波峰为标准相位 那么在一个波阵面上 就出现了sin的波峰构成的点当我们在三维中考量这个问题 则出现类似于下面这种画面 因此在一个波阵面中 其可能相互有关联关系 也就是根绝这个一区域可以推出下一区域但也可能没有关联关系我们可以想象将两块石头扔进水中 向远散去的波 并不受另一个石头的影响 所以我们假定一个运算序列 假设有A～O共15个Wavefront，顺序是由A到O，且部分Wavefront存在相依性。其中C必须依赖B，也就是Wavefront C要等到Wavefront B运算完毕之後，才能算Wavefront C。类似B+2=4，B+C=6，必須先求得B m 的解才能解第二個方程式。其余E和F、F和G、L和K都是相同情況。 直接跳过落后架构VLIW4 其在多个周期出现了使用率低下的问题造成浪费现在的4+1 VLIW5架构指令过程如下 周期1 BC相互依存 则： 周期二：GF相互依存 则： 周齐三： LK互相依存 则： 最后一个周期运算完毕 在4+1架构中某些场景的利用率被大大提高 讲完了硬件的架构和处理原理 下面我们该对硬件层级的处理流程进行一个了解 当然 如果从管线角度去讲的话就没有任何意义了 因为基本上对于一个整个系统都未知来说还是不是很好去理解的 所以先来看看图形在硬件中的转换流程 更高层-硬件流程第一步 数据存储转换 资源信息和指令信息由硬盘经过CPU调度 传输到内存中转，再传输进显存中备用由图中的典型的带宽可见 GPU和显存之间的内部带宽 要比单纯的系统总线贷款要高很多所以典型情况下渲染资源和渲染指令都被加载进显存 所以GPU在渲染过程中 只需向显存调度渲染指令避免了和系统总线频繁IO 第二步 进入渲染预备状态 此时GPU的显存越大则普遍来说依靠CPU的加载额外渲染指令的需要就越少 显存中的信息一般包括：显存和内存一样用于存储GPU处理过后的数据，在显存中有几种不同的储存区域，用于储存不同阶段需要的数据。1、顶点缓冲区：用于储存从内存中传递过来的顶点数据。2、索引缓冲区：用于储存每个顶点的索引值，我们可以根据索引来使用相应的顶点3、纹理缓冲区：用于储存从内存中传递过来的纹理数据4、深度缓冲区：用于存储每个像素的深度信息5、模板缓冲区：用于存储像素的模板值，且模板缓冲区域深度缓冲区公用一片内存。6、颜色缓冲区：用于储存像素的颜色数据 待这部分后我们就可以了解下面的东西了 后续步骤将在之后介绍 软件，第一步不管是三维模型 还是二维UI他们都是有个极其相似的数据结构的以3DS格式为例 ： 都是以三角面为基础如果经过软件解析的话出现的数据结构就是点和索引信息具体的理解这个从点线面的构建过程：一个点的列表 根据索引信息链接点 根据索引信息构成面和块： 所有片面组成了模型的所有信息 举个例子帮助理解：对于下图，9个顶点及拓扑类型Triangle List，对应索引：[0,1,2, 0,2,3, 0,3,4, 0,4,5, 0,5,6, 0,6,7, 0,7,8]。 所以 整个三维场景的数据基础 都是以这种数据结构为框架 之前的内容中说过了 点信息索引信息都被加载进了 显存 中备用 而模型不光有框架而已 包括颜色，贴图 等信息 也被加载如显存 软件，第二步 ——顶点着色器，坐标转换（几何阶段）变换阶段：此阶段是完全可编程的；这个阶段的输入就是单个的顶点（顶点也是并行处理的）先来了解下变换阶段的概念 1. 模型空间：Model Space，也叫Local Space 直观的讲，这个坐标系一般以模型中心为原点，所有的模型在建模的时候给定的模型顶点坐标都以这个坐标系为基准，用户最开始所指定的顶点坐标也是位于该空间。 给出模型空间的好处在于方便建模，以及单个模型的重重利用。因为一个物体可被放置到场景的多个地方，这时每个物体的顶点坐标显然是不一样的，但可以共享同一个模型。 2. 世界空间：World Space 这个坐标系即3D场景给各个物体指定坐标的基准。、世界坐标系为整个游戏场景中的参考坐标系，是一个固定不变的坐标系，所有的模型的坐标都可以在世界坐标系中表示，模型在世界坐标系中可以执行位移变换，旋转变换，缩放变换等操作，但此时参考的坐标系是以世界坐标系为参考坐标系。在世界坐标系中还需要执行的是光照的计算、物体材质计算等工作。 3. 视角空间：View Space 这个坐标是以照相机为基准的，以照相机位置为原点，照相机朝向z轴正方向，右边为x轴正方向，上边为y轴正方向。之所以设置这个坐标系，主要是为了主便接下来的投影及裁剪操作。如果直接在世界空间下进行，由于照相机位置、朝向灵活多变，计算将会十分复杂。有了视角空间，一切计算以原点为基准，会大大方便计算。 4. 投影、裁剪空间：Projection Clip Space 这个空间即世界空间的物体被投影到相应的投影面上之后，继而进行裁剪操作所在的空间。 用户指定的所有顶点都是基于模型空间的，在Vertex Shader阶段，每个顶点要依次经历所有这些空间，最终转换为屏幕上对应的二维坐标，不同空间之间的切换称为“空间变换”，实现空间变换的基本工作即矩阵。一下表明了裁剪过程，eye space坐标转换到project and clip space坐标的过程其实就是一个投影、剪裁、映射的过程。因为在不规则的视锥体内剪裁是一件非常困难的事，所以前人们将剪裁安排到一个单位立方体中进行，这个立方体被称为规范立方体（CCV），CVV的近平面（对应视锥体的近平面）的x、y坐标对应屏幕像素坐标（左下角0、0），z代表画面像素深度。所以这个转换过程事实上由三步组成： （1），用透视变换矩阵把顶点从视锥体变换到CVV中；（2），在CVV内进行剪裁；（3），屏幕映射：将经过前两步得到的坐标映射到屏幕坐标系上。 定点位置和法向量通常以模型坐标系或者世界空间坐标系表示。进行透视，顶点光照和纹理计算，动画角色计算蒙皮顶点着色器可以通过修改顶点位置来产生程序动画。 截至现在为止 我们得到了视角内的所有顶点数据经过上面介绍过的再经过第一步介绍的点和索引结构 还原出点线面 想象一下 现在的场景内 只有模型的线框拿到了供渲染顶点数据之后流程大概如下所示 在unity中 过程可以更精确的表述为： 在移动设备上Unity才会有将Shader解析成OpenGLES这一步 我们可以看到V_shader和F_shader有着不同的工作范围。shader被编译为GPU汇编指令进行定点/光照/阴影等运算。而OPENGL和D3D都有嵌入shader的函数在DX的版本中 13DXCompileShaderFromResource()； openGL中 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081static char *shaderLoadSource(const char *filePath)&#123; const size_t blockSize=512; FILE *fp; char buf[blockSize]; char *source=NULL; size_t tmp,sourceLength=0; fp=fopen(filePath,&quot;r&quot;); if(!fp)&#123; fprintf(stderr,&quot;shaderLoadSource():Unable to open %s for reading\\n&quot;,filePath); return NULL; &#125; while((tmp=fread(buf,1,blockSize,fp))&gt;0) &#123; char *newSource=(char *)malloc(sourceLength+tmp+1); if(!newSource)&#123; fprintf(stderr,&quot;shaderLoadSource():malloc failed\\n&quot;); if(source)&#123; free(source); &#125; return NULL; &#125; if(source)&#123; memcpy(newSource,source,sourceLength); free(source); &#125; memcpy(newSource+sourceLength,buf,tmp); source=newSource; sourceLength+=tmp; &#125; fclose(fp); if(source)&#123; source[sourceLength]=&apos;\\0&apos;; &#125; return source;&#125;static GLuint shaderCompileFromFile(GLenum type,const char *filePath)&#123; char *source; GLuint shader; GLint length,result; source=shaderLoadSource(filePath); if(!source)&#123; return 0; &#125; shader=glCreateShader(type); length=strlen(source); glShaderSource(shader,1,(const char**)&amp;source,&amp;length); glCompileShader(shader); free(source); glGetShaderiv(shader,GL_COMPILE_STATUS,&amp;result); if(result==GL_FALSE)&#123; char *log; glGetShaderiv(shader,GL_INFO_LOG_LENGTH,&amp;length); log=(char *)malloc(length); glGetShaderInfoLog(shader,length,&amp;result,log); fprintf(stderr,&quot;shaderCompileFromFile(): Unable to compile %s: %s\\n&quot;,filePath,log); free(log); glDeleteShader(shader); return 0; &#125; return shader;&#125;void shaderAttachFromFile(GLuint program,GLenum type,const char *filePath)&#123; GLuint shader=shaderCompileFromFile(type,filePath); if(shader!=0)&#123; glAttachShader(program,shader); glDeleteShader(shader); &#125;&#125; 所以我们终于可以看清楚shader是怎样工作 下一篇开始 我们将具体介绍Shader从入门到完成一些效果的过程 总结如果我们以一个已知概念模型来总结这个工作过程一个工厂中shader property中的 材质 纹理 颜色 光照 等等就像是工厂中的原材料硬件本身就是工人shader就像是一副装配图纸告诉工人以怎样的方式组织原材料","categories":[],"tags":[{"name":"shader","slug":"shader","permalink":"http://winshare.tech/tags/shader/"}]},{"title":"unity & Computer graphics Chapter(2)","slug":"《Unity Shader 与 计算机图形学》第二章","date":"2017-05-06T10:44:48.238Z","updated":"2017-11-25T14:09:02.954Z","comments":true,"path":"2017/05/06/《Unity Shader 与 计算机图形学》第二章/","link":"","permalink":"http://winshare.tech/2017/05/06/《Unity Shader 与 计算机图形学》第二章/","excerpt":"提示：本篇将会非常长~ 本系列文章分为 硬件编程入门工程实践 上一篇主要介绍了GPU的特征工作原理 以及渲染的底层流程 其实对于新架构而言还有所不同Shader描述了如何渲染物体的信息，包括： Texture Setup、纹理设置Material Property、材质设置Render State、渲染状态Blend Setup、混合设置Pixel Shader、像素着色Vertex Shader、定点着色Render Target Setup 渲染目标设置","text":"提示：本篇将会非常长~ 本系列文章分为 硬件编程入门工程实践 上一篇主要介绍了GPU的特征工作原理 以及渲染的底层流程 其实对于新架构而言还有所不同Shader描述了如何渲染物体的信息，包括： Texture Setup、纹理设置Material Property、材质设置Render State、渲染状态Blend Setup、混合设置Pixel Shader、像素着色Vertex Shader、定点着色Render Target Setup 渲染目标设置 Shader并不直接和几何体相关联，因为对于同一个几何体，有可能会用不同的Shader来渲染。为了简化描述我们来定义一下：vs: vertex shader, 顶点处理/多边形处理的ps: pixel shader, 处理像素单位的阴影和处理相关纹理以上两种shader都是可编程的在各自的着色器单元(Shader Unit)上，有着把各种各样的Shader程序来实现为3D图形的处理的结构。而且，作为用语，如果直接说[Programmable Shader]，有指双方（VS和PS）的情况，或者是指这个整体的概念。并且，由于这个Shader程序是软件，开发者可以自己制作独创的Shader程序，就可以在GPU上实现新的图形功能。但是在之前的着色器架构中无法面对任务的调节 造成闲置资源 而在现有的统一着色器架构下 资源配置得到了有效保障 所以在DX11之后通用shader架构得到了广泛使用 比较理想的过程是： 当然 以上看不懂也无所谓 因为这个是软件之前的一点小铺垫。 正式篇前导一，纹理？材质？贴图？整个 CG 领域中这三个概念都是差不多的，在一般的实践中，大致上的层级关系是： 材质 Material包含贴图 Map，贴图包含纹理 Texture。 而我们要说的时更广泛应用的概念 纹理是最基本的数据输入单位，游戏领域基本上都用的是位图。常见格式有PNG，TGA，BMP，TIFF此外还有程序化生成的纹理 Procedural Texture。在内存中通常表示为二维像素数组。 贴图英语 Map 其实包含了另一层含义就是“映射”。其功能就是把纹理通过 UV 坐标映射到3D 物体表面。贴图包含了除了纹理以外其他很多信息，比方说 UV 坐标、贴图输入输出控制等等。一张图便能说明其之间的关系 材质本质就是一个数据集，主要功能就是给渲染器提供数据和光照算法。贴图就是其中数据的一部分，根据用途不同，贴图也会被分成不同的类型，比方说 Diffuse Map，Specular Map，Normal Map 和 Gloss Map 等等。另外一个重要部分就是光照模型 Shader ，用以实现不同的渲染效果。贴图种类繁多：我做个不完全总结 Diffuse Map -漫反射贴图/也被称作反照率贴图albedo map 存储了物体相应部分漫反射颜色 Normal Map -法线贴图 本质上存储的是被RGB值编码的法向量 表现凹凸，比如一些凹凸不平的表面，光影在表面产生实时变化 常用来低多边形表现高多边形细节 比如在高多边形下生成normal map在匹配给低多边形模型 是一种常见的降低性能要求的做法 对于讲解normal map来说这篇文章很值得借鉴N’= N + D =[0,0,c]+ D =[a,b,c]a = -dF/du 1/kb = -dF/dv 1/kc = 1 常规来说就是光向量和法向量的点积来确定明暗以表现凹凸质感，也就是把法线存在纹理中 我们又会发现另外一个奇怪的地方 法线贴图的颜色为什么都这么怪？事实上，真正的法线贴图并不是记录贴图上每个点的法线的绝对角度，而是记录的是相对于平面的一个差值。这样的话，随着平面的3D变换都能够实现即时的法线运算了。而借RGB数据存储的法线信息会被法线方向扰动，于是在RGB（x，y，z）上的平均分布空间上 x，z 值较大或者y得值比较大 因此表现出来合成的结果上普遍是紫色（xz）代表面 而绿色（y）反应深浅 Specular Map - 高光贴图 表现质感 高光区域大小可真实反映材质区别 Gloss Map -光泽贴图，每个纹理元素上描述光泽程度 而讲解贴图和纹理的工作机理中这篇博客讲的很不错 总体上说 他们都是要被shader加工的原材料正式篇前导二，光照模型？ 我们先来探讨一下几个问题 1. 当一个物体能被我们看见需要具备什么因素 ?2. 当一个物体是不同材质的时候，视觉上的区别在哪里？带着这两个问题 我们来说一下 什么是光照模型它总结了在什么情况下 一个物体能够被看见 以及以一个近似的概念描述了真实情况下光照的种类 基础－Phone式光照模型（Phone reflection model） 真实世界中的光照效果抽象为三种独立的光照效果的叠加1．环境光(Ambient)此为模拟环境中的整体光照水平，是间接反射光的粗略估计，间接反射的光使阴影部分不会变成全黑 关于环境光还有个事实，1某个可以独立分析的局部场合的环境光强和能够进入这个地方的光的强度有关。其计算公式为： 2．漫反射光(Diffuse)模拟直接光源在表面均匀的向各个方向反射，能够逼近真实光源照射到哑光表面的反射。比如在阳光下，由于路面粗糙的性质，我们发现从任意一个角度观察路面，亮度都是差不多。其计算公式为 3．镜面反射光(Specular)模拟在光滑表面会看到的光亮高光。会出现在光源的直接反射方向。镜子、金属等表面光亮的物体会有镜面反射光。镜面反射光同时与物体表面朝向、光线方向、视点位置有关。如图I是入射光，N是表面法线，R是反射光线，V是从物体上的目标观察点指向视点的向量，a是V和R的夹角。 我们可以判断出一个规律，夹角a越小，即视线与反射方向的偏离越小，则目标点的光强越大其计算公式为： Ks为物体对于反射光线的衰减系数Shininess为高光指数 高光指数反映了物体表面的光泽程度。Shininess越大，反射光越集中，当偏离反射方向时，光线衰减的越厉害，只有当视线方向与反射光线方向非常接近时才能看到镜面反射的高光现象，此时，镜面反射光将会在反射方向附近形成亮且小的光斑；Shininess 越小，表示物体越粗糙，反射光分散，观察到的光斑区域小，强度弱。 以上所在的公式都是便于理解的形式 实际要复杂得多 最后可得：其组成类似于 至于更多的光照模型结合了更多的物理光学等信息 在模拟单种材质例如塑料 合金 石膏陶瓷等等上要好于Phone式模型的效果 但是基本上属于Phone式模型的扩充 有了以上基础概念 我们就可以更好的理解shader的编写了 正式篇第一节 扫盲前一章提到了 可编程shader分为vertex （顶点）/fragement（片段） shader其可由多种语言去编写 比如CGSL/HLSL/CG我们先来比较一下 三种主流语言的优缺点 GLSL：基于OpenGL的OpenGL Shading Language CG：由NVIDIA公司开发。Cg极力保留C语言的大部分语义 HLSL ：基于DirectX的High Level Shading Language, Unity官方手册上讲Shader程序嵌入的小片段是用Cg/HLSL编写的，从“CGPROGRAM”开始，到“CGEND”结束。 我们看一段由unity初始化的shader本体： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748 Shader \"Custom/s1\" //级联菜单/shader名称 &#123;Properties &#123; _Color (\"Color\", Color) = (1,1,1,1) _MainTex (\"Albedo (RGB)\", 2D) = \"white\" &#123;&#125;//主纹理 _Glossiness (\"Smoothness\", Range(0,1)) = 0.5//光泽度 _Metallic (\"Metallic\", Range(0,1)) = 0.0//金属&#125;//属性 可在inspector中修改赋值 相当于供加工的材料SubShader &#123; Tags &#123; \"RenderType\"=\"Opaque\" &#125;//渲染标签 LOD 200 CGPROGRAM // Physically based Standard lighting model, and enable shadows on all light types //基于物理的光照模型 打开所有光照类型的阴影 #pragma surface surf Standard fullforwardshadows // Use shader model 3.0 target, to get nicer looking lighting //使用3.0模型得到更好的视觉效果 #pragma target 3.0 sampler2D _MainTex; struct Input &#123; float2 uv_MainTex; &#125;; half _Glossiness; half _Metallic; fixed4 _Color; void surf (Input IN, inout SurfaceOutputStandard o) &#123; // Albedo comes from a texture tinted by color //反照率来自于纹理着色的颜色 fixed4 c = tex2D (_MainTex, IN.uv_MainTex) * _Color; o.Albedo = c.rgb; // Metallic and smoothness come from slider variables //金属性和平滑度来自于滑动变量 o.Metallic = _Metallic; o.Smoothness = _Glossiness; o.Alpha = c.a; &#125; ENDCG&#125;FallBack \"Diffuse\" &#125; 所以，Unity官方主要是用Cg/HLSL编写Shader程序片段。Unity官方手册也说明对于Cg/HLSL程序进行扩展也可以使用GLSL，不过Unity官方建议使用原生的GLSL进行编写和测试。如果不使用原生GLSL，你就需要知道你的平台必须是Mac OS X、OpenGL ES 2.0以上的移动设备或者是Linux。在一般情况下Unity会把Cg/HLSL交叉编译成优化过的GLSL。因此我们有多种选择，我们既可以考虑使用Cg/HLSL，也可以使用GLSL。不过由于Cg/HLSL更好的跨平台性，更倾向于使用Cg/HLSL编写Shader程序。 第二节-固定管线我们采用更为简单易理解的方式去编写 那就是固定管线 在surface shader中pass通道被忽略 但是我们可以以一种更好的方式去理解 一个helloword性质的shader如下 1234567 Shader \"Custom/s2\" &#123;SubShader&#123; pass &#123; color(1,1,1,1)//白色 &#125; &#125; &#125; 把它和材质相结合之后 渲染出的球如下 但是我们看到他只是画出了一个球而已 没有任何三维特征 我们再回到之前说的光照的阶段 如果一个三维物体想被看见 简单的来说要具备哪些必要的元素呢？ 那就是 光在固定管线中 其实有着简单的光照指令 这时候我们可以试着添加properties以供我们可以更好的添加需要加工的素材像这样：这样之后我们就可以在inspector里实时调节这个颜色1234567891011121314151617 Shader \"test/s2\" &#123;properties&#123; _color(\"main color\",color)=(1,1,1,1)&#125;SubShader&#123;pass &#123; material//命令块 &#123; diffuse[_color]//反射光 &#125; lighting on// 打开光照的命令 //color(1,1,1,1)&#125;&#125; &#125; 这下我们打开了光照 瞬间看起来像是那么回事了 但是相比较而言似乎远远没有场景中其他物体特征那么明显说到了光照自然不得不提光照模型：那么我们把环境 反射 高光加入shader的固定管线之后再加入高光强度参数描述1234567891011121314151617181920212223 Shader &quot;test/s2&quot; &#123;properties&#123; _color(&quot;main color&quot;,color)=(1,1,1,1)//RGBA _ambient(&quot;ambient&quot;,color)=(0.3,0.3,0.3,0.3) _specular(&quot;specular&quot;,color)=(1,1,1,1) _shininess(&quot;specular&quot;,range(0,8))=4&#125;SubShader&#123;pass &#123; material &#123; diffuse[_color]//反射光 ambient[_ambient]//环境光 specular[_specular]//高光 shininess[_shininess]//高光强度 &#125; lighting on// or off//打开光照 separatespecular on//镜面高光开启&#125;&#125; &#125; 到这里他已经比场景里其他东西真实度高得多了 现在下面我们开始加入 材质我们用两张风格迥异的素材作为混合元素 为了加入不同材质我们要加入一些其他亦可赛艇的东西但这之前我们需要了解一点先导也就是alpha测试当渲染器在工作的时候必须要确定相对于摄像机的视角 物体的深度序列 来确定物体之间的遮挡 ，半透明物体的透光等 所以在我们再来看看这张渲染步骤图： 通过以下叠加结合的过程当我们把alpha调低后就可以看到半透明的物体了 123456789101112131415161718192021222324252627282930313233343536373839 Shader &quot;test/s2&quot; &#123;properties&#123; _color(&quot;main color&quot;,color)=(1,1,1,1) //color RGBA _ambient(&quot;ambient&quot;,color)=(0.3,0.3,0.3,0.3) _specular(&quot;specular&quot;,color)=(1,1,1,1) _shininess(&quot;specular&quot;,range(0,8))=4 //range（x,y） _Emission(&quot;Emission&quot;,color)=(1,1,1,1) _Maintex(&quot;MainTex&quot;,2d)=&quot;&quot; //texture 2d _SecondTex(&quot;SecondTex&quot;,2d)=&quot;&quot;&#125;SubShader&#123;Blend srcalpha OneminusSrcAlpha//混合1-scralpha前面的图中有提到pass &#123; //______________________________________________________ material &#123; diffuse[_color]//反射光 ambient[_ambient]//环境光 specular[_specular]//高光 shininess[_shininess]//高光强度 &#125; //________________________________________________________ lighting on// or off separatespecular on//镜面高光 settexture[_Maintex]&#123; //主纹理 combine texture * primary double//结合，且将之前的x2 or quad x4 //primary 代表顶点光照（material命令快）过后的颜色 &#125; settexture[_SecondTex]&#123;//第二纹理 combine texture * previous double//x2 //previous 代表所有之前的颜色 &#125;&#125;&#125; &#125; 我们看到 者甚至出现了一个奇怪的好处就是可以营造 镂空效果Tiling表示UV坐标的缩放倍数，Offset表示UV坐标的起始位置。如下图可见当我们贴上了三角面 则可以看到模型的与之对应的过程 一个模型能够正确被显示，贴图和模型的uv坐标必须能够对应而我们利用其起始坐标和缩放系数的修改就可以营造出运动和镂空等多种效果。 第三节surface shader我们再回到由unity初始化的surface shader中当然我们学习surface最好的途径就是unity 手册的网站：surface shader document12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849 Shader \"Custom/s3\" &#123;Properties &#123; _Color (\"Color\", Color) = (1,1,1,1) _MainTex (\"Albedo (RGB)\", 2D) = \"white\" &#123;&#125; _Glossiness (\"Smoothness\", Range(0,1)) = 0.5 _Metallic (\"Metallic\", Range(0,1)) = 0.0&#125;SubShader &#123; Tags &#123; \"RenderType\"=\"Opaque\" &#125; //渲染标签：渲染类型=不透明 LOD 200 CGPROGRAM//CG语言开始阶段 #pragma surface surf Standard fullforwardshadows #pragma target 3.0//最高支持target5.0直接应用DX11 //编译指令 //#pragma surfaceFuntion Lightmodel [Optionalparams] //#pragma 函数名称 光照模式 [选项] //standard光照模型在unityPBSlighting.cginc中 //默认fullforwardshadows 阴影 struct Input &#123; float2 uv_MainTex; &#125;; //纹理坐标必须以uv开头 sampler2D _MainTex; half _Glossiness; half _Metallic; fixed4 _Color; //在CG语言中需对properties的变量再次声明一一对应 //但是其变量类型并不是完全一致 void surf (Input IN, inout SurfaceOutputStandard o) &#123; // 来自纹理作色的反照率 fixed4 c = tex2D (_MainTex, IN.uv_MainTex) * _Color; o.Albedo = c.rgb; // 一个能被滑块定制的决定平滑度和金属性的变量其实就是range那个能被滑条操纵的变量 o.Metallic = _Metallic; o.Smoothness = _Glossiness; o.Alpha = c.a; &#125; //处理段 ENDCG//CG语言结束阶段&#125;FallBack \"Diffuse\" &#125; 我们看到了几乎是完全两种语言一样 因为他就是两种语言 unity推崇的surface shader中应用了CG语言的一部分因此 在其中特定区域可以写CG语言 同时 surface shader本身就是对两种可编程管线也就是vertex shader和fragment shader的包装 也因此 其中可探究的部分 真可谓写一本书都不够 下面我们就从上到下的顺序开始对其进行解析一个标准的surface sahder有哪些不同的地方 1.渲染标签12 Tags &#123; &quot;RenderType&quot;=&quot;Opaque&quot; &#125;//渲染标签：渲染类型=不透明 ？？？？？？？？？？？ 2.编译指令字段1234567 #pragma surface surf Standard fullforwardshadows#pragma target 3.0//编译指令 //#pragma surfaceFuntion Lightmodel [Optionalparams]//#pragma 函数名称 光照模式 [选项]//standard光照模型在unityPBSlighting.cginc中//默认fullforwardshadows 阴影 由注释可以看到 函数名称后的光照模式和选项部分 其实是我们完全没有见过的东西 Tips：PBS（基于物理的光照运算，从unity5开始引入，技术源于迪士尼。在unity4中不可用） 2.1光照模式 unity内部的东西实际上我们在客户端的安装目录中就可以找到这段指令的来源Unity\\Editor\\Data\\CGIncludes这里包含了所有渲染需要用的引用当我们找到了unityPBSlighting.cgnic这个文件就可以找到其来源 123456789101112131415161718 inline half4 LightingStandard (SurfaceOutputStandard s, half3 viewDir, UnityGI gi) &#123;s.Normal = normalize(s.Normal);half oneMinusReflectivity;half3 specColor;s.Albedo = DiffuseAndSpecularFromMetallic (s.Albedo, s.Metallic, /*out*/ specColor, /*out*/ oneMinusReflectivity);// shader relies on pre-multiply alpha-blend (_SrcBlend = One, _DstBlend = OneMinusSrcAlpha)// this is necessary to handle transparency in physically correct way - only diffuse component gets affected by alphahalf outputAlpha;s.Albedo = PreMultiplyAlpha (s.Albedo, s.Alpha, oneMinusReflectivity, /*out*/ outputAlpha);half4 c = UNITY_BRDF_PBS (s.Albedo, specColor, oneMinusReflectivity, s.Smoothness, s.Normal, viewDir, gi.light, gi.indirect);c.rgb += UNITY_BRDF_GI (s.Albedo, specColor, oneMinusReflectivity, s.Smoothness, s.Normal, viewDir, s.Occlusion, gi);c.a = outputAlpha;return c; &#125; 尤其要注意的是 定义这类光照模式的时候要以lighting为开头否则编译会出错这是unity5之后使用的新型光照模式从这个文件中我们还可以找到其他的的模式类型也就是我们熟悉的BlinnPhong 123456789101112131415161718192021inline fixed4 LightingBlinnPhong (SurfaceOutput s, half3 viewDir, UnityGI gi)&#123; fixed4 c; c = UnityBlinnPhongLight (s, viewDir, gi.light); #if defined(DIRLIGHTMAP_SEPARATE) #ifdef LIGHTMAP_ON c += UnityBlinnPhongLight (s, viewDir, gi.light2); #endif #ifdef DYNAMICLIGHTMAP_ON c += UnityBlinnPhongLight (s, viewDir, gi.light3); #endif #endif #ifdef UNITY_LIGHT_FUNCTION_APPLY_INDIRECT c.rgb += s.Albedo * gi.indirect.diffuse; #endif return c;&#125; 2.2选项部分Optional parameters在unity手册中写的比较清楚 类型过于多也不适合去展开说明我们就挑选出现了的阴影选项去讲解一下 Shadows and Tessellation - .附加指令以控制如何处理阴影和曲面细分。addshadow - 通常使用自定义顶点修改，使得阴影投射也获得任何过程顶点动画。 fullforwardshadows - 支持正向渲染路径中的所有光影类型。默认情况下，着色器仅支持来自正向渲染中的一个定向光源的阴影（以保存内部着色器变量计数）。如果需要在正向渲染中点或点亮阴影，请使用此指令。 tessellate:TessFunction - 使用dx11计算曲面细分因子 3.定义部分这部分倒是没什么说的 CG语言入门不是本篇文章的目的，所以各种变量类型以及作用都不做介绍到了这里本文其实是更重视流程的阐述 所以在这个思想上我们往下看不能直接处理定义在properties 中的元素所以要在处理之前做定义以映射相关元素1234567891011struct Input &#123; float2 uv_MainTex;&#125;;//纹理坐标必须以uv开头sampler2D _MainTex;half _Glossiness;half _Metallic;fixed4 _Color;//在CG语言中需对properties的变量再次声明一一对应//但是其变量类型并不是完全一致 4.函数部分所定义的函数部分要从更高的层面去讲解了必须要回到我们的引用中去123456789 void surf (Input IN, inout SurfaceOutputStandard o) &#123; // 来自纹理作色的反照率 fixed4 c = tex2D (_MainTex, IN.uv_MainTex) * _Color; o.Albedo = c.rgb; // 一个能被滑块定制的决定平滑度和金属性的变量其实就是range那个能被滑条操纵的变量 o.Metallic = _Metallic; o.Smoothness = _Glossiness; o.Alpha = c.a;&#125; 参数列表，Cg 中还提供了三个关键字，in、out、inout，用于表示函数的输入参数的传递方式，称为输入/输出关键字，这组关键字可以和语义词合用表达硬件上不同的存储位置，即同一个语义词，使用in 关键字修辞和out 关键词修辞，表示的图形硬件上不同的寄存器。我们在之前的pbslighting文件中找到参数列表中的输入输出参数类型是什么输入部分（初始化中定义过了）： 123 struct Input &#123; float2 uv_MainTex;&#125;; 输出部分：123456789101112 struct SurfaceOutputStandard &#123;fixed3 Albedo; // base (diffuse or specular) colorfixed3 Normal; // tangent space normal, if writtenhalf3 Emission;half Metallic; // 0=non-metal, 1=metal// Smoothness is the user facing name, it should be perceptual smoothness but user should not have to deal with it.// Everywhere in the code you meet smoothness it is perceptual smoothnesshalf Smoothness; // 0=rough, 1=smoothhalf Occlusion; // occlusion (default 1)fixed Alpha; // alpha for transparencies &#125;; 整体来看 我们也能熟悉这个整体的套路函数作为输入和输出的载体，而输入和输出都有着固定的模式，根据输入的IN计算OUT进入缓存。 当我们完成了surface shader的编写可以通过查看shader编译结果的方式了解整个处理流程短短的一段surface shader被编译成8000多行的真正的执行shader其中还有d3d的支持部分我们截取一小段来看一下例如： 123456789101112131415161718192021222324252627282930313233343536373839404142 -- Vertex shader for &quot;d3d11&quot;: // Stats: 22 math Uses vertex data channel &quot;Vertex&quot; Uses vertex data channel &quot;Color&quot; Uses vertex data channel &quot;TexCoord&quot; Constant Buffer &quot;$Globals&quot; (128 bytes) on slot 0 &#123; Vector4 _MainTex_ST at 96 &#125; Constant Buffer &quot;UnityLighting&quot; (720 bytes) on slot 1 &#123; Vector4 unity_SHBr at 656 Vector4 unity_SHBg at 672 Vector4 unity_SHBb at 688 Vector4 unity_SHC at 704 &#125;Constant Buffer &quot;UnityPerDraw&quot; (352 bytes) on slot 2 &#123; Matrix4x4 glstate_matrix_mvp at 0 Matrix4x4 unity_ObjectToWorld at 192 Matrix4x4 unity_WorldToObject at 256 &#125;-- Fragment shader for &quot;d3d11&quot;: // Stats: 30 math, 4 textures, 2 branches Set 2D Texture &quot;_MainTex&quot; to slot 0 Set 3D Texture &quot;unity_ProbeVolumeSH&quot; to slot 1 Constant Buffer &quot;$Globals&quot; (128 bytes) on slot 0 &#123; Float _Glossiness at 64 Float _Metallic at 68 Vector4 _Color at 80 &#125; Constant Buffer &quot;UnityLighting&quot; (720 bytes) on slot 1 &#123; Vector4 unity_SHAr at 608 Vector4 unity_SHAg at 624 Vector4 unity_SHAb at 640 &#125; Constant Buffer &quot;UnityProbeVolume&quot; (112 bytes) on slot 2 &#123; Matrix4x4 unity_ProbeVolumeWorldToObject at 16 Vector4 unity_ProbeVolumeParams at 0Vector3 unity_ProbeVolumeSizeInv at 80 Vector3 unity_ProbeVolumeMin at 96 &#125; 这两个片段很好的描述了整个着色过程体现在代码阶段的样貌 当然这只是凤毛菱角 函数中对于信息的计算和各种算法以及处理流程才是最重要的。而CG的入门应该在NVIDIA_CG_page这里去入门。我们主要说流程以及不同的地方。 下一篇文章我们会讲解unity shader编写中怎样实现一些好的效果 Good bye Next Month~~","categories":[],"tags":[{"name":"shader","slug":"shader","permalink":"http://winshare.tech/tags/shader/"}]}]}